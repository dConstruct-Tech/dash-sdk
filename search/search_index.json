{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dConstruct d.ASH SDK The dConstruct d.ASH SDK is a cross-platform library for autonomous robot navigation. Use the d.ASH SDK to develop applications for your own Spot from Boston Dynamics or any other robot you wish. This section of the d.ASH SDK documentation provides details about the components of the SDK. Component Description d.ASH Server The d.ASH server acts as the main server responsible for sending control commands to the robot. At the same time, the d.ASH server also broadcasts secured data to any given remote systems. d.ASH Autonomy Engine The d.ASH Autonomy Engine is the autonomy backend code that runs on the edge of the robot. It empowers the robot with robust multi-terrain (indoor and outdoor) autonomous navigation capabilities. It handles secure communication between automony engine and the remote autonomy controller. d.ASH Autonomy Controller The d.ASH autonomy controller is the GUI (graphical user interface) for the d.ASH autonomy engine. It enable users to monitor and have full remote control of autonomy by allowing users to plot waypoints and activate autonomy on a fleet of robots. Stream real-time data via a secure connection between robots and the controller using 4G or 5G. If you decide to use your own custom GUI in place of the d.ASH autonomy controller, or you do not want to run autonomy, you will still need to implement the d.ASH server and the d.ASH autonomy engine to operate your robot.","title":"Introduction"},{"location":"#dconstruct-dash-sdk","text":"The dConstruct d.ASH SDK is a cross-platform library for autonomous robot navigation. Use the d.ASH SDK to develop applications for your own Spot from Boston Dynamics or any other robot you wish. This section of the d.ASH SDK documentation provides details about the components of the SDK. Component Description d.ASH Server The d.ASH server acts as the main server responsible for sending control commands to the robot. At the same time, the d.ASH server also broadcasts secured data to any given remote systems. d.ASH Autonomy Engine The d.ASH Autonomy Engine is the autonomy backend code that runs on the edge of the robot. It empowers the robot with robust multi-terrain (indoor and outdoor) autonomous navigation capabilities. It handles secure communication between automony engine and the remote autonomy controller. d.ASH Autonomy Controller The d.ASH autonomy controller is the GUI (graphical user interface) for the d.ASH autonomy engine. It enable users to monitor and have full remote control of autonomy by allowing users to plot waypoints and activate autonomy on a fleet of robots. Stream real-time data via a secure connection between robots and the controller using 4G or 5G. If you decide to use your own custom GUI in place of the d.ASH autonomy controller, or you do not want to run autonomy, you will still need to implement the d.ASH server and the d.ASH autonomy engine to operate your robot.","title":"dConstruct d.ASH SDK"},{"location":"dash-auto/autonomy-client/","text":"d.ASH Autonomy Controller As mentioned previously, the d.ASH autonomy controller is a GUI (graphical user interface) for the d.ASH SDK. It allows users to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning. This section of the d.ASH SDK documentation provides details about setting up the d.ASH autonomy controller, including information on its respective components. d.ASH Autonomy Controller Description Pair d.C Pilot with d.ASH Autonomy Controller for remote autonomous operations. This app allows you to control multiple robots and author + run autonomous waypoint missions configured with different payloads. Camera Controls You can pan/zoom/fly around the 3D Map Visualization World via the following controls: Tilt/Camera LookAt: Hold down the Left Mouse Button and drag Zoom: Use the mouse scroll wheel to zoom in/zoom out Move Around: Use the WASD keys to pan/move around the world General Workflow The general workflow to operate and run an autonomous waypoint mission is as follows: Login to the Autonomy Controller Load the point cloud map of your deployment location generated with d.ASH Pack into the app Create a new mission Route and plot the waypoints Connect to your desired robot in your robot fleet Set the robot's initial starting pose on the 3D map Start the robot with the route for your new mission 1.0 Load Point Cloud Map Click on the Point Cloud icon to open up the point cloud loading window. Then click on Load Point Cloud . A file dialog will pop up to allow you to load your desired point cloud from disk. Make sure the same point cloud map is also configured on the robot(s). 1.1 Robot Fleet Manager The lower expandable panel opens up the Robot Fleet Manager . This displays the list of robots currently registered and also alive under your user account. You connect your desired robot by locating your robot in the icon list and then clicking on the connect icon. When the robot is connected, the following display appears: You are now able to inspect various properties of the robot ( battery status, LIDAR color etc. ) as well as start launching autonomous waypoint missions for this connected robot. 1.2 General Settings The General Settings expandable panel from the left side of the screen. In here you can configure various options to streamline robot operations. General: This allows the customization of route/waypoint + map display settings Robot Viz: Visualization settings pertaining to the robots operated in the app Map Viz: Visualization settings for the 3D map display. In particular, use the Floor and Ceiling sliders to adjust how much of the 3D map height-wise 1.3 Routes + Waypoints This subpanel can be accessed by expanding the panel on the right side of the screen. It allows you to manage the various mission routes available for your robots. To create a new route, you do the following: Enter a new Route Name in the textbox provided Click the + button to add a new route Select the newly route by clicking on it Now go into the main 3D Map display to start plotting your waypoints for the route. You can Append/Splice/Modify a route via the subpanel below: With the desired waypoint plotting option selected, you can go ahead and plot the waypoint directly with the mouse: Tap the ESC key to exit the waypoint plotting operation. If you need to delete a waypoint, you can select it via a mouse click on the 3D Map, then press the Delete key. 1.4 Settings the Initial Robot Pose When you activate a new robot into the app, the first required step is to tell the system where the robot is and where it is facing in relation to the 3D map. This step is defined as setting the Initial Pose of the robot. You set the Initial Pose via the following steps: Click on the Initial Pose arrow button on the lower expandable panel to start the Initial Pose operation: Go to the 3D map, hold down your mouse on the part of the map where the robot is. Drag a direction and release to set the pose of the robot If the pose was set incorrectly, you can repeat steps 1 and 2 until the LIDAR scans of the robot matches that of the 3D map. This is when you know the Initial Pose is setup correctly. Take Note: It is very important the Initial Pose of the robot is setup correctly before starting any Waypoint Autonomy Mission ! Incorrect initial poses will result in the robot unable to localize correctly leading to mission failure. 1.5 Mission Routes/Management This expandable panel located at the top part of the screen allows you to start new waypoint missions as well as manage existing missions. To start a new mission: Enter a new mission name in the textbox, then press the + button to add a new mission Select the new mission and press the Run button to start it You should now see your robot move in the 3D map viewer along the mission route 1.6 Robot Camera Streaming You can activate any available cameras on the robot via the Camera Stream button circled red above. When pressed, a new Camera Stream window pops up: Select the robot which you will want to stream the camera from via the top drop down box. Then use the lower drop down box to select which of the available robot cameras to stream from. 1.7 Robot Remote Piloting/TeleOps The app also allows basic remote manual piloting of your robots. Just like the Pilot Client , plug in a regular joystick into your system to begin manually piloting your robots. You will have to activate the robot for manual control via the manual control button located in the lower expandable panel before piloting is enabled.","title":"1.0 d.ASH Autonomy Controller"},{"location":"dash-auto/autonomy-client/#dash-autonomy-controller","text":"As mentioned previously, the d.ASH autonomy controller is a GUI (graphical user interface) for the d.ASH SDK. It allows users to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning. This section of the d.ASH SDK documentation provides details about setting up the d.ASH autonomy controller, including information on its respective components. d.ASH Autonomy Controller Description Pair d.C Pilot with d.ASH Autonomy Controller for remote autonomous operations. This app allows you to control multiple robots and author + run autonomous waypoint missions configured with different payloads.","title":"d.ASH Autonomy Controller"},{"location":"dash-auto/autonomy-client/#camera-controls","text":"You can pan/zoom/fly around the 3D Map Visualization World via the following controls: Tilt/Camera LookAt: Hold down the Left Mouse Button and drag Zoom: Use the mouse scroll wheel to zoom in/zoom out Move Around: Use the WASD keys to pan/move around the world","title":"Camera Controls"},{"location":"dash-auto/autonomy-client/#general-workflow","text":"The general workflow to operate and run an autonomous waypoint mission is as follows: Login to the Autonomy Controller Load the point cloud map of your deployment location generated with d.ASH Pack into the app Create a new mission Route and plot the waypoints Connect to your desired robot in your robot fleet Set the robot's initial starting pose on the 3D map Start the robot with the route for your new mission","title":"General Workflow"},{"location":"dash-auto/autonomy-client/#10-load-point-cloud-map","text":"Click on the Point Cloud icon to open up the point cloud loading window. Then click on Load Point Cloud . A file dialog will pop up to allow you to load your desired point cloud from disk. Make sure the same point cloud map is also configured on the robot(s).","title":"1.0 Load Point Cloud Map"},{"location":"dash-auto/autonomy-client/#11-robot-fleet-manager","text":"The lower expandable panel opens up the Robot Fleet Manager . This displays the list of robots currently registered and also alive under your user account. You connect your desired robot by locating your robot in the icon list and then clicking on the connect icon. When the robot is connected, the following display appears: You are now able to inspect various properties of the robot ( battery status, LIDAR color etc. ) as well as start launching autonomous waypoint missions for this connected robot.","title":"1.1 Robot Fleet Manager"},{"location":"dash-auto/autonomy-client/#12-general-settings","text":"The General Settings expandable panel from the left side of the screen. In here you can configure various options to streamline robot operations. General: This allows the customization of route/waypoint + map display settings Robot Viz: Visualization settings pertaining to the robots operated in the app Map Viz: Visualization settings for the 3D map display. In particular, use the Floor and Ceiling sliders to adjust how much of the 3D map height-wise","title":"1.2 General Settings"},{"location":"dash-auto/autonomy-client/#13-routes-waypoints","text":"This subpanel can be accessed by expanding the panel on the right side of the screen. It allows you to manage the various mission routes available for your robots. To create a new route, you do the following: Enter a new Route Name in the textbox provided Click the + button to add a new route Select the newly route by clicking on it Now go into the main 3D Map display to start plotting your waypoints for the route. You can Append/Splice/Modify a route via the subpanel below: With the desired waypoint plotting option selected, you can go ahead and plot the waypoint directly with the mouse: Tap the ESC key to exit the waypoint plotting operation. If you need to delete a waypoint, you can select it via a mouse click on the 3D Map, then press the Delete key.","title":"1.3 Routes + Waypoints"},{"location":"dash-auto/autonomy-client/#14-settings-the-initial-robot-pose","text":"When you activate a new robot into the app, the first required step is to tell the system where the robot is and where it is facing in relation to the 3D map. This step is defined as setting the Initial Pose of the robot. You set the Initial Pose via the following steps: Click on the Initial Pose arrow button on the lower expandable panel to start the Initial Pose operation: Go to the 3D map, hold down your mouse on the part of the map where the robot is. Drag a direction and release to set the pose of the robot If the pose was set incorrectly, you can repeat steps 1 and 2 until the LIDAR scans of the robot matches that of the 3D map. This is when you know the Initial Pose is setup correctly. Take Note: It is very important the Initial Pose of the robot is setup correctly before starting any Waypoint Autonomy Mission ! Incorrect initial poses will result in the robot unable to localize correctly leading to mission failure.","title":"1.4 Settings the Initial Robot Pose"},{"location":"dash-auto/autonomy-client/#15-mission-routesmanagement","text":"This expandable panel located at the top part of the screen allows you to start new waypoint missions as well as manage existing missions. To start a new mission: Enter a new mission name in the textbox, then press the + button to add a new mission Select the new mission and press the Run button to start it You should now see your robot move in the 3D map viewer along the mission route","title":"1.5 Mission Routes/Management"},{"location":"dash-auto/autonomy-client/#16-robot-camera-streaming","text":"You can activate any available cameras on the robot via the Camera Stream button circled red above. When pressed, a new Camera Stream window pops up: Select the robot which you will want to stream the camera from via the top drop down box. Then use the lower drop down box to select which of the available robot cameras to stream from.","title":"1.6 Robot Camera Streaming"},{"location":"dash-auto/autonomy-client/#17-robot-remote-pilotingteleops","text":"The app also allows basic remote manual piloting of your robots. Just like the Pilot Client , plug in a regular joystick into your system to begin manually piloting your robots. You will have to activate the robot for manual control via the manual control button located in the lower expandable panel before piloting is enabled.","title":"1.7 Robot Remote Piloting/TeleOps"},{"location":"dash-pack/dash-pack/","text":"d.ASH Pack | | d.ASH Pack is a mobile sensor system that allows users to record 3D point cloud data for various applications, including robot autonomous navigation and Digital Twin generation. d.ASH Pack can either be worn on the back of the user (just like a backpack) or mounted on a robot. It ships together with d.ASH Xplorer application, which is used to generate a 3D point cloud. The entire workflow is fully integrated with d.ASH Fleet Management system . | | You can view a short video overview of how d.ASH Pack integrates into your Autonomous Robot Deployment workflow here Requirements A Windows PC with d.ASH Xplorer d.ASH Pack device *Users can plug in a 4G USB dongle into the side USB port of d.ASH Pack to remotely control it 1.1 Quick Start A 3D point cloud is created in two steps: data collection and data processing. Data collection requires the d.ASH Pack device. There are 3 different ways to activate the data collection process, as listed below. If you do not have access to an internet connection, please make sure to use Option 1 which allows you to activate the data collection via your phone. Data processing requires the d.ASH Xplorer application and an internet connection. The d.ASH Xplorer software is used to process the recorded data, create and edit 3D point clouds, and upload data to the Fleet Management cloud. Recording cannot be paused for later continuation . If you would like to pause momentarily, please restart the recording. Ensure some overlap in area between the two separate recordings. Do note that the results may not be as accurate as one full walkthrough. 1.2 Connecting to d.ASH Pack The d.ASH Pack Wi-Fi network SSID and Password will be provided to you on the access panel of the d.ASH Pack itself. Use this to connect to your d.ASH Pack and access the user interface by keying this IP Address (https://192.168.10.1/) into a web browser from any device of your choice. Users can check the status of their d.ASH Pack and start/stop recordings here. Mobile interface: | | Status LEDs The status LEDs are able to show different colours with each colour representing a different status. These LEDs are located on the side of the d.ASH Pack itself. Green LEDs means that the d.ASH Pack has been booted up fully and is ready for recording. Red LEDs means that something has gone wrong with d.ASH Pack. Use the status reflected in your d.ASH Pack's website to help trouble shoot the error. Slow, Flashing Yellow LEDs mean that the d.ASH Pack is currently recording. 1.3 Data Collection Option 1 - Connect d.ASH Pack via Wi-Fi Network (No internet connection required) Power up d.ASH Pack Connect to d.ASH Pack's Wi-Fi network from your phone or other electronic devices. Open your web browser and key in \"https://192.168.10.1/\". Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans. Put on the d.ASH Pack and stand stationary for a short moment (e.g. 1s). Then, press start recording. Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, press stop recording. Option 2 - Use d.ASH Xplorer Power up d.ASH Pack Load your d.ASH Xplorer application on your PC Login with your d.ASH credentials. Click on the \"d.ASH Pack Manager\" tab at the top. Select your d.ASH Pack. Click on \"d.ASH Pack Recording Control\" Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans. Press start Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, press stop recording. 1.4 Data Processing For a more in-depth guide, please head to the d.ASH Xplorer documentation page . Load up the d.ASH Xplorer Application Login and click \"d.ASH Pack Manager\" tab at the top. Your d.ASH Pack device should appear in the list. Select it by clicking on it. Select the recording files that you wish to download. If you connect an Ethernet cable between d.ASH Pack and your PC, you will have options to download the recordings via either an Ethernet cable or wirelessly. For fast download speeds, using an Ethernet cable is recommended. Change 3D point cloud generation configurations to suite the environment of the recording. For generation configuration explanations/tips, please refer to Generation Configs section in Xplorer guide . Select the preferred recording file and click \"Generate Point Cloud\" to start the point cloud generation. While it is running, you will have the following options: Pause : Pause the generation process (Appears if generation is running) Resume : Resume the generation process (Appears if generation is paused) Cancel : Cancel the generation process Checkpoint : Export the current 3D point cloud to Point Cloud Editor. This is used to back up the generation progress. If problems arise in the future, some good results can still be restored. Once completed, click \"Point Cloud Editor\" to edit the generated 3D point cloud. The name of the new point cloud is the same as the recording file's name. Follow the d.ASH Xplorer guide to edit the point cloud accordingly. Once you are satisfied with the 3D point cloud, click \"Upload\" to upload the point cloud to your d.ASH Fleet Management account in the cloud. Tips for Data Collection It is recommended to walk in small loops back to previously visited areas for point cloud autocorrection. You will notice some automatic corrections being done during the generation process on d.ASH Xplorer. These corrections are called loop-closures. Good example of a well defined loop: | | Bad example where there is no loop: | { align=center style=\"width:600px\"} | Where the loops/paths criss-cross should have recognisable static/stationary features (e.g. buildings) Good examples of easily recognisable features: | | | | | | Bad examples of features (AKA: Dynamic features): | | | | Tighten the d.ASH Pack straps before recording Move at a steady pace Ensure LiDAR is above your head and do not block the sensor when recording Do not turn quickly in narrow corridors Do not record while in a lift Not recommended to record in narrow stairwells Put on the d.ASH Pack before starting the scan For recording with imaging, please tilt the LiDAR by 30\u00b0, otherwise a horizontal configuration is recommended If on a vehicle, please dismount and walk through bumpy areas Attempting to loop close long corridors (>20m) is discouraged Avoid large empty areas (e.g. fields) when recording as there are a lack of features","title":"1.0 d.ASH Pack"},{"location":"dash-pack/dash-pack/#dash-pack","text":"| | d.ASH Pack is a mobile sensor system that allows users to record 3D point cloud data for various applications, including robot autonomous navigation and Digital Twin generation. d.ASH Pack can either be worn on the back of the user (just like a backpack) or mounted on a robot. It ships together with d.ASH Xplorer application, which is used to generate a 3D point cloud. The entire workflow is fully integrated with d.ASH Fleet Management system . | | You can view a short video overview of how d.ASH Pack integrates into your Autonomous Robot Deployment workflow here","title":"d.ASH Pack"},{"location":"dash-pack/dash-pack/#requirements","text":"A Windows PC with d.ASH Xplorer d.ASH Pack device *Users can plug in a 4G USB dongle into the side USB port of d.ASH Pack to remotely control it","title":"Requirements"},{"location":"dash-pack/dash-pack/#11-quick-start","text":"A 3D point cloud is created in two steps: data collection and data processing. Data collection requires the d.ASH Pack device. There are 3 different ways to activate the data collection process, as listed below. If you do not have access to an internet connection, please make sure to use Option 1 which allows you to activate the data collection via your phone. Data processing requires the d.ASH Xplorer application and an internet connection. The d.ASH Xplorer software is used to process the recorded data, create and edit 3D point clouds, and upload data to the Fleet Management cloud. Recording cannot be paused for later continuation . If you would like to pause momentarily, please restart the recording. Ensure some overlap in area between the two separate recordings. Do note that the results may not be as accurate as one full walkthrough.","title":"1.1 Quick Start"},{"location":"dash-pack/dash-pack/#12-connecting-to-dash-pack","text":"The d.ASH Pack Wi-Fi network SSID and Password will be provided to you on the access panel of the d.ASH Pack itself. Use this to connect to your d.ASH Pack and access the user interface by keying this IP Address (https://192.168.10.1/) into a web browser from any device of your choice. Users can check the status of their d.ASH Pack and start/stop recordings here. Mobile interface: | | Status LEDs The status LEDs are able to show different colours with each colour representing a different status. These LEDs are located on the side of the d.ASH Pack itself. Green LEDs means that the d.ASH Pack has been booted up fully and is ready for recording. Red LEDs means that something has gone wrong with d.ASH Pack. Use the status reflected in your d.ASH Pack's website to help trouble shoot the error. Slow, Flashing Yellow LEDs mean that the d.ASH Pack is currently recording.","title":"1.2 Connecting to d.ASH Pack"},{"location":"dash-pack/dash-pack/#13-data-collection","text":"Option 1 - Connect d.ASH Pack via Wi-Fi Network (No internet connection required) Power up d.ASH Pack Connect to d.ASH Pack's Wi-Fi network from your phone or other electronic devices. Open your web browser and key in \"https://192.168.10.1/\". Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans. Put on the d.ASH Pack and stand stationary for a short moment (e.g. 1s). Then, press start recording. Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, press stop recording. Option 2 - Use d.ASH Xplorer Power up d.ASH Pack Load your d.ASH Xplorer application on your PC Login with your d.ASH credentials. Click on the \"d.ASH Pack Manager\" tab at the top. Select your d.ASH Pack. Click on \"d.ASH Pack Recording Control\" Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans. Press start Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, press stop recording.","title":"1.3 Data Collection"},{"location":"dash-pack/dash-pack/#14-data-processing","text":"For a more in-depth guide, please head to the d.ASH Xplorer documentation page . Load up the d.ASH Xplorer Application Login and click \"d.ASH Pack Manager\" tab at the top. Your d.ASH Pack device should appear in the list. Select it by clicking on it. Select the recording files that you wish to download. If you connect an Ethernet cable between d.ASH Pack and your PC, you will have options to download the recordings via either an Ethernet cable or wirelessly. For fast download speeds, using an Ethernet cable is recommended. Change 3D point cloud generation configurations to suite the environment of the recording. For generation configuration explanations/tips, please refer to Generation Configs section in Xplorer guide . Select the preferred recording file and click \"Generate Point Cloud\" to start the point cloud generation. While it is running, you will have the following options: Pause : Pause the generation process (Appears if generation is running) Resume : Resume the generation process (Appears if generation is paused) Cancel : Cancel the generation process Checkpoint : Export the current 3D point cloud to Point Cloud Editor. This is used to back up the generation progress. If problems arise in the future, some good results can still be restored. Once completed, click \"Point Cloud Editor\" to edit the generated 3D point cloud. The name of the new point cloud is the same as the recording file's name. Follow the d.ASH Xplorer guide to edit the point cloud accordingly. Once you are satisfied with the 3D point cloud, click \"Upload\" to upload the point cloud to your d.ASH Fleet Management account in the cloud.","title":"1.4 Data Processing"},{"location":"dash-pack/dash-pack/#tips-for-data-collection","text":"It is recommended to walk in small loops back to previously visited areas for point cloud autocorrection. You will notice some automatic corrections being done during the generation process on d.ASH Xplorer. These corrections are called loop-closures. Good example of a well defined loop: | | Bad example where there is no loop: | { align=center style=\"width:600px\"} | Where the loops/paths criss-cross should have recognisable static/stationary features (e.g. buildings) Good examples of easily recognisable features: | | | | | | Bad examples of features (AKA: Dynamic features): | | | | Tighten the d.ASH Pack straps before recording Move at a steady pace Ensure LiDAR is above your head and do not block the sensor when recording Do not turn quickly in narrow corridors Do not record while in a lift Not recommended to record in narrow stairwells Put on the d.ASH Pack before starting the scan For recording with imaging, please tilt the LiDAR by 30\u00b0, otherwise a horizontal configuration is recommended If on a vehicle, please dismount and walk through bumpy areas Attempting to loop close long corridors (>20m) is discouraged Avoid large empty areas (e.g. fields) when recording as there are a lack of features","title":"Tips for Data Collection"},{"location":"dash-pack/dash-xplorer/","text":"d.ASH Xplorer | | d.ASH Xplorer is the 3D point cloud management application, allowing users to create, edit and export 3D point cloud for various purposes such as for Autonomous Navigation and Digital Twin Applications. d.ASH Xplorer is designed to work with d.ASH Pack and equipped with state-of-the-art SLAM technology for 3D point cloud generation. Users can edit the 3D point cloud by rotating, translating, downsampling, and cleaning up point clouds. 2D maps can also be generated from the 3D point clouds using the built-in grid map generator. The entire point cloud generation workflow is fully integrated with d.ASH Fleet Management to significantly shorten and streamline the preparation process for autonomous navigation. Two versions of d.ASH Xplorer are available. d.ASH Xplorer and d.ASH Xplorer Pro . d.ASH Xplorer Pro is equipped with other add-on features such as the Scan Manager which provides scanning support and automatic stitching of dense 3D point cloud scans. AutoMerge utilises sensor fusion to perform automatic scan alignment and scale-consistent stitching with little human intervention. The AutoMerge system currently supports the Leica BLK360. Other features include uploading of Navigation Maps to the cloud and exporting maps to Revit. Since d.ASH Xplorer is fully integrated with d.ASH Fleet Management system , an internet connection is required. Should you require d.ASH Xplorer without an internet connection, please contact us for more details. Minimum System Requirements PC with a CPU equivalent to or greater than an Intel i5 4 th Gen or AMD R5 2000 series 16GB of RAM Internet Connection Windows 10/11 We recommend using an Nvidia discrete GPU greater than or equivalent to a GTX 960. Some features such as \"HD View\" are disabled on other GPUs. d.ASH Xplorer is built for Windows 10/11. Therefore, please ensure you are running a Discrete Nvidia GPU in High-Performance mode. Otherwise, some functionalities would be unsupported. You can enable this by going into Windows GPU Settings, and adding d.ASH Xplorer as an app and setting the \"Graphics preference\" to \"High performance\". Tutorial | | You can watch the video tutorial to get a quick overview of how to run d.ASH Xplorer above here . Control Scheme d.ASH Xplorer's control scheme is as follows: WASD: Navigate around the point cloud LMB/MB1: Drag mouse to pan around the point cloud RMB/MB2: Drag mouse to zoom in and out MMB/MB3: Drag mouse to navigate around the point cloud E: Move upwards(positive) in the Y-axis Q: Move downwards(negative) in the Y-axis F: Returns view to origin 2.1 Quick Start For a more detailed look at the different features d.ASH Xplorer has to offer, please refer below. This is just a brief overview on how d.ASH Xplorer should be used. Download the .dpack recording from your d.ASH Pack Click on the Generate Point Cloud button Once the map is generated, configure the Post-processing Settings by changing the Post Processing Options dropdown to Nav Map Then click Post Process Navigate to the Point cloud editor Click Upload Nav Map [d.ASH Xplorer Pro only] The generated recording can now be used for robot autonomous navigation with d.ASH Fleet Management system . 2.2 Modes d.ASH Xplorer has 2 main modes for various tasks: Point Cloud Editor : Perform 3D point cloud edits, exports and uploads. | | d.ASH Pack Manager : Control d.ASH Pack and generate 3D point clouds and 2D maps. | | d.ASH Xplorer Pro also includes: Scan Manager : Download point cloud data and perform AutoMerge on 3 rd party 3D scanners. | | These 3 modes form 3 different tabs at the top of d.ASH Xplorer. 2.3 Point Cloud Editor The point cloud editor is used to manage different point clouds that users have generated. Users can rotate, translate, downsample and perform other 3D point cloud editing features. You can use this mode to visualize the 3D point cloud by using the Load button. File extensions \".pcd\", \".obj\", \".las\" and \".e57\" are currently supported. We also have our own proprietary file extension \".dcloud\" which can be used to load point clouds. We do not recommend exporting large point clouds (> 1gb in size) in the .pcd format. Please export such files in .las, .e57 or .dcloud instead. | | After loading, your 3D objects will appear in the list under Point Cloud Collections . You can hide or show a point cloud object by clicking the green eye icon. | | The Remove button simply removes the 3D object from the list. However, it does not delete the file from the PC. | | The Rename button renames the selected 3D object name. | | The Export Nav Map button exports not just the selected 3D object, but the 3D object's 2D Grid Map and Configuration files for navigation, to a destination of your choice. When clicked, a file dialogue will pop up for you to choose the save folder destination. 3 different files will be saved. They are the 3D point cloud (.pcd), 2D map (.png), and map configuration (.json). | | The Export button exports the selected 3D object to a destination of your choice. When clicked, a file dialogue will pop up for you to choose the save folder destination. | | The HD View button allows for high-resolution views of the full point cloud data including moving and rotating the point cloud in real-time at high frame rates while also being in full colour. An Nvidia discrete gpu with CUDA capabilities is required. | | The Flip Colour button flips the colours of points in the point cloud from RGB to BGR and vice versa, this may help resolve issues with colours not appearing properly or correctly on your point cloud. | | The following options are locked to d.ASH Xplorer Pro ** The Upload Nav Map button uploads the 3D map to the d.ASH Cloud Fleet Management System . If a map with the same name is found in the cloud, a warning will pop up and ask the user to either overwrite the existing file or cancel the uploading operation. Once uploaded, users can access or download the map from the cloud. | | The Export to Revit button exports the selected 3D object for use with Revit. | | The Multi Point Cloud Processor allows users to - align different point clouds through geometry. This is useful for stitching scans of different parts of an area together. - merge the point clouds into a single, final point cloud - compare between different point clouds. There are a few different options for comparing point clouds. To process the point clouds, just select the point clouds you want to process and options to Align , Merge and Compare will appear. A checkbox for the Swap Alignment Indices property will appear as well. | | Swap Alignment Indices means when alignment is done, the target and source points are swapped (i.e. instead of point A trying to match against point B, point B tries to match against point A) [Default: Unchecked] Aligning point clouds Point clouds taken/generated can be aligned and made to match one another in d.ASH Xplorer. This can aid in comparing and merging of the point clouds. In order to align the point clouds, just click the Align button and d.ASH Xplorer will auto align the point clouds for you. | | Merging point clouds Point clouds taken/generated can be merged into one point cloud in d.ASH Xplorer. Please ensure the point clouds are aligned first, as merging without aligning can lead to very undesirable results . To merge the point clouds, just click the Merge button. | | Comparing point clouds Point clouds taken/generated can be compared against one another. Please ensure the point clouds are aligned first, as comparing without aligning can lead to very undesirable results . To compare the point clouds, click the Compare button. | | The following comparison settings are shown after clicking Compare : - Comparison Resolution (m): Points will be grouped into a voxel the size of the value set. This will be used to compare the point clouds voxel by voxel. [Default: 0.8] - Align Before Comparison: Aligns the point clouds before comparison takes place [Default: Unchecked] | | Point clouds can be compared with three different measurements which are: - Points added: Comparing point cloud 1 and 2, what are the points added between the two point clouds. This is visualised in green points. - Points removed: Comparing point cloud 1 and 2, which points are removed between the two point clouds. This is visualised in red points. - Points unchanged: Comparing point cloud 1 and 2, what are points which are the same/retained between the two point clouds. This is visualised in blue points. You can enable or disable the different views by clicking on the checkboxes. | | 2.4 Point Cloud Transformation This feature allows users to edit the point cloud. Users can perform translation and rotation by using XYZ and quaternion values respectively. There are options for users to reset the transformations back to the original state. In addition, a widget in the centre of the screen, which only appears when the tab is open, is designed to facilitate point cloud transformation. Users can click on the widget and see a live transformation of the 3D object. To toggle between translation and rotation modes of the widget, users can choose the right mode under \"Edit Mode\". | | Users can perform downsampling from the same dropdown menu and have the ability to set their desired voxel grid size. The values are in Metres. Therefore, a voxel size of 0.2 for downsampling would mean that for every 0.2M HxWxB Cube, all points are removed except for one. Reset to Original resets the 3D point cloud to the original number of points. | | 2.5 Point Cloud Cleaner The Point Cloud Cleaner helps to remove outliers and smoothen the point cloud to make it cleaner. An explanation of the available options is located below the image. | | Point cloud Denoiser Denoise Quality : Depending on your system, Rough could still take a few minutes to half an hour. This setting controls the number of iterations the algorithm will run. Refined therefore means the denoise will be more accurate as more iterations of the algorithm will be ran. [Default: Rough] Denoise Aggressiveness : The denoiser tries to both remove points and also move points to make the point cloud less noisy. The higher this is set, more points will be removed. [Default: Medium] Chunk Size (m) : The point cloud is split into chunks of equal size for denoising. This controls the size of each chunk. For users with less ram, it is recommended to keep to the default or lower the Chunk Size to prevent crashes and other instabilities. [Default: 50.0] Uniform Sampling : Tries to accentuate surfaces perceived on the point cloud, turn this setting off if shapes are being distorted on the point cloud. [Default: Unchecked] The options listed below are for advanced users, please use them at your own discretion. Statistical Outlier Removal: K-Mean (Number of Neighbours) : For each point, its surrounding points will be used to calculate the standard deviation in distance between points. A higher value means more surrounding points will be considered. [Default: 50] Standard Deviation : A measure of the variation between points. A higher deviation means that points further away from each other will be kept. [Default 2.00] Point Cloud Smoother: Radius (m) : The searching radius per point. The higher the radius, the more time the denoising will take, but the denoising output will be better. [Default 0.50] Epsilon (Smoothness) : The larger the value, the smoother the output will look. [Default 0.20] Point cloud Resampling: Polynomial Order : The higher the number, the sharper the edge the denoising can preserve. [Default: 3] Search Radius : Look through all points within the search radius and perform polynomial fitting of the order specified above. [Default: 0.05] | | 2.6 3D Point Cloud Cropper This feature helps users clean up point clouds by cropping them down to a desired section/size. An explanation of the available options are below the image | | Visualise Cropping Bounds : Draws the cropping bounds on the preview, allowing users to better see the area remaining after cropping. [Default: Unchecked] Range X,Y,Z : The cropping ranges, adjust these values to adjust the area remaining after cropping. [Default: -10.000, 10.000] Auto Set Crop Ranges : d.ASH Xplorer will auto set the crop ranges based on the 3D point cloud. Crop Point Cloud : Crops the point cloud according to the specified ranges set above. Reset Crop : Resets any crop operations, restoring the original point cloud. 2.7 2D Map Generator This feature creates a 2D map from a 3D point cloud by projecting a section of the 3D point cloud to an image file. Users can generate the 2D view from either a top view perspective or side view perspective . Users have 3 different configuration options: min height, max height, and pixel resolution (meter/pixel). To see which region is used for compression, users can check Show Height-Bounds to display the minimum and maximum height planes. | | Once satisfied, click Generate to apply the configurations and view the 2D map. | | Users can choose to Save 2D Map separately if needed. It is recommended to ensure that the free space is correctly represented because this information will be used for automatic path-planning and visualization on the website. However, if you do not intend to use d.ASH automatic path-planning, getting a clear 2D map for visualization is sufficient. 2.8 d.ASH Pack Manager This mode allows users to start/stop d.ASH Pack recordings, download d.ASH Pack recordings and generate 3D point clouds through the d.ASH Pack Manager window. Users can only start/stop d.ASH Pack recordings and download d.ASH Pack recording files when d.ASH Xplorer detects that there are online d.ASH Packs. Otherwise, \"No online d.ASH Pack found\" will be shown. | | If there is an online d.ASH Pack, the d.ASH Pack name will pop up on the list of online d.ASH Pack. Click on it to select the d.ASH Pack device. 2.9 d.ASH Pack Control This section allow users to start/stop d.ASH Pack recordings. Log in to d.ASH Xplorer If offline, connect to d.ASH Pack Wi-Fi Navigate to the d.ASH Pack Manager Before starting the recording, ensure d.ASH Pack is powered on and is emitting a Green light from the status LED, this represents that d.ASH Pack is ready to be used for recording. In d.ASH Xplorer, key in the d.ASH Pack recording name and specify if images should be captured. Images provide colour to the final generated 3D point cloud click the Start button. To monitor the recording status, in d.ASH Xplorer, the d.ASH Pack status will reflect Recording . On the d.ASH Pack itself, the status light will flash Yellow . To stop, click the Stop button. Note that the user can also force stop via pressing the power button, however, only do this as a last resort on the off chance that the stop button isn't functioning. 2.10 Download d.ASH Pack Recordings After clicking on the list of d.ASH Pack, perform the following steps to download the recording: | Select the desired d.ASH Pack recording file from the recording list. | If there is an ethernet connection between the PC running d.ASH Xplorer and d.ASH Pack, users will have options to download either wirelessly or via ethernet. It is recommended to download via ethernet for faster downloading speed. | Click Download to start downloading. Once it is completed, the downloaded file will appear in the Downloaded d.ASH Pack Recordings list ready for 3D point cloud generation. | | 2.11 3D Point Cloud Generation After downloading the d.ASH Pack recording, you can then generate the 3D point cloud for that particular recording. Under Point Cloud Generation Configs , users can choose different settings for the 3D point cloud generation. For details on the configuration, please refer to the next section | | Select d.ASH Pack recording by clicking on the recording name under the Downloaded d.ASH Pack Recordings list. | | Click Generate Point Cloud to start the 3D point cloud generation. You will see the 3D point cloud being generated progressively on the screen. A green line appearing on the screen represents the path taken during the recording process. While the 3D point cloud is being generated, users will have the following options: | | Pause : Pause the generation process (Appears if generation is running) Resume : Resume the generation process (Appears if generation is paused) Cancel : Cancel the generation process Checkpoint : Export the current 3D point cloud to the Point Cloud Editor. This is used to back up the 3D point cloud in case there are problems later on. 5. When generation is completed, the completed point cloud will need to undergo post-processing so the generated point cloud can be used for specific purposes such as for autonomous navigation or to include colour data The point cloud will now be automatically added to the point cloud list under Point Cloud Editor for other purposes such as editing and uploading. Post Processing By clicking on the drop-down menu, the following options to add post-processing effects are shown. Nav Map : autonomous robot navigation map. Colour Nav Map : autonomous robot navigation with colour. Sparse Coloured Map : coloured point cloud with as few points as possible. Dense Coloured Map : coloured point cloud with many points. downsampling reduces the number of points in the final point cloud while maintaining the original structure of the point cloud. Grid size for downsampling influences the resolution of the downsampled point cloud | | Point Cloud Generation Configs To ensure desirable generation quality, users may have to edit the default settings to suit their requirements. To reset the settings back to default, click the reset button. Users have the following options: Start/Stop Time(%) : Users can perform 3D point cloud generation for a part of the d.ASH Pack recording by specifying the start and stop time in percentage (from 0-100%) [Default: 0-100%] Number of Threads : Users can manually set the number of threads d.ASH Xplorer can use. The higher the number, the faster the point cloud generation will be. A higher number of threads used for d.ASH Xplorer may cause other system processes to become more laggy. [Default: Depends on numbers of cores on client system] Loop-Closure Similarity Score : The lower this value, the more stringent loop closure will be when finding similar points. Increase this value in 0.10 intervals. [Default: 0.30] Save Point Cloud When Done : When checked, the 3D point cloud will be automatically exported to the Point Cloud Editor when the generation has completed. [Default: Unchecked] Auto-Pause : Point Cloud Generation will be automatically paused when a huge change in position is detected. This is useful for backing up the currently generated data in case of generation failure. [Default: Unchecked] The Max Point Cloud Range per Scan (m) is the distance from the origin where points will be considered and added to the final, post-processed point cloud. Please increase the value when in wider areas such as when post processing outdoor areas. We recommend a minimum of 30.0 for outside areas. [Default: 10.0] | | The Dynamic Point Removal checkbox allows for removal of unwanted objects from the final point cloud (e.g. pedestrians walking past, cars, pets etc) [Default: Unchecked] Use GPU for Inference is essentially hardware acceleration for Dynamic Point Removal . We recommend turning this on. An Nvidia GPU with CUDA is required. [Default: Unchecked] Set Dilate Kernel Size The higher/larger this value, the more points surrounding the moving object/object to be removed, will be removed. [Default: Medium] | | Advanced Generation Configurations The options listed below are for advanced users, please use them at your own discretion. Loop Closure Search Radius (m) : Used for automatic Loop Closure detection. Scan points within this radius are considered for Loop Closure. [Default: 20.0] Loop Closure Minimum Time Difference (s) : A certain amount of time must pass before points can be considered for Loop Closure. This is to prevent consecutive poses from being used as Loop Closure candidates. [Default: 10.000] Loop Closure Sub-Map Search Number : When a loop closure is found, this value will control the number of neighbouring LiDAR scans from each candidate pose which are concatenated together for the purpose of performing scan matching. [Default: 25] Scan-matching Sub-map Search Radius (m) : During scan to map matching, this value controls the neighbouring distance from the current pose in which scan matching is done. [Default: 20.000] Minimum Keyframe Distance Difference (m) : This value controls the minimum distance between each LiDAR scan which is used for mapping. [Default: 0.50] Minimum Keyframe Angle Difference (rad.) : This value controls the minimum angular displacement between each LiDAR scan which is used for mapping. [Default: 0.10] Fast Mode : Uses multiple threads to run map generation. This will be faster than using a single thread but may result in a lower quality map, especially in complex areas with little features such as buildings. [Default: unchecked] Scan Context Loop Closure : Advanced Loop Closure algorithm. Checking this will result in more scan posititions being considered for loop closure, thus generating a higher quality map. [Default: unchecked] What is Manual Loop Closure Detection? In the event that 3D Point Cloud Generation is unable to detect loop closures (a pair of scan points with similar locations) at certain areas of a point cloud, you can perform Manual Loop Closure Detection to stitch these parts of the point cloud together. Manual Loop Closure Detection works by trying to pair every point selected with each other in all permutations possible. During point cloud generation, if Loop Closures are not detected, pause the generation and perform Manual Loop Closure Detection by following the steps below. Example of a map which requires Manual Loop Closure Detection : | | What the area should be like: | | Select a few pairs of points for Manual Loop Closure Detection . Selected points that should be linked together. An example of this is shown below. | | If you selected the wrong pair of points, highlight the wrong pairs and click the Remove Keyframes button | | Select all remaining pairs and click Optimize and wait for the algorithm to match the points together. | | If no loop closures are able to be detected, increase the similarity score, then attempt optimisation again. | | If needed, continue with manual loop closure detection on other parts of the point cloud. *Final loop close | | Manual Loop Closure Detection Settings - Add Neighbour Keyframes: Also adds keyframes beside the selected keyframe. The number of keyframes added is determined by the Neighbour Size value. [Default: Checked] - Neighbour Size: The number of neighbour keyframes. [Default: 5] - Similarity Score: The lower this value, the more stringent loop closure will be when finding similar points. Increase this value in 0.10 intervals. [Default: 0.30] These values are only for manual loop closure, automatic loop closure configurations are listed above. Tips If the Manual Loop Closure Detection fails, users may want to lower the Loop Closure Similarity Score value based on the pop-up. Ensure that there are not too many large point clouds in d.ASH Xplorer's point cloud manager. These are loaded into RAM and can cause instability when too many of such point clouds are loaded. If you are confident that selected points are at the same location but the Loop Closure algorithm has failed to find similarities, please adjust the Loop Closure Similarity Score to a higher value. Once some loop closures are detected, you may observe some adjustments in the generated point cloud. You can then lower the score and perform Loop Closure again on different points to progressively correct the generated point cloud. Scan Manager (Plugin) This plugin allows users to manage 3 rd -party 3D scanners. Currently, the Leica BLK360 scanner is supported. This is currently limited to users of d.ASH Xplorer Pro . This plugin is used to perform the following: Download scanMeta files from the robot Download scan data from the scanner Perform AutoMerge on all scans. Download ScanMeta Files scanMeta file ( *.scanMeta ) holds critical information for each scan point. Each 3D scan activated by the d.ASH robotics stack will generate a scanMeta file. The scanMeta data can be used to perform AutoMerge for creating a digital twin (high accuracy/density 3D point cloud model). scanMeta files are grouped by their project names which are set by d.ASH Autonomy Mission. To download the scanMeta files, perform the following: Connect your PC running d.ASH Xplorer Pro to the Internet and make sure that the robot is online Log in to d.ASH Xplorer Pro , then connect to the server. Click on the robot from the Online Robot List in the Scan Manager tab. Select the desired data folder by clicking the Folder icon . This folder will be used to store downloaded scanMeta files. We recommend choosing an empty folder. Otherwise, scanMeta files from previous/other projects will be overwritten. Click on Download Files to expand the window. | | Click Download to download ScanMeta files for the entire project. | | After downloading, all ScanMeta files will be stored in the folder selected in Step 3. Download 3D Scan Data from the Scanner This step performs downloading of 3D scan data from the 3D scanner by using the downloaded ScanMeta files. Connect your PC running d.ASH Xplorer Pro to the 3D scanner. Select the desired data folder by clicking the Folder icon . This folder should have ScanMeta files. Click on Download Files to expand the window. Under \"Download scan data from scanner\", click Download There will be a window popup showing all ScanMeta filenames found in the folder selected in Step 2. If 3D scan files and ScanMeta files with the same name exist, the filename will have \"[Downloaded]\" appended at the back of their names. Use the checkboxes on the left to mark 3D scan data for downloading. Users can use Select All or Unselect All buttons for file selections. | | Click Download to start the 3D scan downloading process. Once completed, Click Close to close the popup. AutoMerge This step performs AutoMerge on the 3D Scan data. AutoMerge utilizes sensor fusion techniques to automatically stitch and align multiple 3D scans for scale-consistent digital twin reconstruction. AutoMerge supports both colored and non-colored point clouds. To perform AutoMerge, perform the following steps: Select the desired data folder by clicking Change . This folder should have both ScanMeta files and 3D scan data files. Click on AutoMerge to expand the window. AutoMerge Scan File List displays a list of files in the selected folder for AutoMerge. Only filenames with .scanMeta and .pcd are considered for AutoMerge. Since AutoMerge relies on the orientation of the 3D scanner to perform stitching, users are encouraged to preview some scans first. This is done by selecting a few scans (greater than two) and clicking Preview . After scan previews have loaded, expand Options and change the Scanner Rotation so that the selected scans are roughly aligned. These rotations will rotate the 3D scan about their centres. As the scanner rotation is changed, the 3D scan previews will also be rotated accordingly. Users do not have to perfectly align the 3D scans manually. Just a rough estimate is sufficient. After configuring the scanner rotation, users can start AutoMerge. Click AutoMerge to start the AutoMerge process on the selected files (greater than one). You will see the 3D scans popping up and aligning themselves automatically after some time. When AutoMerge has completed, users have the following options: Export : Save the AutoMerge results and individual scans with corrected poses. Users can choose to export as .pcd , .dcloud , .las , or .e57 file formats. Edit : Export the AutoMerge results to Map Editor for editing. Options There are 3 different options available for Scan Manager: Scanner Rotation : Rotation in degrees of the scanner relative to the robot heading. As this value is changed, the 3D scan preview will also be updated in real-time. Optimize Visualization : Check this to optimize rendering. Check this if you notice a laggy visualization. Auto save AutoMerge results : Automatically save AutoMerge results to the data folder once AutoMerge has completed.","title":"2.0 d.ASH Xplorer"},{"location":"dash-pack/dash-xplorer/#dash-xplorer","text":"| | d.ASH Xplorer is the 3D point cloud management application, allowing users to create, edit and export 3D point cloud for various purposes such as for Autonomous Navigation and Digital Twin Applications. d.ASH Xplorer is designed to work with d.ASH Pack and equipped with state-of-the-art SLAM technology for 3D point cloud generation. Users can edit the 3D point cloud by rotating, translating, downsampling, and cleaning up point clouds. 2D maps can also be generated from the 3D point clouds using the built-in grid map generator. The entire point cloud generation workflow is fully integrated with d.ASH Fleet Management to significantly shorten and streamline the preparation process for autonomous navigation. Two versions of d.ASH Xplorer are available. d.ASH Xplorer and d.ASH Xplorer Pro . d.ASH Xplorer Pro is equipped with other add-on features such as the Scan Manager which provides scanning support and automatic stitching of dense 3D point cloud scans. AutoMerge utilises sensor fusion to perform automatic scan alignment and scale-consistent stitching with little human intervention. The AutoMerge system currently supports the Leica BLK360. Other features include uploading of Navigation Maps to the cloud and exporting maps to Revit. Since d.ASH Xplorer is fully integrated with d.ASH Fleet Management system , an internet connection is required. Should you require d.ASH Xplorer without an internet connection, please contact us for more details.","title":"d.ASH Xplorer"},{"location":"dash-pack/dash-xplorer/#minimum-system-requirements","text":"PC with a CPU equivalent to or greater than an Intel i5 4 th Gen or AMD R5 2000 series 16GB of RAM Internet Connection Windows 10/11 We recommend using an Nvidia discrete GPU greater than or equivalent to a GTX 960. Some features such as \"HD View\" are disabled on other GPUs. d.ASH Xplorer is built for Windows 10/11. Therefore, please ensure you are running a Discrete Nvidia GPU in High-Performance mode. Otherwise, some functionalities would be unsupported. You can enable this by going into Windows GPU Settings, and adding d.ASH Xplorer as an app and setting the \"Graphics preference\" to \"High performance\".","title":"Minimum System Requirements"},{"location":"dash-pack/dash-xplorer/#tutorial","text":"| | You can watch the video tutorial to get a quick overview of how to run d.ASH Xplorer above here . Control Scheme d.ASH Xplorer's control scheme is as follows: WASD: Navigate around the point cloud LMB/MB1: Drag mouse to pan around the point cloud RMB/MB2: Drag mouse to zoom in and out MMB/MB3: Drag mouse to navigate around the point cloud E: Move upwards(positive) in the Y-axis Q: Move downwards(negative) in the Y-axis F: Returns view to origin","title":"Tutorial"},{"location":"dash-pack/dash-xplorer/#21-quick-start","text":"For a more detailed look at the different features d.ASH Xplorer has to offer, please refer below. This is just a brief overview on how d.ASH Xplorer should be used. Download the .dpack recording from your d.ASH Pack Click on the Generate Point Cloud button Once the map is generated, configure the Post-processing Settings by changing the Post Processing Options dropdown to Nav Map Then click Post Process Navigate to the Point cloud editor Click Upload Nav Map [d.ASH Xplorer Pro only] The generated recording can now be used for robot autonomous navigation with d.ASH Fleet Management system .","title":"2.1 Quick Start"},{"location":"dash-pack/dash-xplorer/#22-modes","text":"d.ASH Xplorer has 2 main modes for various tasks: Point Cloud Editor : Perform 3D point cloud edits, exports and uploads. | | d.ASH Pack Manager : Control d.ASH Pack and generate 3D point clouds and 2D maps. | | d.ASH Xplorer Pro also includes: Scan Manager : Download point cloud data and perform AutoMerge on 3 rd party 3D scanners. | | These 3 modes form 3 different tabs at the top of d.ASH Xplorer.","title":"2.2 Modes"},{"location":"dash-pack/dash-xplorer/#23-point-cloud-editor","text":"The point cloud editor is used to manage different point clouds that users have generated. Users can rotate, translate, downsample and perform other 3D point cloud editing features. You can use this mode to visualize the 3D point cloud by using the Load button. File extensions \".pcd\", \".obj\", \".las\" and \".e57\" are currently supported. We also have our own proprietary file extension \".dcloud\" which can be used to load point clouds. We do not recommend exporting large point clouds (> 1gb in size) in the .pcd format. Please export such files in .las, .e57 or .dcloud instead. | | After loading, your 3D objects will appear in the list under Point Cloud Collections . You can hide or show a point cloud object by clicking the green eye icon. | | The Remove button simply removes the 3D object from the list. However, it does not delete the file from the PC. | | The Rename button renames the selected 3D object name. | | The Export Nav Map button exports not just the selected 3D object, but the 3D object's 2D Grid Map and Configuration files for navigation, to a destination of your choice. When clicked, a file dialogue will pop up for you to choose the save folder destination. 3 different files will be saved. They are the 3D point cloud (.pcd), 2D map (.png), and map configuration (.json). | | The Export button exports the selected 3D object to a destination of your choice. When clicked, a file dialogue will pop up for you to choose the save folder destination. | | The HD View button allows for high-resolution views of the full point cloud data including moving and rotating the point cloud in real-time at high frame rates while also being in full colour. An Nvidia discrete gpu with CUDA capabilities is required. | | The Flip Colour button flips the colours of points in the point cloud from RGB to BGR and vice versa, this may help resolve issues with colours not appearing properly or correctly on your point cloud. | | The following options are locked to d.ASH Xplorer Pro ** The Upload Nav Map button uploads the 3D map to the d.ASH Cloud Fleet Management System . If a map with the same name is found in the cloud, a warning will pop up and ask the user to either overwrite the existing file or cancel the uploading operation. Once uploaded, users can access or download the map from the cloud. | | The Export to Revit button exports the selected 3D object for use with Revit. | | The Multi Point Cloud Processor allows users to - align different point clouds through geometry. This is useful for stitching scans of different parts of an area together. - merge the point clouds into a single, final point cloud - compare between different point clouds. There are a few different options for comparing point clouds. To process the point clouds, just select the point clouds you want to process and options to Align , Merge and Compare will appear. A checkbox for the Swap Alignment Indices property will appear as well. | | Swap Alignment Indices means when alignment is done, the target and source points are swapped (i.e. instead of point A trying to match against point B, point B tries to match against point A) [Default: Unchecked] Aligning point clouds Point clouds taken/generated can be aligned and made to match one another in d.ASH Xplorer. This can aid in comparing and merging of the point clouds. In order to align the point clouds, just click the Align button and d.ASH Xplorer will auto align the point clouds for you. | | Merging point clouds Point clouds taken/generated can be merged into one point cloud in d.ASH Xplorer. Please ensure the point clouds are aligned first, as merging without aligning can lead to very undesirable results . To merge the point clouds, just click the Merge button. | | Comparing point clouds Point clouds taken/generated can be compared against one another. Please ensure the point clouds are aligned first, as comparing without aligning can lead to very undesirable results . To compare the point clouds, click the Compare button. | | The following comparison settings are shown after clicking Compare : - Comparison Resolution (m): Points will be grouped into a voxel the size of the value set. This will be used to compare the point clouds voxel by voxel. [Default: 0.8] - Align Before Comparison: Aligns the point clouds before comparison takes place [Default: Unchecked] | | Point clouds can be compared with three different measurements which are: - Points added: Comparing point cloud 1 and 2, what are the points added between the two point clouds. This is visualised in green points. - Points removed: Comparing point cloud 1 and 2, which points are removed between the two point clouds. This is visualised in red points. - Points unchanged: Comparing point cloud 1 and 2, what are points which are the same/retained between the two point clouds. This is visualised in blue points. You can enable or disable the different views by clicking on the checkboxes. | |","title":"2.3 Point Cloud Editor"},{"location":"dash-pack/dash-xplorer/#24-point-cloud-transformation","text":"This feature allows users to edit the point cloud. Users can perform translation and rotation by using XYZ and quaternion values respectively. There are options for users to reset the transformations back to the original state. In addition, a widget in the centre of the screen, which only appears when the tab is open, is designed to facilitate point cloud transformation. Users can click on the widget and see a live transformation of the 3D object. To toggle between translation and rotation modes of the widget, users can choose the right mode under \"Edit Mode\". | | Users can perform downsampling from the same dropdown menu and have the ability to set their desired voxel grid size. The values are in Metres. Therefore, a voxel size of 0.2 for downsampling would mean that for every 0.2M HxWxB Cube, all points are removed except for one. Reset to Original resets the 3D point cloud to the original number of points. | |","title":"2.4 Point Cloud Transformation"},{"location":"dash-pack/dash-xplorer/#25-point-cloud-cleaner","text":"The Point Cloud Cleaner helps to remove outliers and smoothen the point cloud to make it cleaner. An explanation of the available options is located below the image. | | Point cloud Denoiser Denoise Quality : Depending on your system, Rough could still take a few minutes to half an hour. This setting controls the number of iterations the algorithm will run. Refined therefore means the denoise will be more accurate as more iterations of the algorithm will be ran. [Default: Rough] Denoise Aggressiveness : The denoiser tries to both remove points and also move points to make the point cloud less noisy. The higher this is set, more points will be removed. [Default: Medium] Chunk Size (m) : The point cloud is split into chunks of equal size for denoising. This controls the size of each chunk. For users with less ram, it is recommended to keep to the default or lower the Chunk Size to prevent crashes and other instabilities. [Default: 50.0] Uniform Sampling : Tries to accentuate surfaces perceived on the point cloud, turn this setting off if shapes are being distorted on the point cloud. [Default: Unchecked] The options listed below are for advanced users, please use them at your own discretion. Statistical Outlier Removal: K-Mean (Number of Neighbours) : For each point, its surrounding points will be used to calculate the standard deviation in distance between points. A higher value means more surrounding points will be considered. [Default: 50] Standard Deviation : A measure of the variation between points. A higher deviation means that points further away from each other will be kept. [Default 2.00] Point Cloud Smoother: Radius (m) : The searching radius per point. The higher the radius, the more time the denoising will take, but the denoising output will be better. [Default 0.50] Epsilon (Smoothness) : The larger the value, the smoother the output will look. [Default 0.20] Point cloud Resampling: Polynomial Order : The higher the number, the sharper the edge the denoising can preserve. [Default: 3] Search Radius : Look through all points within the search radius and perform polynomial fitting of the order specified above. [Default: 0.05] | |","title":"2.5 Point Cloud Cleaner"},{"location":"dash-pack/dash-xplorer/#26-3d-point-cloud-cropper","text":"This feature helps users clean up point clouds by cropping them down to a desired section/size. An explanation of the available options are below the image | | Visualise Cropping Bounds : Draws the cropping bounds on the preview, allowing users to better see the area remaining after cropping. [Default: Unchecked] Range X,Y,Z : The cropping ranges, adjust these values to adjust the area remaining after cropping. [Default: -10.000, 10.000] Auto Set Crop Ranges : d.ASH Xplorer will auto set the crop ranges based on the 3D point cloud. Crop Point Cloud : Crops the point cloud according to the specified ranges set above. Reset Crop : Resets any crop operations, restoring the original point cloud.","title":"2.6 3D Point Cloud Cropper"},{"location":"dash-pack/dash-xplorer/#27-2d-map-generator","text":"This feature creates a 2D map from a 3D point cloud by projecting a section of the 3D point cloud to an image file. Users can generate the 2D view from either a top view perspective or side view perspective . Users have 3 different configuration options: min height, max height, and pixel resolution (meter/pixel). To see which region is used for compression, users can check Show Height-Bounds to display the minimum and maximum height planes. | | Once satisfied, click Generate to apply the configurations and view the 2D map. | | Users can choose to Save 2D Map separately if needed. It is recommended to ensure that the free space is correctly represented because this information will be used for automatic path-planning and visualization on the website. However, if you do not intend to use d.ASH automatic path-planning, getting a clear 2D map for visualization is sufficient.","title":"2.7 2D Map Generator"},{"location":"dash-pack/dash-xplorer/#28-dash-pack-manager","text":"This mode allows users to start/stop d.ASH Pack recordings, download d.ASH Pack recordings and generate 3D point clouds through the d.ASH Pack Manager window. Users can only start/stop d.ASH Pack recordings and download d.ASH Pack recording files when d.ASH Xplorer detects that there are online d.ASH Packs. Otherwise, \"No online d.ASH Pack found\" will be shown. | | If there is an online d.ASH Pack, the d.ASH Pack name will pop up on the list of online d.ASH Pack. Click on it to select the d.ASH Pack device.","title":"2.8 d.ASH Pack Manager"},{"location":"dash-pack/dash-xplorer/#29-dash-pack-control","text":"This section allow users to start/stop d.ASH Pack recordings. Log in to d.ASH Xplorer If offline, connect to d.ASH Pack Wi-Fi Navigate to the d.ASH Pack Manager Before starting the recording, ensure d.ASH Pack is powered on and is emitting a Green light from the status LED, this represents that d.ASH Pack is ready to be used for recording. In d.ASH Xplorer, key in the d.ASH Pack recording name and specify if images should be captured. Images provide colour to the final generated 3D point cloud click the Start button. To monitor the recording status, in d.ASH Xplorer, the d.ASH Pack status will reflect Recording . On the d.ASH Pack itself, the status light will flash Yellow . To stop, click the Stop button. Note that the user can also force stop via pressing the power button, however, only do this as a last resort on the off chance that the stop button isn't functioning.","title":"2.9 d.ASH Pack Control"},{"location":"dash-pack/dash-xplorer/#210-download-dash-pack-recordings","text":"After clicking on the list of d.ASH Pack, perform the following steps to download the recording: | Select the desired d.ASH Pack recording file from the recording list. | If there is an ethernet connection between the PC running d.ASH Xplorer and d.ASH Pack, users will have options to download either wirelessly or via ethernet. It is recommended to download via ethernet for faster downloading speed. | Click Download to start downloading. Once it is completed, the downloaded file will appear in the Downloaded d.ASH Pack Recordings list ready for 3D point cloud generation. | |","title":"2.10 Download d.ASH Pack Recordings"},{"location":"dash-pack/dash-xplorer/#211-3d-point-cloud-generation","text":"After downloading the d.ASH Pack recording, you can then generate the 3D point cloud for that particular recording. Under Point Cloud Generation Configs , users can choose different settings for the 3D point cloud generation. For details on the configuration, please refer to the next section | | Select d.ASH Pack recording by clicking on the recording name under the Downloaded d.ASH Pack Recordings list. | | Click Generate Point Cloud to start the 3D point cloud generation. You will see the 3D point cloud being generated progressively on the screen. A green line appearing on the screen represents the path taken during the recording process. While the 3D point cloud is being generated, users will have the following options: | | Pause : Pause the generation process (Appears if generation is running) Resume : Resume the generation process (Appears if generation is paused) Cancel : Cancel the generation process Checkpoint : Export the current 3D point cloud to the Point Cloud Editor. This is used to back up the 3D point cloud in case there are problems later on. 5. When generation is completed, the completed point cloud will need to undergo post-processing so the generated point cloud can be used for specific purposes such as for autonomous navigation or to include colour data The point cloud will now be automatically added to the point cloud list under Point Cloud Editor for other purposes such as editing and uploading.","title":"2.11 3D Point Cloud Generation"},{"location":"dash-pack/dash-xplorer/#post-processing","text":"By clicking on the drop-down menu, the following options to add post-processing effects are shown. Nav Map : autonomous robot navigation map. Colour Nav Map : autonomous robot navigation with colour. Sparse Coloured Map : coloured point cloud with as few points as possible. Dense Coloured Map : coloured point cloud with many points. downsampling reduces the number of points in the final point cloud while maintaining the original structure of the point cloud. Grid size for downsampling influences the resolution of the downsampled point cloud | |","title":"Post Processing"},{"location":"dash-pack/dash-xplorer/#point-cloud-generation-configs","text":"To ensure desirable generation quality, users may have to edit the default settings to suit their requirements. To reset the settings back to default, click the reset button. Users have the following options: Start/Stop Time(%) : Users can perform 3D point cloud generation for a part of the d.ASH Pack recording by specifying the start and stop time in percentage (from 0-100%) [Default: 0-100%] Number of Threads : Users can manually set the number of threads d.ASH Xplorer can use. The higher the number, the faster the point cloud generation will be. A higher number of threads used for d.ASH Xplorer may cause other system processes to become more laggy. [Default: Depends on numbers of cores on client system] Loop-Closure Similarity Score : The lower this value, the more stringent loop closure will be when finding similar points. Increase this value in 0.10 intervals. [Default: 0.30] Save Point Cloud When Done : When checked, the 3D point cloud will be automatically exported to the Point Cloud Editor when the generation has completed. [Default: Unchecked] Auto-Pause : Point Cloud Generation will be automatically paused when a huge change in position is detected. This is useful for backing up the currently generated data in case of generation failure. [Default: Unchecked] The Max Point Cloud Range per Scan (m) is the distance from the origin where points will be considered and added to the final, post-processed point cloud. Please increase the value when in wider areas such as when post processing outdoor areas. We recommend a minimum of 30.0 for outside areas. [Default: 10.0] | | The Dynamic Point Removal checkbox allows for removal of unwanted objects from the final point cloud (e.g. pedestrians walking past, cars, pets etc) [Default: Unchecked] Use GPU for Inference is essentially hardware acceleration for Dynamic Point Removal . We recommend turning this on. An Nvidia GPU with CUDA is required. [Default: Unchecked] Set Dilate Kernel Size The higher/larger this value, the more points surrounding the moving object/object to be removed, will be removed. [Default: Medium] | | Advanced Generation Configurations The options listed below are for advanced users, please use them at your own discretion. Loop Closure Search Radius (m) : Used for automatic Loop Closure detection. Scan points within this radius are considered for Loop Closure. [Default: 20.0] Loop Closure Minimum Time Difference (s) : A certain amount of time must pass before points can be considered for Loop Closure. This is to prevent consecutive poses from being used as Loop Closure candidates. [Default: 10.000] Loop Closure Sub-Map Search Number : When a loop closure is found, this value will control the number of neighbouring LiDAR scans from each candidate pose which are concatenated together for the purpose of performing scan matching. [Default: 25] Scan-matching Sub-map Search Radius (m) : During scan to map matching, this value controls the neighbouring distance from the current pose in which scan matching is done. [Default: 20.000] Minimum Keyframe Distance Difference (m) : This value controls the minimum distance between each LiDAR scan which is used for mapping. [Default: 0.50] Minimum Keyframe Angle Difference (rad.) : This value controls the minimum angular displacement between each LiDAR scan which is used for mapping. [Default: 0.10] Fast Mode : Uses multiple threads to run map generation. This will be faster than using a single thread but may result in a lower quality map, especially in complex areas with little features such as buildings. [Default: unchecked] Scan Context Loop Closure : Advanced Loop Closure algorithm. Checking this will result in more scan posititions being considered for loop closure, thus generating a higher quality map. [Default: unchecked] What is Manual Loop Closure Detection? In the event that 3D Point Cloud Generation is unable to detect loop closures (a pair of scan points with similar locations) at certain areas of a point cloud, you can perform Manual Loop Closure Detection to stitch these parts of the point cloud together. Manual Loop Closure Detection works by trying to pair every point selected with each other in all permutations possible. During point cloud generation, if Loop Closures are not detected, pause the generation and perform Manual Loop Closure Detection by following the steps below. Example of a map which requires Manual Loop Closure Detection : | | What the area should be like: | | Select a few pairs of points for Manual Loop Closure Detection . Selected points that should be linked together. An example of this is shown below. | | If you selected the wrong pair of points, highlight the wrong pairs and click the Remove Keyframes button | | Select all remaining pairs and click Optimize and wait for the algorithm to match the points together. | | If no loop closures are able to be detected, increase the similarity score, then attempt optimisation again. | | If needed, continue with manual loop closure detection on other parts of the point cloud. *Final loop close | | Manual Loop Closure Detection Settings - Add Neighbour Keyframes: Also adds keyframes beside the selected keyframe. The number of keyframes added is determined by the Neighbour Size value. [Default: Checked] - Neighbour Size: The number of neighbour keyframes. [Default: 5] - Similarity Score: The lower this value, the more stringent loop closure will be when finding similar points. Increase this value in 0.10 intervals. [Default: 0.30] These values are only for manual loop closure, automatic loop closure configurations are listed above. Tips If the Manual Loop Closure Detection fails, users may want to lower the Loop Closure Similarity Score value based on the pop-up. Ensure that there are not too many large point clouds in d.ASH Xplorer's point cloud manager. These are loaded into RAM and can cause instability when too many of such point clouds are loaded. If you are confident that selected points are at the same location but the Loop Closure algorithm has failed to find similarities, please adjust the Loop Closure Similarity Score to a higher value. Once some loop closures are detected, you may observe some adjustments in the generated point cloud. You can then lower the score and perform Loop Closure again on different points to progressively correct the generated point cloud.","title":"Point Cloud Generation Configs"},{"location":"dash-pack/dash-xplorer/#scan-manager-plugin","text":"This plugin allows users to manage 3 rd -party 3D scanners. Currently, the Leica BLK360 scanner is supported. This is currently limited to users of d.ASH Xplorer Pro . This plugin is used to perform the following: Download scanMeta files from the robot Download scan data from the scanner Perform AutoMerge on all scans. Download ScanMeta Files scanMeta file ( *.scanMeta ) holds critical information for each scan point. Each 3D scan activated by the d.ASH robotics stack will generate a scanMeta file. The scanMeta data can be used to perform AutoMerge for creating a digital twin (high accuracy/density 3D point cloud model). scanMeta files are grouped by their project names which are set by d.ASH Autonomy Mission. To download the scanMeta files, perform the following: Connect your PC running d.ASH Xplorer Pro to the Internet and make sure that the robot is online Log in to d.ASH Xplorer Pro , then connect to the server. Click on the robot from the Online Robot List in the Scan Manager tab. Select the desired data folder by clicking the Folder icon . This folder will be used to store downloaded scanMeta files. We recommend choosing an empty folder. Otherwise, scanMeta files from previous/other projects will be overwritten. Click on Download Files to expand the window. | | Click Download to download ScanMeta files for the entire project. | | After downloading, all ScanMeta files will be stored in the folder selected in Step 3. Download 3D Scan Data from the Scanner This step performs downloading of 3D scan data from the 3D scanner by using the downloaded ScanMeta files. Connect your PC running d.ASH Xplorer Pro to the 3D scanner. Select the desired data folder by clicking the Folder icon . This folder should have ScanMeta files. Click on Download Files to expand the window. Under \"Download scan data from scanner\", click Download There will be a window popup showing all ScanMeta filenames found in the folder selected in Step 2. If 3D scan files and ScanMeta files with the same name exist, the filename will have \"[Downloaded]\" appended at the back of their names. Use the checkboxes on the left to mark 3D scan data for downloading. Users can use Select All or Unselect All buttons for file selections. | | Click Download to start the 3D scan downloading process. Once completed, Click Close to close the popup. AutoMerge This step performs AutoMerge on the 3D Scan data. AutoMerge utilizes sensor fusion techniques to automatically stitch and align multiple 3D scans for scale-consistent digital twin reconstruction. AutoMerge supports both colored and non-colored point clouds. To perform AutoMerge, perform the following steps: Select the desired data folder by clicking Change . This folder should have both ScanMeta files and 3D scan data files. Click on AutoMerge to expand the window. AutoMerge Scan File List displays a list of files in the selected folder for AutoMerge. Only filenames with .scanMeta and .pcd are considered for AutoMerge. Since AutoMerge relies on the orientation of the 3D scanner to perform stitching, users are encouraged to preview some scans first. This is done by selecting a few scans (greater than two) and clicking Preview . After scan previews have loaded, expand Options and change the Scanner Rotation so that the selected scans are roughly aligned. These rotations will rotate the 3D scan about their centres. As the scanner rotation is changed, the 3D scan previews will also be rotated accordingly. Users do not have to perfectly align the 3D scans manually. Just a rough estimate is sufficient. After configuring the scanner rotation, users can start AutoMerge. Click AutoMerge to start the AutoMerge process on the selected files (greater than one). You will see the 3D scans popping up and aligning themselves automatically after some time. When AutoMerge has completed, users have the following options: Export : Save the AutoMerge results and individual scans with corrected poses. Users can choose to export as .pcd , .dcloud , .las , or .e57 file formats. Edit : Export the AutoMerge results to Map Editor for editing. Options There are 3 different options available for Scan Manager: Scanner Rotation : Rotation in degrees of the scanner relative to the robot heading. As this value is changed, the 3D scan preview will also be updated in real-time. Optimize Visualization : Check this to optimize rendering. Check this if you notice a laggy visualization. Auto save AutoMerge results : Automatically save AutoMerge results to the data folder once AutoMerge has completed.","title":"Scan Manager (Plugin)"},{"location":"dc-pilot/pilot-guide/","text":"dC Pilot Client The dC pilot is a GUI (graphical user interface) for the d.ASH SDK. It encompasses interactive visual components for you to control your robot both manually and autonomously. Operate your robots safely and precisely, from any location with our reliable and high-performance BVLOS (Beyond Vision Line of Sight) System with high quality video streams and responsive controls. This section of the d.ASH SDK documentation provides details about using the d.C Pilot Client. 1.1 Introduction | | The pilot client allows you to operate your robots safely and precisely, from any location via its high-performance Remote TeleOps/BVLOS (Beyond Vision Line of Sight) system. It is also equipped with high quality video streams and responsive controls for seamless naviation. The system can also be used for fleet management, to discover, monitor and control multiple robots anytime, anywhere with real time video streaming and data collection. You can view a quick introduction of dc Pilot here | | The Vision AutoDrive is another key feature of the d.C Pilot, using machine learning and computer vision to analyze and understand your robot's surroundings. This allows hands-free Level 2 Autonomy for the navigation of complex, unstructured environments using just cameras alone. A demonstration of what Vision AutoDrive is capable of can be viewed here Some requirements before starting the d.C Pilot are: Nvidia CUDA GPU enabled PC ( At least 2 GB of GPU Memory ) Joystick connected to the PC 1 GB local storage space 16 GB of CPU Memory Intel i5 CPU or equivalent Windows 10 64-bit OS or higher 1.2 Robot Login When you first load up the pilot client, you will be asked to login via your user account. After authentication, you will be presented with the following screen below: | | The screen above shows you the robots switched ON and discovered via dashBoard ( the Fleet Management System ). Any robot currently registered under your user account and is alive will be displayed. Select the robot you want and click on Take Control to proceed to control the robot. If you want to restart the robot ( due to any unforseen previously encountered issues, ), click Restart to do so. 1.3 Main Controls | | Robot Power ON/OFF This is an optional step depending on the type of robot you are running. For most robots the robot is automatically turned ON when you physically attach a battery ( or press the actual Power ON button/switch ). For robots that need to be turned ON via software ( like the Boston Dynamics Spot ), you should turn it on by pressing the Power ON button before piloting the robot. Similary, you can Power OFF the robot if it supports such functionality. Basic Manual Piloting To start the robot from rest, apply pressure on the joystick. To stop the robot from moving, release your hold on the joystick. To move the robot forwards , push front on the joystick. To move the robot backwards , pull back on the joystick. To turn the robot to the left , tilt left on the joystick. To turn the robot to the right , tilt right on the joystick. To get the robot to stand or sit ( if the Robot supports it ), click the stand or sit button under the Basic Control panel on the right side of the main screen. Robot Reconnection/Restart ( Connectivity issues ) If you encounter situations where you lose connection to the robot ( or encounter unstable video/control streams ), you should consider Restarting/Reconnecting with the robot. There are 2 options available: | | Reconnect: This issues a fast reconnection between the pilot client and the robot. Run this if you suspect there was issue with connectivity between the client and the robot. Full Restart: This will flush + restart the robot system, then reconnect the client to the robot when the robot system is ready. Run this if you need to do a full restart with the robot possibly due to issues other than connectivity. 1.4 Control Panel Control Panel (1) Unmute the microphone to allow dual-communication between the pilot client and the robot. (2) Toggle between audio to broadcast speakers. (3) Record videos in mp4 format. (4) Upload/download video recordings. (5) Configure settings for your preference ie. night mode. (6) Broadcast live video streaming using eith a RTSP server or an HSL server. 1.5 Basic Controls Component Description (1) Monitor the joystick position with respect to your robot. Control the robot by pushing further on the joystick. (2) Adjust the cruise control speed using the slider control or if your joystick has a secondary lever, push the lever to activate. (3) Activate auto-drive for your robot to switch to Smart AI Assisted Cruise Autonomy. - Use the spacebar shortcut key to activate auto-drive. - Use the z shortcut key for your robot to take the next few possible left turns. - Use the x shortcut key for your robot to return to forward position after turning left or right. - Use the c shortcut key for your robot to take the next few possible right turns. 1.6 Cameras Component Description (1) Select from a list of cameras onboard Spot, which are automatically detected by the pilot client. (2) Adjust the order of cameras for a wider view scope. Ticking the flipped settings will adjust the camera orientation. (3) Click on sync to sync up the default camera layout/settings from the robot. You can also manually change the camera order via the Cameras drop-down combo box. (4) Activate human tracking for people detection and labelling. 1.7 AutoDrive | | AutoDrive is our state of the art ML/Computer Vision Level 2 Autonomy system for robots. It requires a calibrated 3 camera setup in order to properly function. Please make sure you have the proper setup before continuing. You can watch an overview video of what AutoDrive is capable of here | | The following options/controls are available: Run Motors: This starts/stops the AutoDrive system Avoid Grass: Checking this ON/OFF will tell the system whether to make the robot avoid/ignore a grassy area during Autonomy Log Data: This will record any required data for sending during operation 1.7 Leica BLK360 Laser Scanner | | This panel enables you to running scanning with the Leica BLK360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Select whether you want Color ( None, HDR, LDR ) via the Color combo box. Click Start to start the scanning operation. 1.8 Leica RTC360 Laser Scanner | | This panel enables you to running scanning with the Leica RTC360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Check the options Imaging , Double Scan , VIS for your RTC 360. Please consult your scanner user manual for more information on what those options do. Click Start to start the scanning operation. 1.9 Boston Dynamics Spot Arm | | This panel enables you to operate the Boston Dynamics Spot Arm if your Spot robot has been configured with one. Please take note that your cameras should be set to Spot's Default Black and White Cameras in order for this to function. Click Operate to start the Arm operation This will pop up a separate window that shows the black and white cameras on Spot. Click on the desired target area to run the arm manipulation operation. Click Run to start the arm operation.","title":"1.0 d.ASH Pilot Client"},{"location":"dc-pilot/pilot-guide/#dc-pilot-client","text":"The dC pilot is a GUI (graphical user interface) for the d.ASH SDK. It encompasses interactive visual components for you to control your robot both manually and autonomously. Operate your robots safely and precisely, from any location with our reliable and high-performance BVLOS (Beyond Vision Line of Sight) System with high quality video streams and responsive controls. This section of the d.ASH SDK documentation provides details about using the d.C Pilot Client.","title":"dC Pilot Client"},{"location":"dc-pilot/pilot-guide/#11-introduction","text":"| | The pilot client allows you to operate your robots safely and precisely, from any location via its high-performance Remote TeleOps/BVLOS (Beyond Vision Line of Sight) system. It is also equipped with high quality video streams and responsive controls for seamless naviation. The system can also be used for fleet management, to discover, monitor and control multiple robots anytime, anywhere with real time video streaming and data collection. You can view a quick introduction of dc Pilot here | | The Vision AutoDrive is another key feature of the d.C Pilot, using machine learning and computer vision to analyze and understand your robot's surroundings. This allows hands-free Level 2 Autonomy for the navigation of complex, unstructured environments using just cameras alone. A demonstration of what Vision AutoDrive is capable of can be viewed here Some requirements before starting the d.C Pilot are: Nvidia CUDA GPU enabled PC ( At least 2 GB of GPU Memory ) Joystick connected to the PC 1 GB local storage space 16 GB of CPU Memory Intel i5 CPU or equivalent Windows 10 64-bit OS or higher","title":"1.1 Introduction"},{"location":"dc-pilot/pilot-guide/#12-robot-login","text":"When you first load up the pilot client, you will be asked to login via your user account. After authentication, you will be presented with the following screen below: | | The screen above shows you the robots switched ON and discovered via dashBoard ( the Fleet Management System ). Any robot currently registered under your user account and is alive will be displayed. Select the robot you want and click on Take Control to proceed to control the robot. If you want to restart the robot ( due to any unforseen previously encountered issues, ), click Restart to do so.","title":"1.2 Robot Login"},{"location":"dc-pilot/pilot-guide/#13-main-controls","text":"| |","title":"1.3 Main Controls"},{"location":"dc-pilot/pilot-guide/#robot-power-onoff","text":"This is an optional step depending on the type of robot you are running. For most robots the robot is automatically turned ON when you physically attach a battery ( or press the actual Power ON button/switch ). For robots that need to be turned ON via software ( like the Boston Dynamics Spot ), you should turn it on by pressing the Power ON button before piloting the robot. Similary, you can Power OFF the robot if it supports such functionality. Basic Manual Piloting To start the robot from rest, apply pressure on the joystick. To stop the robot from moving, release your hold on the joystick. To move the robot forwards , push front on the joystick. To move the robot backwards , pull back on the joystick. To turn the robot to the left , tilt left on the joystick. To turn the robot to the right , tilt right on the joystick. To get the robot to stand or sit ( if the Robot supports it ), click the stand or sit button under the Basic Control panel on the right side of the main screen.","title":"Robot Power ON/OFF"},{"location":"dc-pilot/pilot-guide/#robot-reconnectionrestart-connectivity-issues","text":"If you encounter situations where you lose connection to the robot ( or encounter unstable video/control streams ), you should consider Restarting/Reconnecting with the robot. There are 2 options available: | | Reconnect: This issues a fast reconnection between the pilot client and the robot. Run this if you suspect there was issue with connectivity between the client and the robot. Full Restart: This will flush + restart the robot system, then reconnect the client to the robot when the robot system is ready. Run this if you need to do a full restart with the robot possibly due to issues other than connectivity.","title":"Robot Reconnection/Restart ( Connectivity issues )"},{"location":"dc-pilot/pilot-guide/#14-control-panel","text":"Control Panel (1) Unmute the microphone to allow dual-communication between the pilot client and the robot. (2) Toggle between audio to broadcast speakers. (3) Record videos in mp4 format. (4) Upload/download video recordings. (5) Configure settings for your preference ie. night mode. (6) Broadcast live video streaming using eith a RTSP server or an HSL server.","title":"1.4 Control Panel"},{"location":"dc-pilot/pilot-guide/#15-basic-controls","text":"Component Description (1) Monitor the joystick position with respect to your robot. Control the robot by pushing further on the joystick. (2) Adjust the cruise control speed using the slider control or if your joystick has a secondary lever, push the lever to activate. (3) Activate auto-drive for your robot to switch to Smart AI Assisted Cruise Autonomy. - Use the spacebar shortcut key to activate auto-drive. - Use the z shortcut key for your robot to take the next few possible left turns. - Use the x shortcut key for your robot to return to forward position after turning left or right. - Use the c shortcut key for your robot to take the next few possible right turns.","title":"1.5 Basic Controls"},{"location":"dc-pilot/pilot-guide/#16-cameras","text":"Component Description (1) Select from a list of cameras onboard Spot, which are automatically detected by the pilot client. (2) Adjust the order of cameras for a wider view scope. Ticking the flipped settings will adjust the camera orientation. (3) Click on sync to sync up the default camera layout/settings from the robot. You can also manually change the camera order via the Cameras drop-down combo box. (4) Activate human tracking for people detection and labelling.","title":"1.6 Cameras"},{"location":"dc-pilot/pilot-guide/#17-autodrive","text":"| | AutoDrive is our state of the art ML/Computer Vision Level 2 Autonomy system for robots. It requires a calibrated 3 camera setup in order to properly function. Please make sure you have the proper setup before continuing. You can watch an overview video of what AutoDrive is capable of here | | The following options/controls are available: Run Motors: This starts/stops the AutoDrive system Avoid Grass: Checking this ON/OFF will tell the system whether to make the robot avoid/ignore a grassy area during Autonomy Log Data: This will record any required data for sending during operation","title":"1.7 AutoDrive"},{"location":"dc-pilot/pilot-guide/#17-leica-blk360-laser-scanner","text":"| | This panel enables you to running scanning with the Leica BLK360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Select whether you want Color ( None, HDR, LDR ) via the Color combo box. Click Start to start the scanning operation.","title":"1.7 Leica BLK360 Laser Scanner"},{"location":"dc-pilot/pilot-guide/#18-leica-rtc360-laser-scanner","text":"| | This panel enables you to running scanning with the Leica RTC360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Check the options Imaging , Double Scan , VIS for your RTC 360. Please consult your scanner user manual for more information on what those options do. Click Start to start the scanning operation.","title":"1.8 Leica RTC360 Laser Scanner"},{"location":"dc-pilot/pilot-guide/#19-boston-dynamics-spot-arm","text":"| | This panel enables you to operate the Boston Dynamics Spot Arm if your Spot robot has been configured with one. Please take note that your cameras should be set to Spot's Default Black and White Cameras in order for this to function. Click Operate to start the Arm operation This will pop up a separate window that shows the black and white cameras on Spot. Click on the desired target area to run the arm manipulation operation. Click Run to start the arm operation.","title":"1.9 Boston Dynamics Spot Arm"},{"location":"dc-pilot/pilot-sdk/","text":"dC Pilot SDK The dC Pilot SDK allows you to develop your own custom robot Teleoperations apps easily. You will need: C++14 compatible compiler ( VS2022 recommended ) For AutoDrive: CUDA enabled GPU Windows 10 2.1 Discovering your robots The first step you need to perform is to run the discovery service to find the robot you want registered in your fleet. Here are the required includes: #include <iostream> #include <string> #include <cxxopts.hpp> #include <robotDiscovery.h> #include <robotPilot.h> #include <robotNode.h> #include <unordered_map> #include <functional> #include <algorithm> #include <chrono> #include <thread> Next, start the robot discovery service: // Create the robot discovery service auto rDiscovery = DashMicroSv :: getRobotDiscovery (); // Login with your credetials if ( ! rDiscovery -> loginCloud ( userName , pwd )) { std :: cout << \"ERROR! Invalid Login Credentials.\" << std :: endl ; return ; } // Start the discovery rDiscovery -> startDiscovery (); You can now write a simple function like the one below to find the robot you want: std :: shared_ptr < DashMicroSv :: RobotNode > findRobotWithName ( DashMicroSv :: RobotDiscovery & rDiscoveryIn , const std :: string & robotName , bool printList ) { std :: shared_ptr < DashMicroSv :: RobotNode > retBot = nullptr ; auto aliveBots = rDiscoveryIn . getAliveRobots (); if ( printList ) { printRobotList ( aliveBots ); } for ( const auto & aBot : aliveBots ) { if ( aBot -> getName () == robotName ) { retBot = aBot ; break ; } } return retBot ; } So go ahead and retrieve your robot: auto myRobotNode = findRobotWithName ( * rDiscovery , \"myRobot\" , true ); With your robot found, it is now time to construct the Pilot and control it via teleoperation commands. 2.2 Teleoperations Use the robot you found in the previous section to construct your Pilot : auto myPilot = std :: make_shared ( * rDiscovery , * myRobotNode ); // Now connect to the robot if ( ! myPilot -> connect ()) { std :: cout << \"ERROR! Unable to connect to robot!\" << std :: endl ; return ; } Game Loop Ticking, Moving Robot, Retrieving images The recommended implementation to operate the robot is via a simple Game Loop . From there you can tick and send velocity commands as well as retrieve images from your robot. Some pseudo code of how it will look like is presented below: std :: vector < cv :: Mat > camImgs ; while ( true ) { // Retrieve camera images myPilot -> tick ( camImgs ); ProcessCamImgs ( camImgs ); // Move robot float x = 0 , y = 0 , rot = 0 ; RetrieveJoystick ( x , y , rot ); myPilot -> setFreeMoveVel ( x , y , rot ); // In MS Pause ( 1.0 ); } This concludes the simple tutorial/writeup on how to use the Pilot SDK to teleoperate your own robots.","title":"2.0 d.ASH Pilot SDK"},{"location":"dc-pilot/pilot-sdk/#dc-pilot-sdk","text":"The dC Pilot SDK allows you to develop your own custom robot Teleoperations apps easily. You will need: C++14 compatible compiler ( VS2022 recommended ) For AutoDrive: CUDA enabled GPU Windows 10","title":"dC Pilot SDK"},{"location":"dc-pilot/pilot-sdk/#21-discovering-your-robots","text":"The first step you need to perform is to run the discovery service to find the robot you want registered in your fleet. Here are the required includes: #include <iostream> #include <string> #include <cxxopts.hpp> #include <robotDiscovery.h> #include <robotPilot.h> #include <robotNode.h> #include <unordered_map> #include <functional> #include <algorithm> #include <chrono> #include <thread> Next, start the robot discovery service: // Create the robot discovery service auto rDiscovery = DashMicroSv :: getRobotDiscovery (); // Login with your credetials if ( ! rDiscovery -> loginCloud ( userName , pwd )) { std :: cout << \"ERROR! Invalid Login Credentials.\" << std :: endl ; return ; } // Start the discovery rDiscovery -> startDiscovery (); You can now write a simple function like the one below to find the robot you want: std :: shared_ptr < DashMicroSv :: RobotNode > findRobotWithName ( DashMicroSv :: RobotDiscovery & rDiscoveryIn , const std :: string & robotName , bool printList ) { std :: shared_ptr < DashMicroSv :: RobotNode > retBot = nullptr ; auto aliveBots = rDiscoveryIn . getAliveRobots (); if ( printList ) { printRobotList ( aliveBots ); } for ( const auto & aBot : aliveBots ) { if ( aBot -> getName () == robotName ) { retBot = aBot ; break ; } } return retBot ; } So go ahead and retrieve your robot: auto myRobotNode = findRobotWithName ( * rDiscovery , \"myRobot\" , true ); With your robot found, it is now time to construct the Pilot and control it via teleoperation commands.","title":"2.1 Discovering your robots"},{"location":"dc-pilot/pilot-sdk/#22-teleoperations","text":"Use the robot you found in the previous section to construct your Pilot : auto myPilot = std :: make_shared ( * rDiscovery , * myRobotNode ); // Now connect to the robot if ( ! myPilot -> connect ()) { std :: cout << \"ERROR! Unable to connect to robot!\" << std :: endl ; return ; }","title":"2.2 Teleoperations"},{"location":"dc-pilot/pilot-sdk/#game-loop-ticking-moving-robot-retrieving-images","text":"The recommended implementation to operate the robot is via a simple Game Loop . From there you can tick and send velocity commands as well as retrieve images from your robot. Some pseudo code of how it will look like is presented below: std :: vector < cv :: Mat > camImgs ; while ( true ) { // Retrieve camera images myPilot -> tick ( camImgs ); ProcessCamImgs ( camImgs ); // Move robot float x = 0 , y = 0 , rot = 0 ; RetrieveJoystick ( x , y , rot ); myPilot -> setFreeMoveVel ( x , y , rot ); // In MS Pause ( 1.0 ); } This concludes the simple tutorial/writeup on how to use the Pilot SDK to teleoperate your own robots.","title":"Game Loop Ticking, Moving Robot, Retrieving images"},{"location":"getting-started/config-connect/","text":"Configuring Sensors 2.1 Velodyne Driver 2.1.1 Setting Up on Sensor By default, the Velodyne LIDAR sensor IP address is factory set on default value 192.168.1.201 . The d.ASH SDK will assume the default Velodyne IP address. 2.1.2 Setting Up on Personal Computer You'll need to configure a static IP address for your computer to use an address within the range 192.168.1.XXX where XXX may be any integer from 2 to 254, except 201 (which is the LIDAR\u2019s IP). For example, an appropriate static IP address for your compute could be 192.168.1.100 . 2.1.3 Testing Velodyne Sensors Now, let's test your lidar sensors. To test the Velodyne VLP-16 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_velodyne.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points 2.2 Ouster Driver 2.2.1 Setting Up on Sensor By default, the Ouster LIDAR sensor IP address is factory set on your IPv6/IPv4 link-local address. The addresses lie within the block 169.254.0.0 to 169.254.255.255 . To change the static IP address for Ouster, refer to the Ouster Documentation . It is recommended to set up your own static IP address. 2.2.2 Setting Up on Personal Computer You'll need to configure a static IP address for your computer to use an address within the range 192.0.2.XXX where XXX may be any integer from 2 to 254. For example, an appropriate static IP address for your compute could be 192.0.2.123 . 2.1.3 Testing Ouster Sensors To test the Ouster OS1-32 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_ouster.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.0 Configuring Sensors"},{"location":"getting-started/config-connect/#configuring-sensors","text":"","title":"Configuring Sensors"},{"location":"getting-started/config-connect/#21-velodyne-driver","text":"","title":"2.1 Velodyne Driver"},{"location":"getting-started/config-connect/#211-setting-up-on-sensor","text":"By default, the Velodyne LIDAR sensor IP address is factory set on default value 192.168.1.201 . The d.ASH SDK will assume the default Velodyne IP address.","title":"2.1.1 Setting Up on Sensor"},{"location":"getting-started/config-connect/#212-setting-up-on-personal-computer","text":"You'll need to configure a static IP address for your computer to use an address within the range 192.168.1.XXX where XXX may be any integer from 2 to 254, except 201 (which is the LIDAR\u2019s IP). For example, an appropriate static IP address for your compute could be 192.168.1.100 .","title":"2.1.2 Setting Up on Personal Computer"},{"location":"getting-started/config-connect/#213-testing-velodyne-sensors","text":"Now, let's test your lidar sensors. To test the Velodyne VLP-16 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_velodyne.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.1.3 Testing Velodyne Sensors"},{"location":"getting-started/config-connect/#22-ouster-driver","text":"","title":"2.2 Ouster Driver"},{"location":"getting-started/config-connect/#221-setting-up-on-sensor","text":"By default, the Ouster LIDAR sensor IP address is factory set on your IPv6/IPv4 link-local address. The addresses lie within the block 169.254.0.0 to 169.254.255.255 . To change the static IP address for Ouster, refer to the Ouster Documentation . It is recommended to set up your own static IP address.","title":"2.2.1 Setting Up on Sensor"},{"location":"getting-started/config-connect/#222-setting-up-on-personal-computer","text":"You'll need to configure a static IP address for your computer to use an address within the range 192.0.2.XXX where XXX may be any integer from 2 to 254. For example, an appropriate static IP address for your compute could be 192.0.2.123 .","title":"2.2.2 Setting Up on Personal Computer"},{"location":"getting-started/config-connect/#213-testing-ouster-sensors","text":"To test the Ouster OS1-32 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_ouster.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.1.3 Testing Ouster Sensors"},{"location":"getting-started/config-spot/","text":"Configuring Spot This section of the d.ASH SDK documentation provides details about setting up Spot with the d.ASH SDK. To configure Spot, you will need to set up on the robot itself and on your personal computer. For further enquiries of setting up Spot, follow Boston Dynamics Documentation . 1.1 Setting Up On Spot By default, user and admin credentials are printed on the label of the robot's battery compartment. Otherwise, you can create your own account through the admin console by creating a user with admin privileges. Check out Boston Dynamics Documentation for more information on how to do so. Remember your credentials! Remember your Spot credentials as you will need those same credentials to set up the next section on your personal computer. 1.2 Setting Up On PC By default, the Spot robot IP address is 10.0.0.3 . If you have more than one Spot robot, refer to the Boston Dynamics Documentation to use the admin console to change the default IP of additional robots to avoid address conflicts. You'll need to configure a static IP address for your computer to use an address within the range 10.0.0.X where X may be any integer from 2 to 254, except 3 (which is the Spot's IP). For example, an appropriate static IP address for your compute could be 10.0.0.100 . You will then be asked to enter a valid admin or operator username and password. These credentials will match the credentials on Spot's battery compartment.","title":"1.0 Configuring Spot"},{"location":"getting-started/config-spot/#configuring-spot","text":"This section of the d.ASH SDK documentation provides details about setting up Spot with the d.ASH SDK. To configure Spot, you will need to set up on the robot itself and on your personal computer. For further enquiries of setting up Spot, follow Boston Dynamics Documentation .","title":"Configuring Spot"},{"location":"getting-started/config-spot/#11-setting-up-on-spot","text":"By default, user and admin credentials are printed on the label of the robot's battery compartment. Otherwise, you can create your own account through the admin console by creating a user with admin privileges. Check out Boston Dynamics Documentation for more information on how to do so. Remember your credentials! Remember your Spot credentials as you will need those same credentials to set up the next section on your personal computer.","title":"1.1 Setting Up On Spot"},{"location":"getting-started/config-spot/#12-setting-up-on-pc","text":"By default, the Spot robot IP address is 10.0.0.3 . If you have more than one Spot robot, refer to the Boston Dynamics Documentation to use the admin console to change the default IP of additional robots to avoid address conflicts. You'll need to configure a static IP address for your computer to use an address within the range 10.0.0.X where X may be any integer from 2 to 254, except 3 (which is the Spot's IP). For example, an appropriate static IP address for your compute could be 10.0.0.100 . You will then be asked to enter a valid admin or operator username and password. These credentials will match the credentials on Spot's battery compartment.","title":"1.2 Setting Up On PC"},{"location":"getting-started/dash-eng/","text":"Interfacing d.ASH Autonomy Engine with ROS This section of the d.ASH SDK documentation provides details about using ROS with the d.ASH autonomy engine. Described below are ROS topics, along with their type and functionality. 4.1 Publications Topic Type Function /active_path nav_mgs/Path Returns current path being executed. /image sensor_msgs/Image Returns sensor image. /initial_pose geometry_msgs/PoseWithCovarianceStamped Returns initial pose estimate for localization. /localization_status std_msgs/String Returns status of localization certainty. /mcl_pose_marker visualization_msgs/Marker Returns current localization position. /nearest_wpts visualization_msgs/Marker Returns nearest waypoints for the robot to follow. /odom nav_msgs/Odometry Returns odometry reading. /original_path nav_msgs/Path Returns original path before processing. /particle_array geometry_msgs/PoseArray Returns localization particle certainty. /tracking_wpt std_msgs/Float32MultiArray Returns nearest waypoints for the robot to follow. 4.2 Subscriptions Topic Type Function /cmd_vel geometry_msgs/Twist Accepts manual command velocity. /imu sensor_msgs/Imu Accepts imu sensor data. /initial_pose geometry_msgs/PoseWithCovarianceStamped Accepts initial pose estimate for localization. /joy sensor_msgs/Joy Accepts joystick message. /move_base_simple/goal geometry_msgs/PoseStamped Accepts final goal from RVIZ. /odom nav_msgs/Odometry Accepts odometry reading. /lidar_points sensor_msgs/PointCloud2 Accepts lidar scan.","title":"4.0 d.ASH with ROS"},{"location":"getting-started/dash-eng/#interfacing-dash-autonomy-engine-with-ros","text":"This section of the d.ASH SDK documentation provides details about using ROS with the d.ASH autonomy engine. Described below are ROS topics, along with their type and functionality.","title":"Interfacing d.ASH Autonomy Engine with ROS"},{"location":"getting-started/dash-eng/#41-publications","text":"Topic Type Function /active_path nav_mgs/Path Returns current path being executed. /image sensor_msgs/Image Returns sensor image. /initial_pose geometry_msgs/PoseWithCovarianceStamped Returns initial pose estimate for localization. /localization_status std_msgs/String Returns status of localization certainty. /mcl_pose_marker visualization_msgs/Marker Returns current localization position. /nearest_wpts visualization_msgs/Marker Returns nearest waypoints for the robot to follow. /odom nav_msgs/Odometry Returns odometry reading. /original_path nav_msgs/Path Returns original path before processing. /particle_array geometry_msgs/PoseArray Returns localization particle certainty. /tracking_wpt std_msgs/Float32MultiArray Returns nearest waypoints for the robot to follow.","title":"4.1 Publications"},{"location":"getting-started/dash-eng/#42-subscriptions","text":"Topic Type Function /cmd_vel geometry_msgs/Twist Accepts manual command velocity. /imu sensor_msgs/Imu Accepts imu sensor data. /initial_pose geometry_msgs/PoseWithCovarianceStamped Accepts initial pose estimate for localization. /joy sensor_msgs/Joy Accepts joystick message. /move_base_simple/goal geometry_msgs/PoseStamped Accepts final goal from RVIZ. /odom nav_msgs/Odometry Accepts odometry reading. /lidar_points sensor_msgs/PointCloud2 Accepts lidar scan.","title":"4.2 Subscriptions"},{"location":"getting-started/map-loading/","text":"Map Loading This section of the d.ASH SDK documentation provides details about file organisation of autonomy maps for the d.ASH SDK. To load a new map, upload the autonomy map files in the folder maps found in /dash_sdk/.data/maps . Please ensure that the following files are in the folder: dash-sdk/ \u2514\u2500 .data/ \u2514\u2500 maps \u2514\u2500 <MAP_NAME>.png # 2D Autonomy Map \u2514\u2500 <MAP_NAME>.pcd # 3D Autonomy Map \u2514\u2500 <MAP_NAME>.json # Global Planner Configuration To activate the new map, ensure the map name in auto_config.json file matches <MAP_NAME> . For example: \"map_name\": \"outdoor_map\",","title":"3.0 Map Loading"},{"location":"getting-started/map-loading/#map-loading","text":"This section of the d.ASH SDK documentation provides details about file organisation of autonomy maps for the d.ASH SDK. To load a new map, upload the autonomy map files in the folder maps found in /dash_sdk/.data/maps . Please ensure that the following files are in the folder: dash-sdk/ \u2514\u2500 .data/ \u2514\u2500 maps \u2514\u2500 <MAP_NAME>.png # 2D Autonomy Map \u2514\u2500 <MAP_NAME>.pcd # 3D Autonomy Map \u2514\u2500 <MAP_NAME>.json # Global Planner Configuration To activate the new map, ensure the map name in auto_config.json file matches <MAP_NAME> . For example: \"map_name\": \"outdoor_map\",","title":"Map Loading"},{"location":"sdk-config/auto-config/","text":"Auto Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the robot - auto_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure autonomy. 4.1 Config File { \"py_address\" : \"0.0.0.0:50051\" , \"ue_address\" : \"0.0.0.0:50052\" , \"ssl\" : true , \"motion_planner\" : true , \"localization\" : true , \"sim_mode\" : false , \"send_data_gui\" : true , \"camera\" : \"RealsenseCam\" , \"retrieveImg\" : false , \"map_name\" : \"office_lvl4\" , \"pc_topic\" : \"velodyne_points\" , \"odom_topic\" : \"odom\" , \"controller\" :{ \"linear_window\" : 0.5 , \"linear_min_v\" : 0.0 , \"linear_max_v\" : 0.8 , \"angular_max_w\" : 3.142 , \"linear_max_a\" : 1.0 , \"angular_max_a\" : 5.0 , \"robot_width\" : 0.4 , \"robot_length\" : 1.0 , \"obstacle_cost_gains\" : 3.0 , \"speed_cost_gains\" : 1.0 , \"goal_cost_gains\" : 4.0 , \"angular_speed_cost_scaling_factor\" : 0.1 , \"linear_num_window_steps\" : 50 , \"angular_num_window_steps\" : 30 , \"prediction_window\" : 5.0 , \"costmap_size\" : 20.0 , \"costmap_scale\" : 0.1 , \"max_pc_height\" : 0.2 , \"min_pc_height\" : - 0.5 , \"x_filter\" :[ - 0.2 , 0.2 ], \"y_filter\" :[ - 0.1 , 0.1 ], \"costmap_obs_inflation\" : 1.0 , \"occ_obs_deadzone\" : 0.2 , \"dt\" : 0.1 , \"visualise\" : false }, \"state_estimator\" :{ \"initial_x\" : - 7.7 , \"initial_y\" : - 14.5 , \"initial_z\" : 1.0 , \"initial_w\" : - 0.177 , \"kImuTopic\" : \"imu\" , \"kPoseTopic\" : \"mcl_pose\" , \"ktfUpdate\" : 0.02 , \"kStatusUpdate\" : 1.0 , \"kLoggingUpdate\" : 15.0 , \"kposeDiffmax\" : 5.0 , \"KUse_imu_ori\" : false , \"kBadCovThres\" : 2.0 , \"kGoodCovThres\" : 0.7 , \"kCovBadMax\" : 10 , \"kCovGoodtMax\" : 5 , \"kFilter_z\" : true , \"klimit_min\" : - 0.3 , \"klimit_max\" : 5.0 }, \"planner\" :{ \"lookAheadIndex\" : 15 , \"enable_self_rotate\" : false , \"self_rotation_speed\" : 0.5 , \"self_rotation_speed_final\" : 0.3 , \"dis_threshold\" : 0.5 , \"theta_threshold\" : 0.2 , \"cmd_Smoothing\" : true , } } 4.2 Definitions 4.2.1 Main Variable Definition py_address The address of the d.ASH server in the formal <IP>:<PORT> . ue_address The address of the GUI server in the formal <IP>:<PORT> . ssl Enables secure SSL messaging and encryption. motion_planner Enables autonomy motion planning. localization Enables robot localisation, returning users position and orientation in relation to map. sim_mode Enables Spot odometry retrieval. send_data_gui Enables ability to send data to GUI server for visualisation. camera Camera active for the current session to retrieve data ie. RealsenseCam, TestCam . retrieveImg Enables image retrieval. map_name Map name used for autonomy (as mentioned in File Organisation ). pc_topic ROS point cloud topic name for subscribing odom_topic ROS odometry topic name for subscribing. 4.2.2 Controller For the following parameters, ensure the value is within limits of the robot as per its documentation. Variable Definition linear_window Sets DWA (dynamic window approach) size. linear_min_v Sets minimum linear velocity for autonomy. linear_max_v Sets maximum linear velocity for autonomy. angular_max_w Sets maximum angular velocity for autonomy. linear_max_a Sets maximum linear acceleration for autonomy. angular_max_a Sets maximum angular acceleration for autonomy. robot_width Reflects width of robot. robot_length Reflects the length of robot. obstacle_cost_gains Sets weight for an obstacle course based on the weighted sum of the map. speed_cost_gains Sets weight for speed cost. goal_cost_gains Sets weight for goal cost. angular_speed_cost_scaling_factor Sets weight for angular velocity. Note that a higher value of the variable discourages the robot from turning. linear_num_window_steps Sets number of linear velocity values to consider. Note that a higher value of the variable slows down the computations. angular_num_window_steps Sets number of angular velocity values to consider. Note that a higher value of the variable slows down the computations. prediction_window Sets prediction horizion (in seconds). Note that a higher value of the variable slows down the computations. costmap_size Sets local costmap size (in meters). costmap_scale Sets scale to convert map from meter to pixels. max_pc_height Sets maximum point cloud height to be considered as an obstacle. min_pc_height Sets minimum point cloud height to be considered as an obstacle. Note that the point cloud height is measured from the center of the lidar. If the ground is detected, it will be considered as an obstacle. Therefore, set the minimum value to be above the ground. x_filter Sets vector of size 2 consisting the minimum and maximum x-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. y_filter Sets vector of size 2 consisting the minimum and maximum y-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. costmap_obs_inflation Sets inflation radius of obstacles to be considered in planning. Note that a higher value of the variable results in more conservative planning. occ_obs_deadzone Sets minimum distances from obstacles and robots for autonomy. dt Sets timestep. Note that a higher timestamp slows down the computation. visualise Enables visualisation of costmap. This is used only for debugging. 4.2.3 State Estimator Variable Definition initial_x Sets initialization of x-axis for localizaition (in meters). initial_y Sets initialization of y-axis for localizaition (in meters). initial_z Sets initialization of z-axis for localizaition (in meters). initial_w Sets initialization of orientation for localizaition. kImuTopic ROS IMU (Inertial Measurement Unit) topic name for subscribing. kPoseTopic Enables localization result. ktfUpdate Sets ROS tf publishing frequency. kStatusUpdate Sets localisation status of publishing frequency. kLoggingUpdate Sets data logging period. kposeDiffmax Sets the maximum distance between two consecutive pose estimation. KUse_imu_ori Enables IMU (Inertial Measurement Unit) or odom orientation for odometry estimation. If this variable is set to true, ensure kImuTopic is available. kBadCovThres Sets localization quality. kGoodCovThres Sets localization quality. kCovBadMax Sets localization quality. kCovGoodtMax Sets localization quality. kFilter_z Enables pass through filter application for localization. klimit_min Sets minimum range of pass through filter. klimit_max Sets maximum range of pass through filter. 4.2.4 Planner Variable Definition lookAheadIndexv Sets look-ahead index from the nearest waypoint for path to follow. Note that a lower index slows down the movement of the robot. Similarly, a higher index results in the robot not follow path properly. enable_self_rotate Enables one round of rotation around the robot itself before performing autonomy. This is to ensure that localisation is working before starting autonomy. self_rotation_speed Sets angular velocity of robot to turn around itself before performing autonomy (in radiants/second). self_rotation_speed_final Sets angular velocity of robot to turn around itself after performing autonomy (in radiants/second). This ensures that the final orientation of robot aligns with its goal. dis_threshold Sets maximum euclidean distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. theta_threshold Sets maximum orientation distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. cmd_Smoothing Enables smoothing control commands.","title":"4.0 Auto Configuration"},{"location":"sdk-config/auto-config/#auto-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the robot - auto_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure autonomy.","title":"Auto Configuration"},{"location":"sdk-config/auto-config/#41-config-file","text":"{ \"py_address\" : \"0.0.0.0:50051\" , \"ue_address\" : \"0.0.0.0:50052\" , \"ssl\" : true , \"motion_planner\" : true , \"localization\" : true , \"sim_mode\" : false , \"send_data_gui\" : true , \"camera\" : \"RealsenseCam\" , \"retrieveImg\" : false , \"map_name\" : \"office_lvl4\" , \"pc_topic\" : \"velodyne_points\" , \"odom_topic\" : \"odom\" , \"controller\" :{ \"linear_window\" : 0.5 , \"linear_min_v\" : 0.0 , \"linear_max_v\" : 0.8 , \"angular_max_w\" : 3.142 , \"linear_max_a\" : 1.0 , \"angular_max_a\" : 5.0 , \"robot_width\" : 0.4 , \"robot_length\" : 1.0 , \"obstacle_cost_gains\" : 3.0 , \"speed_cost_gains\" : 1.0 , \"goal_cost_gains\" : 4.0 , \"angular_speed_cost_scaling_factor\" : 0.1 , \"linear_num_window_steps\" : 50 , \"angular_num_window_steps\" : 30 , \"prediction_window\" : 5.0 , \"costmap_size\" : 20.0 , \"costmap_scale\" : 0.1 , \"max_pc_height\" : 0.2 , \"min_pc_height\" : - 0.5 , \"x_filter\" :[ - 0.2 , 0.2 ], \"y_filter\" :[ - 0.1 , 0.1 ], \"costmap_obs_inflation\" : 1.0 , \"occ_obs_deadzone\" : 0.2 , \"dt\" : 0.1 , \"visualise\" : false }, \"state_estimator\" :{ \"initial_x\" : - 7.7 , \"initial_y\" : - 14.5 , \"initial_z\" : 1.0 , \"initial_w\" : - 0.177 , \"kImuTopic\" : \"imu\" , \"kPoseTopic\" : \"mcl_pose\" , \"ktfUpdate\" : 0.02 , \"kStatusUpdate\" : 1.0 , \"kLoggingUpdate\" : 15.0 , \"kposeDiffmax\" : 5.0 , \"KUse_imu_ori\" : false , \"kBadCovThres\" : 2.0 , \"kGoodCovThres\" : 0.7 , \"kCovBadMax\" : 10 , \"kCovGoodtMax\" : 5 , \"kFilter_z\" : true , \"klimit_min\" : - 0.3 , \"klimit_max\" : 5.0 }, \"planner\" :{ \"lookAheadIndex\" : 15 , \"enable_self_rotate\" : false , \"self_rotation_speed\" : 0.5 , \"self_rotation_speed_final\" : 0.3 , \"dis_threshold\" : 0.5 , \"theta_threshold\" : 0.2 , \"cmd_Smoothing\" : true , } }","title":"4.1 Config File"},{"location":"sdk-config/auto-config/#42-definitions","text":"","title":"4.2 Definitions"},{"location":"sdk-config/auto-config/#421-main","text":"Variable Definition py_address The address of the d.ASH server in the formal <IP>:<PORT> . ue_address The address of the GUI server in the formal <IP>:<PORT> . ssl Enables secure SSL messaging and encryption. motion_planner Enables autonomy motion planning. localization Enables robot localisation, returning users position and orientation in relation to map. sim_mode Enables Spot odometry retrieval. send_data_gui Enables ability to send data to GUI server for visualisation. camera Camera active for the current session to retrieve data ie. RealsenseCam, TestCam . retrieveImg Enables image retrieval. map_name Map name used for autonomy (as mentioned in File Organisation ). pc_topic ROS point cloud topic name for subscribing odom_topic ROS odometry topic name for subscribing.","title":"4.2.1 Main"},{"location":"sdk-config/auto-config/#422-controller","text":"For the following parameters, ensure the value is within limits of the robot as per its documentation. Variable Definition linear_window Sets DWA (dynamic window approach) size. linear_min_v Sets minimum linear velocity for autonomy. linear_max_v Sets maximum linear velocity for autonomy. angular_max_w Sets maximum angular velocity for autonomy. linear_max_a Sets maximum linear acceleration for autonomy. angular_max_a Sets maximum angular acceleration for autonomy. robot_width Reflects width of robot. robot_length Reflects the length of robot. obstacle_cost_gains Sets weight for an obstacle course based on the weighted sum of the map. speed_cost_gains Sets weight for speed cost. goal_cost_gains Sets weight for goal cost. angular_speed_cost_scaling_factor Sets weight for angular velocity. Note that a higher value of the variable discourages the robot from turning. linear_num_window_steps Sets number of linear velocity values to consider. Note that a higher value of the variable slows down the computations. angular_num_window_steps Sets number of angular velocity values to consider. Note that a higher value of the variable slows down the computations. prediction_window Sets prediction horizion (in seconds). Note that a higher value of the variable slows down the computations. costmap_size Sets local costmap size (in meters). costmap_scale Sets scale to convert map from meter to pixels. max_pc_height Sets maximum point cloud height to be considered as an obstacle. min_pc_height Sets minimum point cloud height to be considered as an obstacle. Note that the point cloud height is measured from the center of the lidar. If the ground is detected, it will be considered as an obstacle. Therefore, set the minimum value to be above the ground. x_filter Sets vector of size 2 consisting the minimum and maximum x-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. y_filter Sets vector of size 2 consisting the minimum and maximum y-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. costmap_obs_inflation Sets inflation radius of obstacles to be considered in planning. Note that a higher value of the variable results in more conservative planning. occ_obs_deadzone Sets minimum distances from obstacles and robots for autonomy. dt Sets timestep. Note that a higher timestamp slows down the computation. visualise Enables visualisation of costmap. This is used only for debugging.","title":"4.2.2 Controller"},{"location":"sdk-config/auto-config/#423-state-estimator","text":"Variable Definition initial_x Sets initialization of x-axis for localizaition (in meters). initial_y Sets initialization of y-axis for localizaition (in meters). initial_z Sets initialization of z-axis for localizaition (in meters). initial_w Sets initialization of orientation for localizaition. kImuTopic ROS IMU (Inertial Measurement Unit) topic name for subscribing. kPoseTopic Enables localization result. ktfUpdate Sets ROS tf publishing frequency. kStatusUpdate Sets localisation status of publishing frequency. kLoggingUpdate Sets data logging period. kposeDiffmax Sets the maximum distance between two consecutive pose estimation. KUse_imu_ori Enables IMU (Inertial Measurement Unit) or odom orientation for odometry estimation. If this variable is set to true, ensure kImuTopic is available. kBadCovThres Sets localization quality. kGoodCovThres Sets localization quality. kCovBadMax Sets localization quality. kCovGoodtMax Sets localization quality. kFilter_z Enables pass through filter application for localization. klimit_min Sets minimum range of pass through filter. klimit_max Sets maximum range of pass through filter.","title":"4.2.3 State Estimator"},{"location":"sdk-config/auto-config/#424-planner","text":"Variable Definition lookAheadIndexv Sets look-ahead index from the nearest waypoint for path to follow. Note that a lower index slows down the movement of the robot. Similarly, a higher index results in the robot not follow path properly. enable_self_rotate Enables one round of rotation around the robot itself before performing autonomy. This is to ensure that localisation is working before starting autonomy. self_rotation_speed Sets angular velocity of robot to turn around itself before performing autonomy (in radiants/second). self_rotation_speed_final Sets angular velocity of robot to turn around itself after performing autonomy (in radiants/second). This ensures that the final orientation of robot aligns with its goal. dis_threshold Sets maximum euclidean distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. theta_threshold Sets maximum orientation distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. cmd_Smoothing Enables smoothing control commands.","title":"4.2.4 Planner"},{"location":"sdk-config/register-bot/","text":"Register Payload Configuration This section of the d.ASH SDK documentation provides details about the configuration file for payload registration - register_payload_config - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure payload registration. 2.1 Config File { \"robot_name\" : \"<ROBOT_NAME>\" , \"robot_username\" : \"<DC_USERNAME>\" } 2.2 Definitions Variable Definition robotName Set the name of your robot - this can be any string. robotUserName Set the name of your username - this has to match your dConstruct cloud admin username.","title":"2.0 Register Payload Configuration"},{"location":"sdk-config/register-bot/#register-payload-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for payload registration - register_payload_config - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure payload registration.","title":"Register Payload Configuration"},{"location":"sdk-config/register-bot/#21-config-file","text":"{ \"robot_name\" : \"<ROBOT_NAME>\" , \"robot_username\" : \"<DC_USERNAME>\" }","title":"2.1 Config File"},{"location":"sdk-config/register-bot/#22-definitions","text":"Variable Definition robotName Set the name of your robot - this can be any string. robotUserName Set the name of your username - this has to match your dConstruct cloud admin username.","title":"2.2 Definitions"},{"location":"sdk-config/rest-config/","text":"d.ASH Service Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the rest server - dash_service_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure the d.ASH service. 1.1 Config File { \"port\" : 3000 , \"cert_filename\" : \"./cert.pem\" , \"key_filename\" : \"./key.pem\" , \"dh_params_filename\" : \"\" , \"robot_register_native_cert\" : true , \"active_IP_idx\" : 1 , \"preferred_IP\" : \"10.8.0.5\" , \"run_cmds\" : { \"py_server\" : { \"cmd_str\" : \"python ./spot_server.py ./configs/dash-service-config.json <!TOKEN!>\" , \"cmd_path\" : \"C:/Users/dc/Documents/Projects/dc/dash_code/py_server\" } } } 1.2 Definitions 1.2.1 Main Variable Definition port Fixed port number. cert_filename Fixed certification filename. key_filename Fixed certification key filename. dh_params_filename Fixed parameter filename. robot_register_native_cert If you registed with register_bot_native, the data will be encrypted. Always set this variable to true. active_IP_idx Selects the IP address you will send to the backend cloud service for robot discovery. This is an integer index ( from 0 to N ), based on the IP addresses available on your system. When the rest service starts up, you should see a list. Set the value to the appropriate index you want. This index will map the the IP which the clients will try to connect to. preferred_IP Selects your preferred IP from the list of IPs. Specify the IP as a string in this case. 1.2.2 d.ASH Server Commands Variable Definition cmd_str Sets command to run d.ASH server. cmd_path Sets command path.","title":"1.0 d.ASH Service Configuration"},{"location":"sdk-config/rest-config/#dash-service-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the rest server - dash_service_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure the d.ASH service.","title":"d.ASH Service Configuration"},{"location":"sdk-config/rest-config/#11-config-file","text":"{ \"port\" : 3000 , \"cert_filename\" : \"./cert.pem\" , \"key_filename\" : \"./key.pem\" , \"dh_params_filename\" : \"\" , \"robot_register_native_cert\" : true , \"active_IP_idx\" : 1 , \"preferred_IP\" : \"10.8.0.5\" , \"run_cmds\" : { \"py_server\" : { \"cmd_str\" : \"python ./spot_server.py ./configs/dash-service-config.json <!TOKEN!>\" , \"cmd_path\" : \"C:/Users/dc/Documents/Projects/dc/dash_code/py_server\" } } }","title":"1.1 Config File"},{"location":"sdk-config/rest-config/#12-definitions","text":"","title":"1.2 Definitions"},{"location":"sdk-config/rest-config/#121-main","text":"Variable Definition port Fixed port number. cert_filename Fixed certification filename. key_filename Fixed certification key filename. dh_params_filename Fixed parameter filename. robot_register_native_cert If you registed with register_bot_native, the data will be encrypted. Always set this variable to true. active_IP_idx Selects the IP address you will send to the backend cloud service for robot discovery. This is an integer index ( from 0 to N ), based on the IP addresses available on your system. When the rest service starts up, you should see a list. Set the value to the appropriate index you want. This index will map the the IP which the clients will try to connect to. preferred_IP Selects your preferred IP from the list of IPs. Specify the IP as a string in this case.","title":"1.2.1 Main"},{"location":"sdk-config/rest-config/#122-dash-server-commands","text":"Variable Definition cmd_str Sets command to run d.ASH server. cmd_path Sets command path.","title":"1.2.2 d.ASH Server Commands"},{"location":"sdk-config/robot-config/","text":"Robot Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the robot - robot_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions used to configure the d.ASH server. 3.1 Config File { \"server_address\" : \"localhost:50051\" , \"robot_hostname\" : \"192.168.80.3\" , \"username\" : \"<USERNAME>\" , \"cam_list\" : [ \"RealsenseCam\" ], \"payloads\" : [], \"data_state_log_folder\" : \"G:/Temp/logs\" , \"ssl\" : true , \"fast_server\" : false , \"fast_server_hostname\" : \"localhost:7777\" , \"secure_default_token\" : false , \"test_mode\" : true , \"with_audio\" : true , \"real_sense_config\" : { \"test\" : true , \"test_filenames\" : [ \"../../test_videos/nus_left.mp4\" , \"../../test_videos/nus_center.mp4\" , \"../../test_videos/nus_right.mp4\" ], \"flip_options\" : { \"0\" : [ false , false ], \"1\" : [ true , true ], \"2\" : [ false , false ] }, \"base_width\" : 640 , \"base_height\" : 480 , \"codec\" : \"video\" , \"width\" : 320 , \"height\" : 240 , \"bitrate\" : 3600000 } } 3.2 Definitions 3.2.1 Main Variable Definition server_address Sets address of the d.ASH server in <HOSTNAME>:<PORT> format. robot_hostname Sets hostname of the Spot to connect to robot's IP. username Sets username for d.ASH server credentials. cam_list Sets a list of cameras active for the current session. payloads Optional payloads list. data_state_log_folder Sets folder to write out the recorded msgpack data of the robot. ssl Enables secure SSL messaging and encryption. test_mode Enables the d.ASH server to enter into test mode. with_audio Enables audio streaming playback. 3.2.2 Intel RealSense Configuration Variable Definition test Enables simulation of camera streaming via provided custom mp4 video files specified as a list in test_filenames . test_filenames List of test files. flip_options Specify how each camera flips long the x-axis and y-axis following the format {\"index\" : [x-flip, y-flip]} . baseWidth Sets processing width of the camera stream. Note that a minimum baseWidth of 640 is required. baseHeight Sets the processing height of the camera stream. Note that a minimum baseHeight of 360 is required. codec Sets jpg/video options, with jpg being regular jpeg encoding and video using VP9 encoding. width Adjusts the final returned/resized width dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. height Adjusts the final returned/resized height dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. bitrate This is the quality of the video encoding. Note for HD Streaming, RealSense requires a high bitrate of 3600000.","title":"3.0 Robot Configuration"},{"location":"sdk-config/robot-config/#robot-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the robot - robot_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions used to configure the d.ASH server.","title":"Robot Configuration"},{"location":"sdk-config/robot-config/#31-config-file","text":"{ \"server_address\" : \"localhost:50051\" , \"robot_hostname\" : \"192.168.80.3\" , \"username\" : \"<USERNAME>\" , \"cam_list\" : [ \"RealsenseCam\" ], \"payloads\" : [], \"data_state_log_folder\" : \"G:/Temp/logs\" , \"ssl\" : true , \"fast_server\" : false , \"fast_server_hostname\" : \"localhost:7777\" , \"secure_default_token\" : false , \"test_mode\" : true , \"with_audio\" : true , \"real_sense_config\" : { \"test\" : true , \"test_filenames\" : [ \"../../test_videos/nus_left.mp4\" , \"../../test_videos/nus_center.mp4\" , \"../../test_videos/nus_right.mp4\" ], \"flip_options\" : { \"0\" : [ false , false ], \"1\" : [ true , true ], \"2\" : [ false , false ] }, \"base_width\" : 640 , \"base_height\" : 480 , \"codec\" : \"video\" , \"width\" : 320 , \"height\" : 240 , \"bitrate\" : 3600000 } }","title":"3.1 Config File"},{"location":"sdk-config/robot-config/#32-definitions","text":"","title":"3.2 Definitions"},{"location":"sdk-config/robot-config/#321-main","text":"Variable Definition server_address Sets address of the d.ASH server in <HOSTNAME>:<PORT> format. robot_hostname Sets hostname of the Spot to connect to robot's IP. username Sets username for d.ASH server credentials. cam_list Sets a list of cameras active for the current session. payloads Optional payloads list. data_state_log_folder Sets folder to write out the recorded msgpack data of the robot. ssl Enables secure SSL messaging and encryption. test_mode Enables the d.ASH server to enter into test mode. with_audio Enables audio streaming playback.","title":"3.2.1 Main"},{"location":"sdk-config/robot-config/#322-intel-realsense-configuration","text":"Variable Definition test Enables simulation of camera streaming via provided custom mp4 video files specified as a list in test_filenames . test_filenames List of test files. flip_options Specify how each camera flips long the x-axis and y-axis following the format {\"index\" : [x-flip, y-flip]} . baseWidth Sets processing width of the camera stream. Note that a minimum baseWidth of 640 is required. baseHeight Sets the processing height of the camera stream. Note that a minimum baseHeight of 360 is required. codec Sets jpg/video options, with jpg being regular jpeg encoding and video using VP9 encoding. width Adjusts the final returned/resized width dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. height Adjusts the final returned/resized height dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. bitrate This is the quality of the video encoding. Note for HD Streaming, RealSense requires a high bitrate of 3600000.","title":"3.2.2 Intel RealSense Configuration"},{"location":"setup/dash/","text":"Setting Up d.ASH As mentioned previously, the d.ASH consists of three main components - d.ASH server, d.ASH service, and d.ASH autonomy engine. This section of the d.ASH SDK documentation provides details about setting up the d.ASH components including compiling and testing. 4.1 Installing d.ASH Dependencies To install the remaining d.ASH dependencies using pip, the following desktop dependencies must be set up prior: Intel RealSense SDK 2.0 ROS Melodic on Ubuntu 18.04 FFmpeg and others If the above dependencies have been installed, proceed by running the following command to install the rest of the python packages: python3.7 config_libs.py Please ensure you are in the \\dash-sdk directory before running. Following the instructions prompted by the terminal to proceed with installation. 4.2 Setting up d.ASH Server To set up the d.ASH server, you will need to configure the d.ASH server configuration file - robot_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 robot_config.json \u2514\u2500 ... Follow the variable definitions for robot_config.json to set up the file correctly for the d.ASH server. Once robot_config.json has been set up, run the d.ASH server by executing the following command on your terminal: python3 .7 ./ dash_server . py robot_config . json 4.3 Setting up d.ASH Service To set up the d.ASH service, you will need to configure the d.ASH service configuration file - dash_service_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 dash_service_config.json \u2514\u2500 ... First, run runrest to see available IP address for your rest server: runrest Pick the index of the IP address you like and append it to the activeIPIdx variable in dash_service_config.json : \"activeIPIdx\" : 1, # where '1' is the chosen IP address index Then, you will need to set your preferredIP address, that is, the IP address for the computer onboard your robot. This IP address will have precedence over activeIPIdx . Similarly, replace the default IP address with your preferred IP address in dash_service_config.json : \"preferredIP\" : \"10.8.0.5\", # where '10.8.0.5' is the preferred IP address Ensure that the IP address of the onboard computer is within the same subnet by the remote client. Lastly, you will need to change the <PATH_OF_SDK> of cmdPath in dash_service_config.json : \"cmdPath\" : \"<PATH>\" To do this, use pwd to print your current working directory path and replace <PATH_OF_SDK> with the path printed. For example, if your current directory is /home/dash_sdk/py_server : \"cmdPath\" : \"/home/dash_sdk\" To test the d.ASH service, you'll need to run the d.ASH server by running the following command: ./ robot_rest < PATH_TO_SDK >/ configs / dash_service_config . json Now that your d.ASH service is running, you can use our d.ASH Pilot app. To launch the d.ASH Pilot app, simply search for it in your Windows search bar. Now, login to the system and connect to your robot to start controlling your robot. For more information on the d.ASH Pilot, refer to the d.ASH Pilot guide . 4.4 Setting up d.ASH Autonomy Engine To set up the d.ASH autonomy engine, you will need to configure the d.ASH autonomy configuration file - auto_config.json - located in the folder /dash-sdk/configs/ . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 auto_config.json \u2514\u2500 ... Follow the variable definitions for auto_config.json to set up the file correctly for the d.ASH autonomy engine. Once auto_config.json has been set up, test the d.ASH autonomy engine by run the executable below to start autonomy driver. Note to replace <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: ./dash_autonomy <PATH_TO_SDK>/config/auto_config.json To find your current working directory, use pwd . For example, if your directory is /home/dash-sdk , you would run the following command to test d.ASH autonomy: ./dash_autonomy /home/dash-sdk/config/auto_config.json You will need to run d.ASH service first before running the d.ASH server and the d.ASH autonomy engine. On a seperate terminal, start a simple roslaunch test by running the following prompt, replacing <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: cd \\launch roslaunch <PATH_TO_SDK>\\dash_sdk\\launch\\simple_joy.launch Launch files have been prepared for setup - either with the Velodyne VLP-16 lidar sensor or the Ouster OS1-32 lidar sensor. These lauch files can be found in under the \\dash-sdk\\launch folder. You can also create your own sensor launch files for your tests.","title":"4.0 Setting up d.ASH"},{"location":"setup/dash/#setting-up-dash","text":"As mentioned previously, the d.ASH consists of three main components - d.ASH server, d.ASH service, and d.ASH autonomy engine. This section of the d.ASH SDK documentation provides details about setting up the d.ASH components including compiling and testing.","title":"Setting Up d.ASH"},{"location":"setup/dash/#41-installing-dash-dependencies","text":"To install the remaining d.ASH dependencies using pip, the following desktop dependencies must be set up prior: Intel RealSense SDK 2.0 ROS Melodic on Ubuntu 18.04 FFmpeg and others If the above dependencies have been installed, proceed by running the following command to install the rest of the python packages: python3.7 config_libs.py Please ensure you are in the \\dash-sdk directory before running. Following the instructions prompted by the terminal to proceed with installation.","title":"4.1 Installing d.ASH Dependencies"},{"location":"setup/dash/#42-setting-up-dash-server","text":"To set up the d.ASH server, you will need to configure the d.ASH server configuration file - robot_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 robot_config.json \u2514\u2500 ... Follow the variable definitions for robot_config.json to set up the file correctly for the d.ASH server. Once robot_config.json has been set up, run the d.ASH server by executing the following command on your terminal: python3 .7 ./ dash_server . py robot_config . json","title":"4.2 Setting up d.ASH Server"},{"location":"setup/dash/#43-setting-up-dash-service","text":"To set up the d.ASH service, you will need to configure the d.ASH service configuration file - dash_service_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 dash_service_config.json \u2514\u2500 ... First, run runrest to see available IP address for your rest server: runrest Pick the index of the IP address you like and append it to the activeIPIdx variable in dash_service_config.json : \"activeIPIdx\" : 1, # where '1' is the chosen IP address index Then, you will need to set your preferredIP address, that is, the IP address for the computer onboard your robot. This IP address will have precedence over activeIPIdx . Similarly, replace the default IP address with your preferred IP address in dash_service_config.json : \"preferredIP\" : \"10.8.0.5\", # where '10.8.0.5' is the preferred IP address Ensure that the IP address of the onboard computer is within the same subnet by the remote client. Lastly, you will need to change the <PATH_OF_SDK> of cmdPath in dash_service_config.json : \"cmdPath\" : \"<PATH>\" To do this, use pwd to print your current working directory path and replace <PATH_OF_SDK> with the path printed. For example, if your current directory is /home/dash_sdk/py_server : \"cmdPath\" : \"/home/dash_sdk\" To test the d.ASH service, you'll need to run the d.ASH server by running the following command: ./ robot_rest < PATH_TO_SDK >/ configs / dash_service_config . json Now that your d.ASH service is running, you can use our d.ASH Pilot app. To launch the d.ASH Pilot app, simply search for it in your Windows search bar. Now, login to the system and connect to your robot to start controlling your robot. For more information on the d.ASH Pilot, refer to the d.ASH Pilot guide .","title":"4.3 Setting up d.ASH Service"},{"location":"setup/dash/#44-setting-up-dash-autonomy-engine","text":"To set up the d.ASH autonomy engine, you will need to configure the d.ASH autonomy configuration file - auto_config.json - located in the folder /dash-sdk/configs/ . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 auto_config.json \u2514\u2500 ... Follow the variable definitions for auto_config.json to set up the file correctly for the d.ASH autonomy engine. Once auto_config.json has been set up, test the d.ASH autonomy engine by run the executable below to start autonomy driver. Note to replace <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: ./dash_autonomy <PATH_TO_SDK>/config/auto_config.json To find your current working directory, use pwd . For example, if your directory is /home/dash-sdk , you would run the following command to test d.ASH autonomy: ./dash_autonomy /home/dash-sdk/config/auto_config.json You will need to run d.ASH service first before running the d.ASH server and the d.ASH autonomy engine. On a seperate terminal, start a simple roslaunch test by running the following prompt, replacing <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: cd \\launch roslaunch <PATH_TO_SDK>\\dash_sdk\\launch\\simple_joy.launch Launch files have been prepared for setup - either with the Velodyne VLP-16 lidar sensor or the Ouster OS1-32 lidar sensor. These lauch files can be found in under the \\dash-sdk\\launch folder. You can also create your own sensor launch files for your tests.","title":"4.4 Setting up d.ASH Autonomy Engine"},{"location":"setup/desktop-dep/","text":"Installing Dependencies on the Desktop While most of the d.ASH SDK build is hermetic, some system dependencies on the Desktop are required. This section of the d.ASH SDK documentation provides details for Intel RealSense SDK, Ubuntu, ROS Melodic, and FFmpeg installations. 1.1 Ubuntu Installation Ubuntu is a complete Linux operating system, which will serve as the primary platform for ROS. Currently, the d.ASH SDK only supports Linux Ubuntu 18.04 LTS for development and simulation from your workstation. Ubuntu Installation via Bootable USB If you would like to install Ubuntu via a bootable USB, you can do so for both Windows and MacOS . Ubuntu Installation via Virtual Machine If you would like to install Ubuntu via a virtual machine, you can do so using VirtualBox to kickstart your installation process. Once Ubuntu is installed, check that your version of Ubuntu has the release code 18.04 . Open the terminal and type the command: lsb_release - a This should print the following result: No LSB modules are available . Distributor ID : Ubuntu Description : Ubuntu 18.04.5 LTS Release : 18.04 Codename : bionic 1.2 ROS Installation ROS (Robot Operating System) is a open-source framework that helps researchers and developers build and reuse code between robotics applications. Currently, the d.ASH SDK only supports ROS Melodic for development and simulation from your workstation. Use Ubuntu to install ROS Melodic onto your computer system. Once ROS has been installed on your Linux system, check that your version of ROS is melodic . Open the terminal and type the command: rosversion - d This should print melodic . Otherwise, ensure that you installed the correct version of ROS - ROS Melodic . 1.3 Intel RealSense SDK Installation Intel RealSense is an RGB camera with channels designed for depth perception capabilities. The RealSense SDK 2.0 provides installation packages for Intel X86 / AMD64-based Debian distributions in dpkg format for Ubuntu 16/18/20 LTS. You'll be able to configure custom settings for any Intel RealSense cameras attached to the system to stream images to remote clients. Use Ubuntu to install Intel RealSense SDK 2.0 onto your computer system. 1.4 FFmpeg Installation FFmpeg is an open-source software project consisting of libraries and programs that handle video, audio, and other multimedia files and streams. To install FFmpeg, run the following commands on your Ubuntu terminal: sudo add-apt-repository ppa:jonathonf/ffmpeg-4 sudo apt-get install ffmpeg libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev libavutil-dev libpostproc-dev libswresample-dev libswscale-dev libgoogle-glog-dev 1.5 Python Requirements The d.ASH SDK works with Python 3.7 . To properly run the server, you will also need to install a python package installer, pip. 1.5.1 apt-get Installed in Ubuntu and any Ubuntu-based Linux distribution, apt-get is tool for installing, upgrading, and cleaning packages. To set up the new environment, execute the following command on your Ubuntu terminal: sudo apt-get install -y python3.7-dev 1.5.2 Pip Installation Pip is a package installer for Python. The d.ASH SDK and the third-party packages used by many of its programming examples use pip to install. To install pip, run the following command on your Ubuntu terminal: sudo apt install python3 .7 python3 - pip python - pip python3 .7 - m pip instal -- upgrade pip","title":"1.0 Installing Desktop Dependencies"},{"location":"setup/desktop-dep/#installing-dependencies-on-the-desktop","text":"While most of the d.ASH SDK build is hermetic, some system dependencies on the Desktop are required. This section of the d.ASH SDK documentation provides details for Intel RealSense SDK, Ubuntu, ROS Melodic, and FFmpeg installations.","title":"Installing Dependencies on the Desktop"},{"location":"setup/desktop-dep/#11-ubuntu-installation","text":"Ubuntu is a complete Linux operating system, which will serve as the primary platform for ROS. Currently, the d.ASH SDK only supports Linux Ubuntu 18.04 LTS for development and simulation from your workstation. Ubuntu Installation via Bootable USB If you would like to install Ubuntu via a bootable USB, you can do so for both Windows and MacOS . Ubuntu Installation via Virtual Machine If you would like to install Ubuntu via a virtual machine, you can do so using VirtualBox to kickstart your installation process. Once Ubuntu is installed, check that your version of Ubuntu has the release code 18.04 . Open the terminal and type the command: lsb_release - a This should print the following result: No LSB modules are available . Distributor ID : Ubuntu Description : Ubuntu 18.04.5 LTS Release : 18.04 Codename : bionic","title":"1.1 Ubuntu Installation"},{"location":"setup/desktop-dep/#12-ros-installation","text":"ROS (Robot Operating System) is a open-source framework that helps researchers and developers build and reuse code between robotics applications. Currently, the d.ASH SDK only supports ROS Melodic for development and simulation from your workstation. Use Ubuntu to install ROS Melodic onto your computer system. Once ROS has been installed on your Linux system, check that your version of ROS is melodic . Open the terminal and type the command: rosversion - d This should print melodic . Otherwise, ensure that you installed the correct version of ROS - ROS Melodic .","title":"1.2 ROS Installation"},{"location":"setup/desktop-dep/#13-intel-realsense-sdk-installation","text":"Intel RealSense is an RGB camera with channels designed for depth perception capabilities. The RealSense SDK 2.0 provides installation packages for Intel X86 / AMD64-based Debian distributions in dpkg format for Ubuntu 16/18/20 LTS. You'll be able to configure custom settings for any Intel RealSense cameras attached to the system to stream images to remote clients. Use Ubuntu to install Intel RealSense SDK 2.0 onto your computer system.","title":"1.3 Intel RealSense SDK Installation"},{"location":"setup/desktop-dep/#14-ffmpeg-installation","text":"FFmpeg is an open-source software project consisting of libraries and programs that handle video, audio, and other multimedia files and streams. To install FFmpeg, run the following commands on your Ubuntu terminal: sudo add-apt-repository ppa:jonathonf/ffmpeg-4 sudo apt-get install ffmpeg libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev libavutil-dev libpostproc-dev libswresample-dev libswscale-dev libgoogle-glog-dev","title":"1.4 FFmpeg Installation"},{"location":"setup/desktop-dep/#15-python-requirements","text":"The d.ASH SDK works with Python 3.7 . To properly run the server, you will also need to install a python package installer, pip.","title":"1.5 Python Requirements"},{"location":"setup/desktop-dep/#151-apt-get","text":"Installed in Ubuntu and any Ubuntu-based Linux distribution, apt-get is tool for installing, upgrading, and cleaning packages. To set up the new environment, execute the following command on your Ubuntu terminal: sudo apt-get install -y python3.7-dev","title":"1.5.1 apt-get"},{"location":"setup/desktop-dep/#152-pip-installation","text":"Pip is a package installer for Python. The d.ASH SDK and the third-party packages used by many of its programming examples use pip to install. To install pip, run the following command on your Ubuntu terminal: sudo apt install python3 .7 python3 - pip python - pip python3 .7 - m pip instal -- upgrade pip","title":"1.5.2 Pip Installation"},{"location":"setup/payload-reg/","text":"Payload Registration Before running the d.ASH SDK, please make sure that all of your credentials have been set up correctly. This means using the right username and the right password. This section of the d.ASH SDK documentation provides details about setting up credentials for the d.ASH server, your robot, and d.ASH autonomy. Files in this section can be found in the folder registration : dash-sdk/ \u2514\u2500 registration \u2514\u2500 set_spot_cred \u2514\u2500 register_payload \u2514\u2500 set_autonomy_cred 2.1 d.ASH Server Credentials To set up the local credentials for the d.ASH server, you will need to run the file set_spot_cred . Run the following command replacing <USERNAME> with your chosen username and <PASSWORD> with your chosen password. ./set_spot_cred -u <USERNAME> -p <PASSWORD> For example, if your username is user123 and your password is pw123 , your command would look like this: ./ set_spot_cred - u user123 - p pw123 Username in Robot Configuration Please ensure that the username for the d.ASH server is the same as the one defined in the robot configuration file - robot_config.json . That is, you would replace <USERNAME> with your chosen username in \"username\" : \"<USERNAME>\" . 2.2 Robot Registration To register the payload computer with d.ASH's backend system, you will need to run the file register_payload . However, you will first need to configure the register_payload_config.json found in the \\dash-sdk\\configs folder of the SDK. Set <ROBOT_NAME> to any name you like, and set <DC_USERNAME> to your dConstruct cloud admin username. For example, if your robot name is robot1 and your cloud admin user name is user123 , your register_payload_config.json would look like this: { RobotName: robot1, RobotUserName: user123 } Now, run the following command to register your robot, replacing <PATH_TO_SDK> with your local path to the d.ASH SDK. ./register_payload -i <PATH_TO_SDK>/dash_sdk/configs/register_payload_config 2.3 d.ASH Autonomy Credentials To set up the local credentials for d.ASH autonomy, you will need to run the file set_autonomy_cred . Run the following command replacing <USERNAME> with your cloud admin username. cd ./ set_auto_cred / build ./ set_autonomy_cred - u < USERNAME > For example, if your username is user123 , your command would look like this: cd ./ set_auto_cred / build ./ set_autonomy_cred - u user123 You will then be prompted to enter a password, which will match your cloud admin password. Enter","title":"2.0 Payload Registration"},{"location":"setup/payload-reg/#payload-registration","text":"Before running the d.ASH SDK, please make sure that all of your credentials have been set up correctly. This means using the right username and the right password. This section of the d.ASH SDK documentation provides details about setting up credentials for the d.ASH server, your robot, and d.ASH autonomy. Files in this section can be found in the folder registration : dash-sdk/ \u2514\u2500 registration \u2514\u2500 set_spot_cred \u2514\u2500 register_payload \u2514\u2500 set_autonomy_cred","title":"Payload Registration"},{"location":"setup/payload-reg/#21-dash-server-credentials","text":"To set up the local credentials for the d.ASH server, you will need to run the file set_spot_cred . Run the following command replacing <USERNAME> with your chosen username and <PASSWORD> with your chosen password. ./set_spot_cred -u <USERNAME> -p <PASSWORD> For example, if your username is user123 and your password is pw123 , your command would look like this: ./ set_spot_cred - u user123 - p pw123 Username in Robot Configuration Please ensure that the username for the d.ASH server is the same as the one defined in the robot configuration file - robot_config.json . That is, you would replace <USERNAME> with your chosen username in \"username\" : \"<USERNAME>\" .","title":"2.1 d.ASH Server Credentials"},{"location":"setup/payload-reg/#22-robot-registration","text":"To register the payload computer with d.ASH's backend system, you will need to run the file register_payload . However, you will first need to configure the register_payload_config.json found in the \\dash-sdk\\configs folder of the SDK. Set <ROBOT_NAME> to any name you like, and set <DC_USERNAME> to your dConstruct cloud admin username. For example, if your robot name is robot1 and your cloud admin user name is user123 , your register_payload_config.json would look like this: { RobotName: robot1, RobotUserName: user123 } Now, run the following command to register your robot, replacing <PATH_TO_SDK> with your local path to the d.ASH SDK. ./register_payload -i <PATH_TO_SDK>/dash_sdk/configs/register_payload_config","title":"2.2 Robot Registration"},{"location":"setup/payload-reg/#23-dash-autonomy-credentials","text":"To set up the local credentials for d.ASH autonomy, you will need to run the file set_autonomy_cred . Run the following command replacing <USERNAME> with your cloud admin username. cd ./ set_auto_cred / build ./ set_autonomy_cred - u < USERNAME > For example, if your username is user123 , your command would look like this: cd ./ set_auto_cred / build ./ set_autonomy_cred - u user123 You will then be prompted to enter a password, which will match your cloud admin password. Enter","title":"2.3 d.ASH Autonomy Credentials"},{"location":"setup/vpn/","text":"Setting Up d.ASH VPN When setting up VPN for d.ASH, two separate login credentials are required for two seperate VPN connections - one for the robot onboard computer and one for the remote client. This section of the d.ASH SDK documentation provides details about setting up the d.ASH VPN for both your robot and your remote client. 3.1 Setting Up VPN Onboard Computer To start, you will need to install some packages to configure automatic VPN connection on Ubuntu 18.04 LTS by executing the following command: sudo apt install network - manager - openvpn network - manager - openvpn - gnome openvpn openvpn - systemd - resolved - y This will install an openvpn package, which creates a /etc/openvpn/client/ directory into which you can place the OpenVPN client configuration file. You will need to configure the VPN configuration file - client.ovpn which can be found in your vpn folder /dash_sdk/vpn . dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Note that <USER> in this instance is replaced by your dConstruct admin username. Now, you will need to copy client.ovpn and your user certifications - ca.crt , <USER>.crt , <USER>.key - into the new open vpn directory. In the /dash_sdk directory, execute the following commands: python3 .7 config_vpn . py sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt < USER >. crt < USER >. key / etc / openvpn / client For example, if your dConstruct admin username is user123 , you would replacing <USER> with user123 : sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt user123 . crt user123 . key / etc / openvpn / client To check that your files have been copied and renamed correctly, cd into the /etc/openvpn/client directory and ls to see your list of files. You should have client.conf and your user certification files, namely ca.crt <USER>.crt <USER>.key : etc/ \u2514\u2500 openvpn/ \u2514\u2500 client/ \u2514\u2500 client.conf \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Now, let's test that the VPN service was set up correctly by running the following command: sudo systemctl start openvpn - client @client . service If there is no error print, proceed onto the next step. If you come across a failure, ensure that the path in client.conf matches the following format: cat \\ etc \\ openvpn \\ client \\ ca . crt cert \\ etc \\ openvpn \\ client \\ < USER >. crt key \\ etc \\ openvpn \\ client \\ < USER >. crt Now, to check your VPN status, enter the following command: sudo systemctl status openvpn - client @client . service If successful, you should be able to see the status Initialization Sequence Completed . Lastly, enable the VPN onboard your computer by executing the following command: sudo systemctl enable openvpn - client @client . service 3.2 Setting Up VPN Remote Client Remember to use a separate login credential from the robot onboard computer credentials as at any point in time, there can only be one active user session. Firstly, download OpenVPN Connect . Once OpenVPN has been launched, click on the tab - 'Import from File' tab and drag-and-drop the client.ovpn file located in \\dash-sdk\\vpn . It is important to note that the client.ovpn file has to be in the same directory as there certification files, namely ca.crt <USER>.crt <USER>.key : dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key","title":"3.0 Setting up d.ASH VPN"},{"location":"setup/vpn/#setting-up-dash-vpn","text":"When setting up VPN for d.ASH, two separate login credentials are required for two seperate VPN connections - one for the robot onboard computer and one for the remote client. This section of the d.ASH SDK documentation provides details about setting up the d.ASH VPN for both your robot and your remote client.","title":"Setting Up d.ASH VPN"},{"location":"setup/vpn/#31-setting-up-vpn-onboard-computer","text":"To start, you will need to install some packages to configure automatic VPN connection on Ubuntu 18.04 LTS by executing the following command: sudo apt install network - manager - openvpn network - manager - openvpn - gnome openvpn openvpn - systemd - resolved - y This will install an openvpn package, which creates a /etc/openvpn/client/ directory into which you can place the OpenVPN client configuration file. You will need to configure the VPN configuration file - client.ovpn which can be found in your vpn folder /dash_sdk/vpn . dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Note that <USER> in this instance is replaced by your dConstruct admin username. Now, you will need to copy client.ovpn and your user certifications - ca.crt , <USER>.crt , <USER>.key - into the new open vpn directory. In the /dash_sdk directory, execute the following commands: python3 .7 config_vpn . py sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt < USER >. crt < USER >. key / etc / openvpn / client For example, if your dConstruct admin username is user123 , you would replacing <USER> with user123 : sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt user123 . crt user123 . key / etc / openvpn / client To check that your files have been copied and renamed correctly, cd into the /etc/openvpn/client directory and ls to see your list of files. You should have client.conf and your user certification files, namely ca.crt <USER>.crt <USER>.key : etc/ \u2514\u2500 openvpn/ \u2514\u2500 client/ \u2514\u2500 client.conf \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Now, let's test that the VPN service was set up correctly by running the following command: sudo systemctl start openvpn - client @client . service If there is no error print, proceed onto the next step. If you come across a failure, ensure that the path in client.conf matches the following format: cat \\ etc \\ openvpn \\ client \\ ca . crt cert \\ etc \\ openvpn \\ client \\ < USER >. crt key \\ etc \\ openvpn \\ client \\ < USER >. crt Now, to check your VPN status, enter the following command: sudo systemctl status openvpn - client @client . service If successful, you should be able to see the status Initialization Sequence Completed . Lastly, enable the VPN onboard your computer by executing the following command: sudo systemctl enable openvpn - client @client . service","title":"3.1 Setting Up VPN Onboard Computer"},{"location":"setup/vpn/#32-setting-up-vpn-remote-client","text":"Remember to use a separate login credential from the robot onboard computer credentials as at any point in time, there can only be one active user session. Firstly, download OpenVPN Connect . Once OpenVPN has been launched, click on the tab - 'Import from File' tab and drag-and-drop the client.ovpn file located in \\dash-sdk\\vpn . It is important to note that the client.ovpn file has to be in the same directory as there certification files, namely ca.crt <USER>.crt <USER>.key : dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key","title":"3.2 Setting Up VPN Remote Client"}]}