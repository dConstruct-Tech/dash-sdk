{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dConstruct d.ASH SDK The dConstruct d.ASH SDK is a cross-platform library for autonomous robot navigation. Use the d.ASH SDK to develop applications for your own Spot from Boston Dynamics or any other robot you wish. This section of the d.ASH SDK documentation provides details about the components of the SDK. Component Description d.ASH Server The d.ASH server acts as the main server responsible for sending control commands to the robot. At the same time, the d.ASH server also broadcasts secured data to any given remote systems. d.ASH Autonomy Engine The d.ASH Autonomy Engine is the autonomy backend code that runs on the edge of the robot. It empowers the robot with robust multi-terrain (indoor and outdoor) autonomous navigation capabilities. It handles secure communication between automony engine and the remote autonomy controller. d.ASH Autonomy Controller The d.ASH autonomy controller is the GUI (graphical user interface) for the d.ASH autonomy engine. It enable users to monitor and have full remote control of autonomy by allowing users to plot waypoints and activate autonomy on a fleet of robots. Stream real-time data via a secure connection between robots and the controller using 4G or 5G. If you decide to use your own custom GUI in place of the d.ASH autonomy controller, or you do not want to run autonomy, you will still need to implement the d.ASH server and the d.ASH autonomy engine to operate your robot.","title":"Introduction"},{"location":"#dconstruct-dash-sdk","text":"The dConstruct d.ASH SDK is a cross-platform library for autonomous robot navigation. Use the d.ASH SDK to develop applications for your own Spot from Boston Dynamics or any other robot you wish. This section of the d.ASH SDK documentation provides details about the components of the SDK. Component Description d.ASH Server The d.ASH server acts as the main server responsible for sending control commands to the robot. At the same time, the d.ASH server also broadcasts secured data to any given remote systems. d.ASH Autonomy Engine The d.ASH Autonomy Engine is the autonomy backend code that runs on the edge of the robot. It empowers the robot with robust multi-terrain (indoor and outdoor) autonomous navigation capabilities. It handles secure communication between automony engine and the remote autonomy controller. d.ASH Autonomy Controller The d.ASH autonomy controller is the GUI (graphical user interface) for the d.ASH autonomy engine. It enable users to monitor and have full remote control of autonomy by allowing users to plot waypoints and activate autonomy on a fleet of robots. Stream real-time data via a secure connection between robots and the controller using 4G or 5G. If you decide to use your own custom GUI in place of the d.ASH autonomy controller, or you do not want to run autonomy, you will still need to implement the d.ASH server and the d.ASH autonomy engine to operate your robot.","title":"dConstruct d.ASH SDK"},{"location":"dash-auto/autonomy-client/","text":"d.ASH Autonomy Controller As mentioned previously, the d.ASH autonomy controller is a GUI (graphical user interface) for the d.ASH SDK. It allows users to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning. This section of the d.ASH SDK documentation provides details about setting up the d.ASH autonomy controller, including information on its respective components. d.ASH Autonomy Controller Description Pair d.C Pilot with d.ASH Autonomy Controller for remote autonomous operations. This app allows you to control multiple robots and author + run autonomous waypoint missions configured with different payloads. Camera Controls You can pan/zoom/fly around the 3D Map Visualization World via the following controls: Tilt/Camera LookAt: Hold down the Left Mouse Button and drag Zoom: Use the mouse scroll wheel to zoom in/zoom out Move Around: Use the WASD keys to pan/move around the world General Workflow The general workflow to operate and run an autonomous waypoint mission is as follows: Login to the Autonomy Controller Load the point cloud map of your deployment location generated with d.ASH Pack into the app Create a new mission Route and plot the waypoints Connect to your desired robot in your robot fleet Set the robot's initial starting pose on the 3D map Start the robot with the route for your new mission 1.0 Load Point Cloud Map Click on the Point Cloud icon to open up the point cloud loading window. Then click on Load Point Cloud . A file dialog will pop up to allow you to load your desired point cloud from disk. Make sure the same point cloud map is also configured on the robot(s). 1.1 Robot Fleet Manager The lower expandable panel opens up the Robot Fleet Manager . This displays the list of robots currently registered and also alive under your user account. You connect your desired robot by locating your robot in the icon list and then clicking on the connect icon. When the robot is connected, the following display appears: You are now able to inspect various properties of the robot ( battery status, LIDAR color etc. ) as well as start launching autonomous waypoint missions for this connected robot. 1.2 General Settings The General Settings expandable panel from the left side of the screen. In here you can configure various options to streamline robot operations. General: This allows the customization of route/waypoint + map display settings Robot Viz: Visualization settings pertaining to the robots operated in the app Map Viz: Visualization settings for the 3D map display. In particular, use the Floor and Ceiling sliders to adjust how much of the 3D map height-wise 1.3 Routes + Waypoints This subpanel can be accessed by expanding the panel on the right side of the screen. It allows you to manage the various mission routes available for your robots. To create a new route, you do the following: Enter a new Route Name in the textbox provided Click the + button to add a new route Select the newly route by clicking on it Now go into the main 3D Map display to start plotting your waypoints for the route. You can Append/Splice/Modify a route via the subpanel below: With the desired waypoint plotting option selected, you can go ahead and plot the waypoint directly with the mouse: Tap the ESC key to exit the waypoint plotting operation. If you need to delete a waypoint, you can select it via a mouse click on the 3D Map, then press the Delete key. 1.4 Settings the Initial Robot Pose When you activate a new robot into the app, the first required step is to tell the system where the robot is and where it is facing in relation to the 3D map. This step is defined as setting the Initial Pose of the robot. You set the Initial Pose via the following steps: Click on the Initial Pose arrow button on the lower expandable panel to start the Initial Pose operation: Go to the 3D map, hold down your mouse on the part of the map where the robot is. Drag a direction and release to set the pose of the robot If the pose was set incorrectly, you can repeat steps 1 and 2 until the LIDAR scans of the robot matches that of the 3D map. This is when you know the Initial Pose is setup correctly. Take Note: It is very important the Initial Pose of the robot is setup correctly before starting any Waypoint Autonomy Mission ! Incorrect initial poses will result in the robot unable to localize correctly leading to mission failure. 1.5 Mission Routes/Management This expandable panel located at the top part of the screen allows you to start new waypoint missions as well as manage existing missions. To start a new mission: Enter a new mission name in the textbox, then press the + button to add a new mission Select the new mission and press the Run button to start it You should now see your robot move in the 3D map viewer along the mission route 1.6 Robot Camera Streaming You can activate any available cameras on the robot via the Camera Stream button circled red above. When pressed, a new Camera Stream window pops up: Select the robot which you will want to stream the camera from via the top drop down box. Then use the lower drop down box to select which of the available robot cameras to stream from. 1.7 Robot Remote Piloting/TeleOps The app also allows basic remote manual piloting of your robots. Just like the Pilot Client , plug in a regular joystick into your system to begin manually piloting your robots. You will have to activate the robot for manual control via the manual control button located in the lower expandable panel before piloting is enabled.","title":"1.0 d.ASH Autonomy Controller"},{"location":"dash-auto/autonomy-client/#dash-autonomy-controller","text":"As mentioned previously, the d.ASH autonomy controller is a GUI (graphical user interface) for the d.ASH SDK. It allows users to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning. This section of the d.ASH SDK documentation provides details about setting up the d.ASH autonomy controller, including information on its respective components. d.ASH Autonomy Controller Description Pair d.C Pilot with d.ASH Autonomy Controller for remote autonomous operations. This app allows you to control multiple robots and author + run autonomous waypoint missions configured with different payloads.","title":"d.ASH Autonomy Controller"},{"location":"dash-auto/autonomy-client/#camera-controls","text":"You can pan/zoom/fly around the 3D Map Visualization World via the following controls: Tilt/Camera LookAt: Hold down the Left Mouse Button and drag Zoom: Use the mouse scroll wheel to zoom in/zoom out Move Around: Use the WASD keys to pan/move around the world","title":"Camera Controls"},{"location":"dash-auto/autonomy-client/#general-workflow","text":"The general workflow to operate and run an autonomous waypoint mission is as follows: Login to the Autonomy Controller Load the point cloud map of your deployment location generated with d.ASH Pack into the app Create a new mission Route and plot the waypoints Connect to your desired robot in your robot fleet Set the robot's initial starting pose on the 3D map Start the robot with the route for your new mission","title":"General Workflow"},{"location":"dash-auto/autonomy-client/#10-load-point-cloud-map","text":"Click on the Point Cloud icon to open up the point cloud loading window. Then click on Load Point Cloud . A file dialog will pop up to allow you to load your desired point cloud from disk. Make sure the same point cloud map is also configured on the robot(s).","title":"1.0 Load Point Cloud Map"},{"location":"dash-auto/autonomy-client/#11-robot-fleet-manager","text":"The lower expandable panel opens up the Robot Fleet Manager . This displays the list of robots currently registered and also alive under your user account. You connect your desired robot by locating your robot in the icon list and then clicking on the connect icon. When the robot is connected, the following display appears: You are now able to inspect various properties of the robot ( battery status, LIDAR color etc. ) as well as start launching autonomous waypoint missions for this connected robot.","title":"1.1 Robot Fleet Manager"},{"location":"dash-auto/autonomy-client/#12-general-settings","text":"The General Settings expandable panel from the left side of the screen. In here you can configure various options to streamline robot operations. General: This allows the customization of route/waypoint + map display settings Robot Viz: Visualization settings pertaining to the robots operated in the app Map Viz: Visualization settings for the 3D map display. In particular, use the Floor and Ceiling sliders to adjust how much of the 3D map height-wise","title":"1.2 General Settings"},{"location":"dash-auto/autonomy-client/#13-routes-waypoints","text":"This subpanel can be accessed by expanding the panel on the right side of the screen. It allows you to manage the various mission routes available for your robots. To create a new route, you do the following: Enter a new Route Name in the textbox provided Click the + button to add a new route Select the newly route by clicking on it Now go into the main 3D Map display to start plotting your waypoints for the route. You can Append/Splice/Modify a route via the subpanel below: With the desired waypoint plotting option selected, you can go ahead and plot the waypoint directly with the mouse: Tap the ESC key to exit the waypoint plotting operation. If you need to delete a waypoint, you can select it via a mouse click on the 3D Map, then press the Delete key.","title":"1.3 Routes + Waypoints"},{"location":"dash-auto/autonomy-client/#14-settings-the-initial-robot-pose","text":"When you activate a new robot into the app, the first required step is to tell the system where the robot is and where it is facing in relation to the 3D map. This step is defined as setting the Initial Pose of the robot. You set the Initial Pose via the following steps: Click on the Initial Pose arrow button on the lower expandable panel to start the Initial Pose operation: Go to the 3D map, hold down your mouse on the part of the map where the robot is. Drag a direction and release to set the pose of the robot If the pose was set incorrectly, you can repeat steps 1 and 2 until the LIDAR scans of the robot matches that of the 3D map. This is when you know the Initial Pose is setup correctly. Take Note: It is very important the Initial Pose of the robot is setup correctly before starting any Waypoint Autonomy Mission ! Incorrect initial poses will result in the robot unable to localize correctly leading to mission failure.","title":"1.4 Settings the Initial Robot Pose"},{"location":"dash-auto/autonomy-client/#15-mission-routesmanagement","text":"This expandable panel located at the top part of the screen allows you to start new waypoint missions as well as manage existing missions. To start a new mission: Enter a new mission name in the textbox, then press the + button to add a new mission Select the new mission and press the Run button to start it You should now see your robot move in the 3D map viewer along the mission route","title":"1.5 Mission Routes/Management"},{"location":"dash-auto/autonomy-client/#16-robot-camera-streaming","text":"You can activate any available cameras on the robot via the Camera Stream button circled red above. When pressed, a new Camera Stream window pops up: Select the robot which you will want to stream the camera from via the top drop down box. Then use the lower drop down box to select which of the available robot cameras to stream from.","title":"1.6 Robot Camera Streaming"},{"location":"dash-auto/autonomy-client/#17-robot-remote-pilotingteleops","text":"The app also allows basic remote manual piloting of your robots. Just like the Pilot Client , plug in a regular joystick into your system to begin manually piloting your robots. You will have to activate the robot for manual control via the manual control button located in the lower expandable panel before piloting is enabled.","title":"1.7 Robot Remote Piloting/TeleOps"},{"location":"dash-pack/dash-pack/","text":"d.ASH Pack | | d.ASH Pack is a mobile sensor system that allows users to create 3D Navigation Maps for Robot Autonomy. d.ASH Pack can either be worn on the back of the user (just like a backpack) or mounted on a robot. It works with d.ASH Xplorer application to generate a 3D pointcloud map. The entire workflow is fully integrated with d.ASH Fleet Management system. | | You can view a short video overview of how d.ASH Pack integrates into your Autonomous Robot Deployment workflow here Requirements A Windows 10 / Ubuntu PC with a decent GPU d.ASH Pack device Internet Connection (Contact us if you prefer the version without any internet connection and Fleet Management integration support). This guide assumes that you have an internet connection throughout the entire workflow. 1.1 Quick Start A 3D map is created in two steps: data collection and data processing. Data collection requires the d.ASH Pack device. There are 3 different ways to activate the data collection process as listed below. If you do not have access to the Internet connection, please make sure to use Option 1 which allows you to activate the data collection via your phone. Data processing requires the d.ASH Xplorer application and Internet connection. The d.ASH Xplorer software is used to process the recorded data, create and edit 3D maps, and upload data to the Fleet Management cloud. 1.2 Data Collection Option 1 - Connect d.ASH Pack via Wifi Network (No internet connection required) Power up d.ASH Pack Connect to d.ASH Pack's Wifi network from your phone or other electronic devices. Open your web browser and key in \"https://10.0.0.0/dashpack\". Name your d.ASH Pack recording file and tap start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording. Option 2 - Connect to https://dc-blah-blah.com/dashpack Power up d.ASH Pack Open your web browser and key in \"https://dc-blah-blah.com/dashpack\". Login with your d.ASH credentials. Name your d.ASH Pack recording file and tap start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording. Option 3 - Use d.ASH Xplorer Power up d.ASH Pack Load your d.ASH Xplorer application on your PC Login with your d.ASH credentials. Click on \"d.ASH Pack Manager\" tab at the top. Select your d.ASH Pack. Click on \"d.ASH Pack Recording Control\" Key in your d.ASH Pack recording file name and click start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording. 1.3 Data Processing Load up the d.ASH Xplorer Application Login and click \"d.ASH Pack Manager\" tab at the top. Your d.ASH Pack device should appear in the list. Select it by clicking on it. Select the recording files that you wish to download. If you connect an ethernet cable between d.ASH Pack and your PC, you will have options to download the recordings via either an ethernet cable or wirelessly. For fast download speeds, using an Ethernet cable is recommended. Change 3D mapping configuration to suite the environment of the recording. For mapping configuration explanations/tips, please refer to Mapping Configs section in Xplorer guide. Select the preferred recording file and click \"Generate Map\" to start the map generation. While it is running, you will have the following options: Pause : Pause the mapping process (Appear if mapping is running) Resume : Resume the mapping process (Appear if mapping is paused) Cancel : Cancel the mapping process Checkpoint : Export the current 3D map to Map Editor. This is used to backup the mapping progress, if problems arise in the future some good results can be restored. Once completed, click \"Map Editor\" to edit the generated map. The name of the new map is the same as the recording file's name. Follow d.ASH Xplorer guide to edit the map accordingly. Once you are satisfied with the 3D map, click \"Upload\" to upload the map to your d.ASH Fleet Management account in cloud. Tips Good Quality 3D Map : It is recommended to walk in loops back to previously visited areas for map auto-correction. You will notice some automatic corrections being done during the mapping process on d.ASH Xplorer. These corrections are called loop-closure. Map Editing : You can use d.ASH Xplorer map editing function to rotate and translate the maps. Map editing is recommended so that users can deploy their autonomous robot easily. We recommend rotating the map so that the ground plane is aligned with the grid on d.ASH Xplorer. Fast Record Downloading : To achieve high-speed d.ASH Pack recording retrieval, please connect an ethernet between the d.ASH Pack and your PC running d.ASH Xplorer. Slow Visualization : If you encounter a slow/laggy visualization or pointcloud editing, you can downsample the pointcloud. This will increase the FPS of visualization/processing. Once the editing work is done, you can restore the pointcloud density and export or upload the pointcloud. Autonomy : If you are planning to export the pointcloud map without going through our Fleet Management system, we recommend that downsample the pointcloud before you export. This will speed up the map loading process on the robots.","title":"1.0 d.ASH Pack"},{"location":"dash-pack/dash-pack/#dash-pack","text":"| | d.ASH Pack is a mobile sensor system that allows users to create 3D Navigation Maps for Robot Autonomy. d.ASH Pack can either be worn on the back of the user (just like a backpack) or mounted on a robot. It works with d.ASH Xplorer application to generate a 3D pointcloud map. The entire workflow is fully integrated with d.ASH Fleet Management system. | | You can view a short video overview of how d.ASH Pack integrates into your Autonomous Robot Deployment workflow here","title":"d.ASH Pack"},{"location":"dash-pack/dash-pack/#requirements","text":"A Windows 10 / Ubuntu PC with a decent GPU d.ASH Pack device Internet Connection (Contact us if you prefer the version without any internet connection and Fleet Management integration support). This guide assumes that you have an internet connection throughout the entire workflow.","title":"Requirements"},{"location":"dash-pack/dash-pack/#11-quick-start","text":"A 3D map is created in two steps: data collection and data processing. Data collection requires the d.ASH Pack device. There are 3 different ways to activate the data collection process as listed below. If you do not have access to the Internet connection, please make sure to use Option 1 which allows you to activate the data collection via your phone. Data processing requires the d.ASH Xplorer application and Internet connection. The d.ASH Xplorer software is used to process the recorded data, create and edit 3D maps, and upload data to the Fleet Management cloud.","title":"1.1 Quick Start"},{"location":"dash-pack/dash-pack/#12-data-collection","text":"Option 1 - Connect d.ASH Pack via Wifi Network (No internet connection required) Power up d.ASH Pack Connect to d.ASH Pack's Wifi network from your phone or other electronic devices. Open your web browser and key in \"https://10.0.0.0/dashpack\". Name your d.ASH Pack recording file and tap start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording. Option 2 - Connect to https://dc-blah-blah.com/dashpack Power up d.ASH Pack Open your web browser and key in \"https://dc-blah-blah.com/dashpack\". Login with your d.ASH credentials. Name your d.ASH Pack recording file and tap start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording. Option 3 - Use d.ASH Xplorer Power up d.ASH Pack Load your d.ASH Xplorer application on your PC Login with your d.ASH credentials. Click on \"d.ASH Pack Manager\" tab at the top. Select your d.ASH Pack. Click on \"d.ASH Pack Recording Control\" Key in your d.ASH Pack recording file name and click start. Walk around to cover the area that you would like to map. For better quality, please make sure to walk in loops back to previously visited areas. Once you are done, stop recording.","title":"1.2 Data Collection"},{"location":"dash-pack/dash-pack/#13-data-processing","text":"Load up the d.ASH Xplorer Application Login and click \"d.ASH Pack Manager\" tab at the top. Your d.ASH Pack device should appear in the list. Select it by clicking on it. Select the recording files that you wish to download. If you connect an ethernet cable between d.ASH Pack and your PC, you will have options to download the recordings via either an ethernet cable or wirelessly. For fast download speeds, using an Ethernet cable is recommended. Change 3D mapping configuration to suite the environment of the recording. For mapping configuration explanations/tips, please refer to Mapping Configs section in Xplorer guide. Select the preferred recording file and click \"Generate Map\" to start the map generation. While it is running, you will have the following options: Pause : Pause the mapping process (Appear if mapping is running) Resume : Resume the mapping process (Appear if mapping is paused) Cancel : Cancel the mapping process Checkpoint : Export the current 3D map to Map Editor. This is used to backup the mapping progress, if problems arise in the future some good results can be restored. Once completed, click \"Map Editor\" to edit the generated map. The name of the new map is the same as the recording file's name. Follow d.ASH Xplorer guide to edit the map accordingly. Once you are satisfied with the 3D map, click \"Upload\" to upload the map to your d.ASH Fleet Management account in cloud.","title":"1.3 Data Processing"},{"location":"dash-pack/dash-pack/#tips","text":"Good Quality 3D Map : It is recommended to walk in loops back to previously visited areas for map auto-correction. You will notice some automatic corrections being done during the mapping process on d.ASH Xplorer. These corrections are called loop-closure. Map Editing : You can use d.ASH Xplorer map editing function to rotate and translate the maps. Map editing is recommended so that users can deploy their autonomous robot easily. We recommend rotating the map so that the ground plane is aligned with the grid on d.ASH Xplorer. Fast Record Downloading : To achieve high-speed d.ASH Pack recording retrieval, please connect an ethernet between the d.ASH Pack and your PC running d.ASH Xplorer. Slow Visualization : If you encounter a slow/laggy visualization or pointcloud editing, you can downsample the pointcloud. This will increase the FPS of visualization/processing. Once the editing work is done, you can restore the pointcloud density and export or upload the pointcloud. Autonomy : If you are planning to export the pointcloud map without going through our Fleet Management system, we recommend that downsample the pointcloud before you export. This will speed up the map loading process on the robots.","title":"Tips"},{"location":"dash-pack/dash-xplorer/","text":"d.ASH Xplorer | | d.ASH Xplorer is the 3D pointcloud management application, allowing users to create, edit and export 3D maps for robotics autonomy. d.ASH Xplorer is designed to work with d.ASH Pack and equipped with state-of-the-art SLAM technology for 3D map generation. Users can edit the 3D map by rotating, translating, downsampling and cleaning up pointcloud for autonomy. 2D map can also be generated from the 3D pointcloud using the in-built grid map generator. The entire map generation workflow is fully integrated with d.ASH Fleet Management to significantly shorten and streamline the preparation process for autonomous navigation. Additionally, d.ASH Xplorer is equipped with other add-ons features such as AutoMerge which is our automatic stitching software of dense 3D scans. AutoMerge utilises sensor fusion to perform automatic scan alignment and scale-consistent stitching with little human intervention. AutoMerge system currently supports Leica BLK360. Since d.ASH Xplorer is fully integrated with d.ASH Fleet Management system to streamline autonomous robotics deployment, Internet connection is required. Should you required d.ASH Xplorer without Internet connection, please contact us for more details. Requirements PC with sufficiently good GPU d.ASH Xplorer software Internet Connection (Contact us if you are looking for offline version) IMPORTANT! When running on Windows 10/11, please ensure you are running your Discrete GPU in High Performance mode. Otherwise some of the functionality will fail. You can enable this by going into GPU Settings, adding d.ASH Xplorer as the app and then forcing High Performance Mode Tutorial | | You can watch the video tutorial below to get a quick overview of how to run d.ASH Xplorer above here. 2.1 Modes d.ASH Xplorer has 3 main modes for various tasks: Map Editor : Perform 3D pointcloud edit, export and upload d.ASH Pack Manager : Control d.ASH Pack and generate 3D pointcloud map Scan Loader : Download and perform AutoMerge on 3 rd party 3D scanner. These 3 modes form 3 different tabs at the top of d.ASH Xplorer. 2.2 Map Editor Map editor is used to manage different pointclouds that you have generated. Users can perform rotation, translation, downsampling and other 3D pointcloud editing features. You can use this mode to visualize 3D pointcloud and 3D mesh by using the load button. File extension \".pcd\" and \".obj\" are currently supported. After loading, your 3D objects will appear in the list under Map Collections . You can hide or show a pointcloud object by clicking the green eye button. Remove button simply removes the 3D object from the list. However, it does not delete the file from the PC. Rename button renames the selected 3D object name. Export button exports the selected 3D object to a destination of your choice. When clicked, a file dialogue will popup for you to choose the save folder destination. If the 3D object has a mesh, an \"obj\" file will be exported. On the other hand, if the object has a pointcloud, 3 different files will be saved. They are 3D pointcloud (.pcd), 2D map (.png) and map configuration (.json). Upload button uploads the 3D map to d.ASH Cloud Fleet Management System. If a map with the same name is found in the cloud, a popup warning will ask the user to either overwrite the existing file or cancel the uploading operation. Once uploaded, users can access or download the map from the cloud. 2.3 Surface Reconstruction This section allows users to perform mesh reconstruction from 3D pointcloud. Grid size determines the quality of the scan. Larger grid size helps to smoothen the mesh at an expense of quality. There is an option to perform pointcloud clean up when performing surface reconstruction. However, this option tends to significantly slow down the meshing process. When surface reconstruction is running, map removal is disabled. Additionally, users should not perform any map transformation because the end mesh product will not be in sync with the mesh itself. 2.4 Map Transformation This section allows users to perform map editing. Users can perform translation and rotation by using XYZ and quaternion values respectively. There are options for users to reset the transformations back to the original state. In addition, a widget in the center of the screen is designed to facilitate pointcloud transformation. Users can click on the widgets and see live transformation of the 3D object via clicking on the widget. To toggle between translation and rotation mode of the widget, users can choose the right mode under \"Widget Mode\". Users can perform downsampling by changing the Pointcloud Map Details . Users can choose between Original and Sparse details, or set their desired voxel grid size. Map Cleaner helps to remove outliers to make the 3D map cleaner. 2.5 2D Map Generator This feature creates a 2D map from a 3D map by projecting a section of the 3D map onto an image file from the top view. Users have 3 different configurations: min height, max height and pixel resolution (metre / pixel). To see which region is used for compressions, users can check Show Height-Bounds to display the minimum and maximum height planes. Once satisfied, click Generate to apply the configurations and view the 2D map. Users can choose to Save 2D Map separately if needed. It is recommended to ensure that the freespace is correctly represented because this information will be used for automatic path-planning and visualization on the website. However, if you do not intent to use d.ASH automatic path-planning, getting a clear 2D map for visualization is sufficient. 2.6 d.ASH Pack Manager This mode allows users to start/stop d.ASH Pack recordings, download d.ASH Pack recordings and generate 3D map through d.ASH Pack Manager window. Users can only start/stop d.ASH Pack recordings and download d.ASH Pack recording files when d.ASH Xplorer detects that there are online d.ASH Pack. Otherwise, \"No online d.ASH Pack found\" will be shown. If there is an online d.ASH Pack, the d.ASH Pack name will pop up on the list of online d.ASH Pack. Click on it to select the d.ASH Pack device. 2.7 d.ASH Pack Control This section allow users to start/stop d.ASH Pack recordings. To start, key in d.ASH Pack recording name and click Start button. To stop, click Stop button. 2.8 Download d.ASH Pack Recordings After clicking on the list of d.ASH Pack, perform the following steps to download the recording: Select the desired d.ASH Pack recording file from the recording list. If there is an ethernet connection between the PC running d.ASH Xplorer and d.ASH Pack, users will have options to download either wirelessly or via ethernet. It is recommend to download via an ethernet connection for fast downloading speed. Click Download to start downloading. Once it is completed, the downloaded file will appear in the Downloaded d.ASH Pack Recordings list ready for 3D map generation. 2.9 3D Map Generation After downloading the d.ASH Pack recording, you can then generate the 3D map for that particular recording. Under Map Configs , users can choose different settings for the 3D map generation. For details on the configuration, please refer to the next section Select d.ASH Pack recording by clicking on the recording name under the Downloaded d.ASH Pack Recordings list. Click Generate Map to start the 3D map generation. You will see the 3D map being generated progressively on the screen. A green line appearing on the screen represents the path taken during the recording process. While the 3D map is being generated, users will have the following options: Pause : Pause the mapping process (Appear if mapping is running) Resume : Resume the mapping process (Appear if mapping is paused) Cancel : Cancel the mapping process Checkpoint : Export the current 3D map to Map Editor. This is used to backup the 3D map in case there are problems later on. When mapping is completed, the completed map will be automatically added to the map list under Map Editor for other purposes such as editing and uploading. Mapping Configs To ensure desirable mapping quality, different settings may be required for different environments and terrains. d.ASH Xplorer is equipped with different preset settings. Users are also allowed to create their own custom settings to suite their requirements. Following 3 different presents are embedded in d.ASH Xplorer: General : This preset should work for most environment. We recommend using this preset as the first setting for your mapping. Outdoor : Suitable for an outdoor environment with large open space, Narrow Space : Suitable for environment with narrow corridors or cluttered space. Generate Configuration On top of the mapping configurations, users have the following options: Start/Stop Time(%) : Users can perform mapping for a part of the d.ASH Pack recording by specifying the start and stop time in percentage (from 0-100%) Save Map When Done : When checked, the 3D map will be automatically saved on the PC under dASH_Xplorer/maps folder. The absolute path to dASH_Xplorer folder depends on the operating system. You can search for the folder using the system native file dialogue. Custom Mapping Configurations To customise the configurations, please choose Custom preset. The following options are avilable: Number of Cores : Uses number of cpu cores for parallel computation. It is recommended to be as high as possible Map Corner Voxel Size : Determines the accuracy of corners alignment. The lower the value, the more accurate the alignments Map Surface Voxel Size : Determines the accuracy of surface alignment. The lower the value, the more accurate the alignments Keyframe Nearest Radius : Radius in meter for scan positions to be considered for loop closure. Keyframe Time Difference : Time difference in seconds for different scan positions to be considered for loop closure Keyframe Search Number : Number of neighbouring scan positions to be merged for loop closure detection. Keyframe Similarity Score : Minimum similarity score between different scans to be considered for loop closure. Surrounding Keyframe Search Radius : Radius in meter for scan positions optimization. Scan Manager (Plugin) This plugin allows users to manage 3 rd -party 3D scanners. Currently, Leica BLK360 scanner is supported. This plugin is used to perform the following: 1. Download scanMeta file from the robot 2. Download scan data from the scanner 3. Perform AutoMerge on all scans. Download ScanMeta Files ScanMeta file ( *.scanMeta ) holds critical information for each scan point. Each 3D scan activated by d.ASH robotics stack will generate a ScanMeta file. The ScanMeta data can be used to performe AutoMerge for createing digital twin (high accuracy/density 3D pointcloud model). ScanMeta files are grouped by their project names which are set by d.ASH Autonomy Mission. To download the ScanMeta files, perform the following: Connect your PC running d.ASH Xplorer to the Internet and make sure that the robot is online Click on the robot from the Online Robot List . Select the desired data folder by clicking Change . This folder will be used to store downloaded ScanMeta files. We recommend choosing an empty folder. Otherwise, some ScanMeta files will be overwritten. Click on Download Files to expand the window. If there are ScanMeta files found on the robot, their project names will be listed under Available Scan Projects . Click on the desired project. Click Download to download ScanMeta files for the entire project. After downloading, all ScanMeta files will be stored in the folder selected in Step 3. Download 3D Scan Data From the Scanner This step performs downloading of 3D scan data from the 3D scanner by using the downloaded ScanMeta files. Connect your PC running d.ASH Xplorer to the 3D scanner. Select the desried data folder by clicking Change . This folder should have ScanMeta files. Click on Download Files to expand the window. Under \"Download scan data from scanner\", click Download There will be a window popup showing all ScanMeta filenames found in the folder selected in Step 2. If 3D scan files and scanMeta files with the same name exist, the filename will have \"[Downloaded]\" appended at the back of their names. Use the check boxes on the left to mark 3D scan data for downloading. Users can use Select All or Unselect All buttons for file selections. Click Download to start the 3D scan downloading process. Once completed, Click Close to close the popup. AutoMerge This step performs AutoMerge on the 3D Scan data. AutoMerge utilizes sensor fusion techniques to automatically stitch and align multiple 3D scans for scale-consistent digital twin reconstruction. AutoMerge supports both colored and non-colored pointcloud. To perform AutoMerge, perform the following steps: Select the desried data folder by clicking Change . This folder should have both ScanMeta files and 3D scan data files. Click on AutoMerge to expand the window. AutoMerge Scan File List displays a list of files in the selected folder for AutoMerge. Only filenames with .scanMeta and .pcd are considered for AutoMerge. Since AutoMerge relies on the orientation of the 3D scanner to perform stitching, users are encouraged to preview some scans first. This is done by selecting a few scans (greater than two) and click Preview . After scan previews have loaded, expand Options and change the Scanner Rotation so that the selected scans are roughly aligned. These rotations will rotate the 3D scan about their centers. As the scanner rotation being changed, the 3D scan previews will also be rotated accordingly. Users do not have to perfectly align the 3D scans manually. Just a rough estimate is sufficient. After configuring the scanner rotation, users can start AutoMerge. Click AutoMerge to start the AutoMerge process on the selected files (greater than one). You will see the 3D scans popping up and aligning themselves automatically after some time. When AutoMerge has completed, users have the following options: Export : Save the AutoMerge results and individual scans with corrected poses. Users can choose to export as .pcd or .xyz file formats. Edit : Export the AutoMerge results to Map Editor for editing. Options There are 3 different options available for Scan Manager: Scanner Rotation : Rotation in degrees of the scanner relative to the robot heading. As this value being changed, the 3D scan preview will also be updated in real-time. Optimize Visualization : Check this to optimize rendering. Check this if you notice a laggy visualization. Auto save AutoMerge results : Automatically save AutoMerge results to the data folder once AutoMerge has completed. Tips Good Mesh Quality : It is recommended to downsample the pointcloud by using Pointcloud Map Details using a grid size of about 0.1-0.2 metre depending on the quality you would like the pointcloud to be. After that, you run Surface Reconstruction with a grid size larger than what you used for map details. We recommend using grid size of 0.1-0.2 metre for Pointcloud Map Details and 1.0 metre for Surface Reconstruction.","title":"2.0 d.ASH Xplorer"},{"location":"dash-pack/dash-xplorer/#dash-xplorer","text":"| | d.ASH Xplorer is the 3D pointcloud management application, allowing users to create, edit and export 3D maps for robotics autonomy. d.ASH Xplorer is designed to work with d.ASH Pack and equipped with state-of-the-art SLAM technology for 3D map generation. Users can edit the 3D map by rotating, translating, downsampling and cleaning up pointcloud for autonomy. 2D map can also be generated from the 3D pointcloud using the in-built grid map generator. The entire map generation workflow is fully integrated with d.ASH Fleet Management to significantly shorten and streamline the preparation process for autonomous navigation. Additionally, d.ASH Xplorer is equipped with other add-ons features such as AutoMerge which is our automatic stitching software of dense 3D scans. AutoMerge utilises sensor fusion to perform automatic scan alignment and scale-consistent stitching with little human intervention. AutoMerge system currently supports Leica BLK360. Since d.ASH Xplorer is fully integrated with d.ASH Fleet Management system to streamline autonomous robotics deployment, Internet connection is required. Should you required d.ASH Xplorer without Internet connection, please contact us for more details.","title":"d.ASH Xplorer"},{"location":"dash-pack/dash-xplorer/#requirements","text":"PC with sufficiently good GPU d.ASH Xplorer software Internet Connection (Contact us if you are looking for offline version) IMPORTANT! When running on Windows 10/11, please ensure you are running your Discrete GPU in High Performance mode. Otherwise some of the functionality will fail. You can enable this by going into GPU Settings, adding d.ASH Xplorer as the app and then forcing High Performance Mode","title":"Requirements"},{"location":"dash-pack/dash-xplorer/#tutorial","text":"| | You can watch the video tutorial below to get a quick overview of how to run d.ASH Xplorer above here.","title":"Tutorial"},{"location":"dash-pack/dash-xplorer/#21-modes","text":"d.ASH Xplorer has 3 main modes for various tasks: Map Editor : Perform 3D pointcloud edit, export and upload d.ASH Pack Manager : Control d.ASH Pack and generate 3D pointcloud map Scan Loader : Download and perform AutoMerge on 3 rd party 3D scanner. These 3 modes form 3 different tabs at the top of d.ASH Xplorer.","title":"2.1 Modes"},{"location":"dash-pack/dash-xplorer/#22-map-editor","text":"Map editor is used to manage different pointclouds that you have generated. Users can perform rotation, translation, downsampling and other 3D pointcloud editing features. You can use this mode to visualize 3D pointcloud and 3D mesh by using the load button. File extension \".pcd\" and \".obj\" are currently supported. After loading, your 3D objects will appear in the list under Map Collections . You can hide or show a pointcloud object by clicking the green eye button. Remove button simply removes the 3D object from the list. However, it does not delete the file from the PC. Rename button renames the selected 3D object name. Export button exports the selected 3D object to a destination of your choice. When clicked, a file dialogue will popup for you to choose the save folder destination. If the 3D object has a mesh, an \"obj\" file will be exported. On the other hand, if the object has a pointcloud, 3 different files will be saved. They are 3D pointcloud (.pcd), 2D map (.png) and map configuration (.json). Upload button uploads the 3D map to d.ASH Cloud Fleet Management System. If a map with the same name is found in the cloud, a popup warning will ask the user to either overwrite the existing file or cancel the uploading operation. Once uploaded, users can access or download the map from the cloud.","title":"2.2 Map Editor"},{"location":"dash-pack/dash-xplorer/#23-surface-reconstruction","text":"This section allows users to perform mesh reconstruction from 3D pointcloud. Grid size determines the quality of the scan. Larger grid size helps to smoothen the mesh at an expense of quality. There is an option to perform pointcloud clean up when performing surface reconstruction. However, this option tends to significantly slow down the meshing process. When surface reconstruction is running, map removal is disabled. Additionally, users should not perform any map transformation because the end mesh product will not be in sync with the mesh itself.","title":"2.3 Surface Reconstruction"},{"location":"dash-pack/dash-xplorer/#24-map-transformation","text":"This section allows users to perform map editing. Users can perform translation and rotation by using XYZ and quaternion values respectively. There are options for users to reset the transformations back to the original state. In addition, a widget in the center of the screen is designed to facilitate pointcloud transformation. Users can click on the widgets and see live transformation of the 3D object via clicking on the widget. To toggle between translation and rotation mode of the widget, users can choose the right mode under \"Widget Mode\". Users can perform downsampling by changing the Pointcloud Map Details . Users can choose between Original and Sparse details, or set their desired voxel grid size. Map Cleaner helps to remove outliers to make the 3D map cleaner.","title":"2.4 Map Transformation"},{"location":"dash-pack/dash-xplorer/#25-2d-map-generator","text":"This feature creates a 2D map from a 3D map by projecting a section of the 3D map onto an image file from the top view. Users have 3 different configurations: min height, max height and pixel resolution (metre / pixel). To see which region is used for compressions, users can check Show Height-Bounds to display the minimum and maximum height planes. Once satisfied, click Generate to apply the configurations and view the 2D map. Users can choose to Save 2D Map separately if needed. It is recommended to ensure that the freespace is correctly represented because this information will be used for automatic path-planning and visualization on the website. However, if you do not intent to use d.ASH automatic path-planning, getting a clear 2D map for visualization is sufficient.","title":"2.5 2D Map Generator"},{"location":"dash-pack/dash-xplorer/#26-dash-pack-manager","text":"This mode allows users to start/stop d.ASH Pack recordings, download d.ASH Pack recordings and generate 3D map through d.ASH Pack Manager window. Users can only start/stop d.ASH Pack recordings and download d.ASH Pack recording files when d.ASH Xplorer detects that there are online d.ASH Pack. Otherwise, \"No online d.ASH Pack found\" will be shown. If there is an online d.ASH Pack, the d.ASH Pack name will pop up on the list of online d.ASH Pack. Click on it to select the d.ASH Pack device.","title":"2.6 d.ASH Pack Manager"},{"location":"dash-pack/dash-xplorer/#27-dash-pack-control","text":"This section allow users to start/stop d.ASH Pack recordings. To start, key in d.ASH Pack recording name and click Start button. To stop, click Stop button.","title":"2.7 d.ASH Pack Control"},{"location":"dash-pack/dash-xplorer/#28-download-dash-pack-recordings","text":"After clicking on the list of d.ASH Pack, perform the following steps to download the recording: Select the desired d.ASH Pack recording file from the recording list. If there is an ethernet connection between the PC running d.ASH Xplorer and d.ASH Pack, users will have options to download either wirelessly or via ethernet. It is recommend to download via an ethernet connection for fast downloading speed. Click Download to start downloading. Once it is completed, the downloaded file will appear in the Downloaded d.ASH Pack Recordings list ready for 3D map generation.","title":"2.8 Download d.ASH Pack Recordings"},{"location":"dash-pack/dash-xplorer/#29-3d-map-generation","text":"After downloading the d.ASH Pack recording, you can then generate the 3D map for that particular recording. Under Map Configs , users can choose different settings for the 3D map generation. For details on the configuration, please refer to the next section Select d.ASH Pack recording by clicking on the recording name under the Downloaded d.ASH Pack Recordings list. Click Generate Map to start the 3D map generation. You will see the 3D map being generated progressively on the screen. A green line appearing on the screen represents the path taken during the recording process. While the 3D map is being generated, users will have the following options: Pause : Pause the mapping process (Appear if mapping is running) Resume : Resume the mapping process (Appear if mapping is paused) Cancel : Cancel the mapping process Checkpoint : Export the current 3D map to Map Editor. This is used to backup the 3D map in case there are problems later on. When mapping is completed, the completed map will be automatically added to the map list under Map Editor for other purposes such as editing and uploading.","title":"2.9 3D Map Generation"},{"location":"dash-pack/dash-xplorer/#mapping-configs","text":"To ensure desirable mapping quality, different settings may be required for different environments and terrains. d.ASH Xplorer is equipped with different preset settings. Users are also allowed to create their own custom settings to suite their requirements. Following 3 different presents are embedded in d.ASH Xplorer: General : This preset should work for most environment. We recommend using this preset as the first setting for your mapping. Outdoor : Suitable for an outdoor environment with large open space, Narrow Space : Suitable for environment with narrow corridors or cluttered space. Generate Configuration On top of the mapping configurations, users have the following options: Start/Stop Time(%) : Users can perform mapping for a part of the d.ASH Pack recording by specifying the start and stop time in percentage (from 0-100%) Save Map When Done : When checked, the 3D map will be automatically saved on the PC under dASH_Xplorer/maps folder. The absolute path to dASH_Xplorer folder depends on the operating system. You can search for the folder using the system native file dialogue. Custom Mapping Configurations To customise the configurations, please choose Custom preset. The following options are avilable: Number of Cores : Uses number of cpu cores for parallel computation. It is recommended to be as high as possible Map Corner Voxel Size : Determines the accuracy of corners alignment. The lower the value, the more accurate the alignments Map Surface Voxel Size : Determines the accuracy of surface alignment. The lower the value, the more accurate the alignments Keyframe Nearest Radius : Radius in meter for scan positions to be considered for loop closure. Keyframe Time Difference : Time difference in seconds for different scan positions to be considered for loop closure Keyframe Search Number : Number of neighbouring scan positions to be merged for loop closure detection. Keyframe Similarity Score : Minimum similarity score between different scans to be considered for loop closure. Surrounding Keyframe Search Radius : Radius in meter for scan positions optimization.","title":"Mapping Configs"},{"location":"dash-pack/dash-xplorer/#scan-manager-plugin","text":"This plugin allows users to manage 3 rd -party 3D scanners. Currently, Leica BLK360 scanner is supported. This plugin is used to perform the following: 1. Download scanMeta file from the robot 2. Download scan data from the scanner 3. Perform AutoMerge on all scans. Download ScanMeta Files ScanMeta file ( *.scanMeta ) holds critical information for each scan point. Each 3D scan activated by d.ASH robotics stack will generate a ScanMeta file. The ScanMeta data can be used to performe AutoMerge for createing digital twin (high accuracy/density 3D pointcloud model). ScanMeta files are grouped by their project names which are set by d.ASH Autonomy Mission. To download the ScanMeta files, perform the following: Connect your PC running d.ASH Xplorer to the Internet and make sure that the robot is online Click on the robot from the Online Robot List . Select the desired data folder by clicking Change . This folder will be used to store downloaded ScanMeta files. We recommend choosing an empty folder. Otherwise, some ScanMeta files will be overwritten. Click on Download Files to expand the window. If there are ScanMeta files found on the robot, their project names will be listed under Available Scan Projects . Click on the desired project. Click Download to download ScanMeta files for the entire project. After downloading, all ScanMeta files will be stored in the folder selected in Step 3. Download 3D Scan Data From the Scanner This step performs downloading of 3D scan data from the 3D scanner by using the downloaded ScanMeta files. Connect your PC running d.ASH Xplorer to the 3D scanner. Select the desried data folder by clicking Change . This folder should have ScanMeta files. Click on Download Files to expand the window. Under \"Download scan data from scanner\", click Download There will be a window popup showing all ScanMeta filenames found in the folder selected in Step 2. If 3D scan files and scanMeta files with the same name exist, the filename will have \"[Downloaded]\" appended at the back of their names. Use the check boxes on the left to mark 3D scan data for downloading. Users can use Select All or Unselect All buttons for file selections. Click Download to start the 3D scan downloading process. Once completed, Click Close to close the popup. AutoMerge This step performs AutoMerge on the 3D Scan data. AutoMerge utilizes sensor fusion techniques to automatically stitch and align multiple 3D scans for scale-consistent digital twin reconstruction. AutoMerge supports both colored and non-colored pointcloud. To perform AutoMerge, perform the following steps: Select the desried data folder by clicking Change . This folder should have both ScanMeta files and 3D scan data files. Click on AutoMerge to expand the window. AutoMerge Scan File List displays a list of files in the selected folder for AutoMerge. Only filenames with .scanMeta and .pcd are considered for AutoMerge. Since AutoMerge relies on the orientation of the 3D scanner to perform stitching, users are encouraged to preview some scans first. This is done by selecting a few scans (greater than two) and click Preview . After scan previews have loaded, expand Options and change the Scanner Rotation so that the selected scans are roughly aligned. These rotations will rotate the 3D scan about their centers. As the scanner rotation being changed, the 3D scan previews will also be rotated accordingly. Users do not have to perfectly align the 3D scans manually. Just a rough estimate is sufficient. After configuring the scanner rotation, users can start AutoMerge. Click AutoMerge to start the AutoMerge process on the selected files (greater than one). You will see the 3D scans popping up and aligning themselves automatically after some time. When AutoMerge has completed, users have the following options: Export : Save the AutoMerge results and individual scans with corrected poses. Users can choose to export as .pcd or .xyz file formats. Edit : Export the AutoMerge results to Map Editor for editing. Options There are 3 different options available for Scan Manager: Scanner Rotation : Rotation in degrees of the scanner relative to the robot heading. As this value being changed, the 3D scan preview will also be updated in real-time. Optimize Visualization : Check this to optimize rendering. Check this if you notice a laggy visualization. Auto save AutoMerge results : Automatically save AutoMerge results to the data folder once AutoMerge has completed.","title":"Scan Manager (Plugin)"},{"location":"dash-pack/dash-xplorer/#tips","text":"Good Mesh Quality : It is recommended to downsample the pointcloud by using Pointcloud Map Details using a grid size of about 0.1-0.2 metre depending on the quality you would like the pointcloud to be. After that, you run Surface Reconstruction with a grid size larger than what you used for map details. We recommend using grid size of 0.1-0.2 metre for Pointcloud Map Details and 1.0 metre for Surface Reconstruction.","title":"Tips"},{"location":"dc-pilot/pilot-guide/","text":"dC Pilot Client The dC pilot is a GUI (graphical user interface) for the d.ASH SDK. It encompasses interactive visual components for you to control your robot both manually and autonomously. Operate your robots safely and precisely, from any location with our reliable and high-performance BVLOS (Beyond Vision Line of Sight) System with high quality video streams and responsive controls. This section of the d.ASH SDK documentation provides details about using the d.C Pilot Client. 1.1 Introduction | | The pilot client allows you to operate your robots safely and precisely, from any location via its high-performance Remote TeleOps/BVLOS (Beyond Vision Line of Sight) system. It is also equipped with high quality video streams and responsive controls for seamless naviation. The system can also be used for fleet management, to discover, monitor and control multiple robots anytime, anywhere with real time video streaming and data collection. You can view a quick introduction of dc Pilot here | | The Vision AutoDrive is another key feature of the d.C Pilot, using machine learning and computer vision to analyze and understand your robot's surroundings. This allows hands-free Level 2 Autonomy for the navigation of complex, unstructured environments using just cameras alone. A demonstration of what Vision AutoDrive is capable of can be viewed here Some requirements before starting the d.C Pilot are: Nvidia CUDA GPU enabled PC ( At least 2 GB of GPU Memory ) Joystick connected to the PC 1 GB local storage space 16 GB of CPU Memory Intel i5 CPU or equivalent Windows 10 64-bit OS or higher 1.2 Robot Login When you first load up the pilot client, you will be asked to login via your user account. After authentication, you will be presented with the following screen below: | | The screen above shows you the robots switched ON and discovered via dashBoard ( the Fleet Management System ). Any robot currently registered under your user account and is alive will be displayed. Select the robot you want and click on Take Control to proceed to control the robot. If you want to restart the robot ( due to any unforseen previously encountered issues, ), click Restart to do so. 1.3 Main Controls | | Robot Power ON/OFF This is an optional step depending on the type of robot you are running. For most robots the robot is automatically turned ON when you physically attach a battery ( or press the actual Power ON button/switch ). For robots that need to be turned ON via software ( like the Boston Dynamics Spot ), you should turn it on by pressing the Power ON button before piloting the robot. Similary, you can Power OFF the robot if it supports such functionality. Basic Manual Piloting To start the robot from rest, apply pressure on the joystick. To stop the robot from moving, release your hold on the joystick. To move the robot forwards , push front on the joystick. To move the robot backwards , pull back on the joystick. To turn the robot to the left , tilt left on the joystick. To turn the robot to the right , tilt right on the joystick. To get the robot to stand or sit ( if the Robot supports it ), click the stand or sit button under the Basic Control panel on the right side of the main screen. Robot Reconnection/Restart ( Connectivity issues ) If you encounter situations where you lose connection to the robot ( or encounter unstable video/control streams ), you should consider Restarting/Reconnecting with the robot. There are 2 options available: | | Reconnect: This issues a fast reconnection between the pilot client and the robot. Run this if you suspect there was issue with connectivity between the client and the robot. Full Restart: This will flush + restart the robot system, then reconnect the client to the robot when the robot system is ready. Run this if you need to do a full restart with the robot possibly due to issues other than connectivity. 1.4 Control Panel Control Panel (1) Unmute the microphone to allow dual-communication between the pilot client and the robot. (2) Toggle between audio to broadcast speakers. (3) Record videos in mp4 format. (4) Upload/download video recordings. (5) Configure settings for your preference ie. night mode. (6) Broadcast live video streaming using eith a RTSP server or an HSL server. 1.5 Basic Controls Component Description (1) Monitor the joystick position with respect to your robot. Control the robot by pushing further on the joystick. (2) Adjust the cruise control speed using the slider control or if your joystick has a secondary lever, push the lever to activate. (3) Activate auto-drive for your robot to switch to Smart AI Assisted Cruise Autonomy. - Use the spacebar shortcut key to activate auto-drive. - Use the z shortcut key for your robot to take the next few possible left turns. - Use the x shortcut key for your robot to return to forward position after turning left or right. - Use the c shortcut key for your robot to take the next few possible right turns. 1.6 Cameras Component Description (1) Select from a list of cameras onboard Spot, which are automatically detected by the pilot client. (2) Adjust the order of cameras for a wider view scope. Ticking the flipped settings will adjust the camera orientation. (3) Click on sync to sync up the default camera layout/settings from the robot. You can also manually change the camera order via the Cameras drop-down combo box. (4) Activate human tracking for people detection and labelling. 1.7 AutoDrive | | AutoDrive is our state of the art ML/Computer Vision Level 2 Autonomy system for robots. It requires a calibrated 3 camera setup in order to properly function. Please make sure you have the proper setup before continuing. You can watch an overview video of what AutoDrive is capable of here | | The following options/controls are available: Run Motors: This starts/stops the AutoDrive system Avoid Grass: Checking this ON/OFF will tell the system whether to make the robot avoid/ignore a grassy area during Autonomy Log Data: This will record any required data for sending during operation 1.7 Leica BLK360 Laser Scanner | | This panel enables you to running scanning with the Leica BLK360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Select whether you want Color ( None, HDR, LDR ) via the Color combo box. Click Start to start the scanning operation. 1.8 Leica RTC360 Laser Scanner | | This panel enables you to running scanning with the Leica RTC360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Check the options Imaging , Double Scan , VIS for your RTC 360. Please consult your scanner user manual for more information on what those options do. Click Start to start the scanning operation. 1.9 Boston Dynamics Spot Arm | | This panel enables you to operate the Boston Dynamics Spot Arm if your Spot robot has been configured with one. Please take note that your cameras should be set to Spot's Default Black and White Cameras in order for this to function. Click Operate to start the Arm operation This will pop up a separate window that shows the black and white cameras on Spot. Click on the desired target area to run the arm manipulation operation. Click Run to start the arm operation.","title":"1.0 d.ASH Pilot Client"},{"location":"dc-pilot/pilot-guide/#dc-pilot-client","text":"The dC pilot is a GUI (graphical user interface) for the d.ASH SDK. It encompasses interactive visual components for you to control your robot both manually and autonomously. Operate your robots safely and precisely, from any location with our reliable and high-performance BVLOS (Beyond Vision Line of Sight) System with high quality video streams and responsive controls. This section of the d.ASH SDK documentation provides details about using the d.C Pilot Client.","title":"dC Pilot Client"},{"location":"dc-pilot/pilot-guide/#11-introduction","text":"| | The pilot client allows you to operate your robots safely and precisely, from any location via its high-performance Remote TeleOps/BVLOS (Beyond Vision Line of Sight) system. It is also equipped with high quality video streams and responsive controls for seamless naviation. The system can also be used for fleet management, to discover, monitor and control multiple robots anytime, anywhere with real time video streaming and data collection. You can view a quick introduction of dc Pilot here | | The Vision AutoDrive is another key feature of the d.C Pilot, using machine learning and computer vision to analyze and understand your robot's surroundings. This allows hands-free Level 2 Autonomy for the navigation of complex, unstructured environments using just cameras alone. A demonstration of what Vision AutoDrive is capable of can be viewed here Some requirements before starting the d.C Pilot are: Nvidia CUDA GPU enabled PC ( At least 2 GB of GPU Memory ) Joystick connected to the PC 1 GB local storage space 16 GB of CPU Memory Intel i5 CPU or equivalent Windows 10 64-bit OS or higher","title":"1.1 Introduction"},{"location":"dc-pilot/pilot-guide/#12-robot-login","text":"When you first load up the pilot client, you will be asked to login via your user account. After authentication, you will be presented with the following screen below: | | The screen above shows you the robots switched ON and discovered via dashBoard ( the Fleet Management System ). Any robot currently registered under your user account and is alive will be displayed. Select the robot you want and click on Take Control to proceed to control the robot. If you want to restart the robot ( due to any unforseen previously encountered issues, ), click Restart to do so.","title":"1.2 Robot Login"},{"location":"dc-pilot/pilot-guide/#13-main-controls","text":"| |","title":"1.3 Main Controls"},{"location":"dc-pilot/pilot-guide/#robot-power-onoff","text":"This is an optional step depending on the type of robot you are running. For most robots the robot is automatically turned ON when you physically attach a battery ( or press the actual Power ON button/switch ). For robots that need to be turned ON via software ( like the Boston Dynamics Spot ), you should turn it on by pressing the Power ON button before piloting the robot. Similary, you can Power OFF the robot if it supports such functionality. Basic Manual Piloting To start the robot from rest, apply pressure on the joystick. To stop the robot from moving, release your hold on the joystick. To move the robot forwards , push front on the joystick. To move the robot backwards , pull back on the joystick. To turn the robot to the left , tilt left on the joystick. To turn the robot to the right , tilt right on the joystick. To get the robot to stand or sit ( if the Robot supports it ), click the stand or sit button under the Basic Control panel on the right side of the main screen.","title":"Robot Power ON/OFF"},{"location":"dc-pilot/pilot-guide/#robot-reconnectionrestart-connectivity-issues","text":"If you encounter situations where you lose connection to the robot ( or encounter unstable video/control streams ), you should consider Restarting/Reconnecting with the robot. There are 2 options available: | | Reconnect: This issues a fast reconnection between the pilot client and the robot. Run this if you suspect there was issue with connectivity between the client and the robot. Full Restart: This will flush + restart the robot system, then reconnect the client to the robot when the robot system is ready. Run this if you need to do a full restart with the robot possibly due to issues other than connectivity.","title":"Robot Reconnection/Restart ( Connectivity issues )"},{"location":"dc-pilot/pilot-guide/#14-control-panel","text":"Control Panel (1) Unmute the microphone to allow dual-communication between the pilot client and the robot. (2) Toggle between audio to broadcast speakers. (3) Record videos in mp4 format. (4) Upload/download video recordings. (5) Configure settings for your preference ie. night mode. (6) Broadcast live video streaming using eith a RTSP server or an HSL server.","title":"1.4 Control Panel"},{"location":"dc-pilot/pilot-guide/#15-basic-controls","text":"Component Description (1) Monitor the joystick position with respect to your robot. Control the robot by pushing further on the joystick. (2) Adjust the cruise control speed using the slider control or if your joystick has a secondary lever, push the lever to activate. (3) Activate auto-drive for your robot to switch to Smart AI Assisted Cruise Autonomy. - Use the spacebar shortcut key to activate auto-drive. - Use the z shortcut key for your robot to take the next few possible left turns. - Use the x shortcut key for your robot to return to forward position after turning left or right. - Use the c shortcut key for your robot to take the next few possible right turns.","title":"1.5 Basic Controls"},{"location":"dc-pilot/pilot-guide/#16-cameras","text":"Component Description (1) Select from a list of cameras onboard Spot, which are automatically detected by the pilot client. (2) Adjust the order of cameras for a wider view scope. Ticking the flipped settings will adjust the camera orientation. (3) Click on sync to sync up the default camera layout/settings from the robot. You can also manually change the camera order via the Cameras drop-down combo box. (4) Activate human tracking for people detection and labelling.","title":"1.6 Cameras"},{"location":"dc-pilot/pilot-guide/#17-autodrive","text":"| | AutoDrive is our state of the art ML/Computer Vision Level 2 Autonomy system for robots. It requires a calibrated 3 camera setup in order to properly function. Please make sure you have the proper setup before continuing. You can watch an overview video of what AutoDrive is capable of here | | The following options/controls are available: Run Motors: This starts/stops the AutoDrive system Avoid Grass: Checking this ON/OFF will tell the system whether to make the robot avoid/ignore a grassy area during Autonomy Log Data: This will record any required data for sending during operation","title":"1.7 AutoDrive"},{"location":"dc-pilot/pilot-guide/#17-leica-blk360-laser-scanner","text":"| | This panel enables you to running scanning with the Leica BLK360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Select whether you want Color ( None, HDR, LDR ) via the Color combo box. Click Start to start the scanning operation.","title":"1.7 Leica BLK360 Laser Scanner"},{"location":"dc-pilot/pilot-guide/#18-leica-rtc360-laser-scanner","text":"| | This panel enables you to running scanning with the Leica RTC360 Laser Scanner . Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning: Type in your Job Name in the textbox. This name will be used for the entire set of scans. Select your Scan quality via the Quality combo box. Check the options Imaging , Double Scan , VIS for your RTC 360. Please consult your scanner user manual for more information on what those options do. Click Start to start the scanning operation.","title":"1.8 Leica RTC360 Laser Scanner"},{"location":"dc-pilot/pilot-guide/#19-boston-dynamics-spot-arm","text":"| | This panel enables you to operate the Boston Dynamics Spot Arm if your Spot robot has been configured with one. Please take note that your cameras should be set to Spot's Default Black and White Cameras in order for this to function. Click Operate to start the Arm operation This will pop up a separate window that shows the black and white cameras on Spot. Click on the desired target area to run the arm manipulation operation. Click Run to start the arm operation.","title":"1.9 Boston Dynamics Spot Arm"},{"location":"dc-pilot/pilot-sdk/","text":"dC Pilot SDK The dC Pilot SDK allows you to develop your own custom robot Teleoperations apps easily. You will need: C++14 compatible compiler ( VS2022 recommended ) For AutoDrive: CUDA enabled GPU Windows 10 2.1 Discovering your robots The first step you need to perform is to run the discovery service to find the robot you want registered in your fleet. Here are the required includes: #include <iostream> #include <string> #include <cxxopts.hpp> #include <robotDiscovery.h> #include <robotPilot.h> #include <robotNode.h> #include <unordered_map> #include <functional> #include <algorithm> #include <chrono> #include <thread> Next, start the robot discovery service: // Create the robot discovery service auto rDiscovery = DashMicroSv :: getRobotDiscovery (); // Login with your credetials if ( ! rDiscovery -> loginCloud ( userName , pwd )) { std :: cout << \"ERROR! Invalid Login Credentials.\" << std :: endl ; return ; } // Start the discovery rDiscovery -> startDiscovery (); You can now write a simple function like the one below to find the robot you want: std :: shared_ptr < DashMicroSv :: RobotNode > findRobotWithName ( DashMicroSv :: RobotDiscovery & rDiscoveryIn , const std :: string & robotName , bool printList ) { std :: shared_ptr < DashMicroSv :: RobotNode > retBot = nullptr ; auto aliveBots = rDiscoveryIn . getAliveRobots (); if ( printList ) { printRobotList ( aliveBots ); } for ( const auto & aBot : aliveBots ) { if ( aBot -> getName () == robotName ) { retBot = aBot ; break ; } } return retBot ; } So go ahead and retrieve your robot: auto myRobotNode = findRobotWithName ( * rDiscovery , \"myRobot\" , true ); With your robot found, it is now time to construct the Pilot and control it via teleoperation commands. 2.2 Teleoperations Use the robot you found in the previous section to construct your Pilot : auto myPilot = std :: make_shared ( * rDiscovery , * myRobotNode ); // Now connect to the robot if ( ! myPilot -> connect ()) { std :: cout << \"ERROR! Unable to connect to robot!\" << std :: endl ; return ; } Game Loop Ticking, Moving Robot, Retrieving images The recommended implementation to operate the robot is via a simple Game Loop . From there you can tick and send velocity commands as well as retrieve images from your robot. Some pseudo code of how it will look like is presented below: std :: vector < cv :: Mat > camImgs ; while ( true ) { // Retrieve camera images myPilot -> tick ( camImgs ); ProcessCamImgs ( camImgs ); // Move robot float x = 0 , y = 0 , rot = 0 ; RetrieveJoystick ( x , y , rot ); myPilot -> setFreeMoveVel ( x , y , rot ); // In MS Pause ( 1.0 ); } This concludes the simple tutorial/writeup on how to use the Pilot SDK to teleoperate your own robots.","title":"2.0 d.ASH Pilot SDK"},{"location":"dc-pilot/pilot-sdk/#dc-pilot-sdk","text":"The dC Pilot SDK allows you to develop your own custom robot Teleoperations apps easily. You will need: C++14 compatible compiler ( VS2022 recommended ) For AutoDrive: CUDA enabled GPU Windows 10","title":"dC Pilot SDK"},{"location":"dc-pilot/pilot-sdk/#21-discovering-your-robots","text":"The first step you need to perform is to run the discovery service to find the robot you want registered in your fleet. Here are the required includes: #include <iostream> #include <string> #include <cxxopts.hpp> #include <robotDiscovery.h> #include <robotPilot.h> #include <robotNode.h> #include <unordered_map> #include <functional> #include <algorithm> #include <chrono> #include <thread> Next, start the robot discovery service: // Create the robot discovery service auto rDiscovery = DashMicroSv :: getRobotDiscovery (); // Login with your credetials if ( ! rDiscovery -> loginCloud ( userName , pwd )) { std :: cout << \"ERROR! Invalid Login Credentials.\" << std :: endl ; return ; } // Start the discovery rDiscovery -> startDiscovery (); You can now write a simple function like the one below to find the robot you want: std :: shared_ptr < DashMicroSv :: RobotNode > findRobotWithName ( DashMicroSv :: RobotDiscovery & rDiscoveryIn , const std :: string & robotName , bool printList ) { std :: shared_ptr < DashMicroSv :: RobotNode > retBot = nullptr ; auto aliveBots = rDiscoveryIn . getAliveRobots (); if ( printList ) { printRobotList ( aliveBots ); } for ( const auto & aBot : aliveBots ) { if ( aBot -> getName () == robotName ) { retBot = aBot ; break ; } } return retBot ; } So go ahead and retrieve your robot: auto myRobotNode = findRobotWithName ( * rDiscovery , \"myRobot\" , true ); With your robot found, it is now time to construct the Pilot and control it via teleoperation commands.","title":"2.1 Discovering your robots"},{"location":"dc-pilot/pilot-sdk/#22-teleoperations","text":"Use the robot you found in the previous section to construct your Pilot : auto myPilot = std :: make_shared ( * rDiscovery , * myRobotNode ); // Now connect to the robot if ( ! myPilot -> connect ()) { std :: cout << \"ERROR! Unable to connect to robot!\" << std :: endl ; return ; }","title":"2.2 Teleoperations"},{"location":"dc-pilot/pilot-sdk/#game-loop-ticking-moving-robot-retrieving-images","text":"The recommended implementation to operate the robot is via a simple Game Loop . From there you can tick and send velocity commands as well as retrieve images from your robot. Some pseudo code of how it will look like is presented below: std :: vector < cv :: Mat > camImgs ; while ( true ) { // Retrieve camera images myPilot -> tick ( camImgs ); ProcessCamImgs ( camImgs ); // Move robot float x = 0 , y = 0 , rot = 0 ; RetrieveJoystick ( x , y , rot ); myPilot -> setFreeMoveVel ( x , y , rot ); // In MS Pause ( 1.0 ); } This concludes the simple tutorial/writeup on how to use the Pilot SDK to teleoperate your own robots.","title":"Game Loop Ticking, Moving Robot, Retrieving images"},{"location":"getting-started/config-connect/","text":"Configuring Sensors 2.1 Velodyne Driver 2.1.1 Setting Up on Sensor By default, the Velodyne LIDAR sensor IP address is factory set on default value 192.168.1.201 . The d.ASH SDK will assume the default Velodyne IP address. 2.1.2 Setting Up on Personal Computer You'll need to configure a static IP address for your computer to use an address within the range 192.168.1.XXX where XXX may be any integer from 2 to 254, except 201 (which is the LIDAR\u2019s IP). For example, an appropriate static IP address for your compute could be 192.168.1.100 . 2.1.3 Testing Velodyne Sensors Now, let's test your lidar sensors. To test the Velodyne VLP-16 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_velodyne.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points 2.2 Ouster Driver 2.2.1 Setting Up on Sensor By default, the Ouster LIDAR sensor IP address is factory set on your IPv6/IPv4 link-local address. The addresses lie within the block 169.254.0.0 to 169.254.255.255 . To change the static IP address for Ouster, refer to the Ouster Documentation . It is recommended to set up your own static IP address. 2.2.2 Setting Up on Personal Computer You'll need to configure a static IP address for your computer to use an address within the range 192.0.2.XXX where XXX may be any integer from 2 to 254. For example, an appropriate static IP address for your compute could be 192.0.2.123 . 2.1.3 Testing Ouster Sensors To test the Ouster OS1-32 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_ouster.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.0 Configuring Sensors"},{"location":"getting-started/config-connect/#configuring-sensors","text":"","title":"Configuring Sensors"},{"location":"getting-started/config-connect/#21-velodyne-driver","text":"","title":"2.1 Velodyne Driver"},{"location":"getting-started/config-connect/#211-setting-up-on-sensor","text":"By default, the Velodyne LIDAR sensor IP address is factory set on default value 192.168.1.201 . The d.ASH SDK will assume the default Velodyne IP address.","title":"2.1.1 Setting Up on Sensor"},{"location":"getting-started/config-connect/#212-setting-up-on-personal-computer","text":"You'll need to configure a static IP address for your computer to use an address within the range 192.168.1.XXX where XXX may be any integer from 2 to 254, except 201 (which is the LIDAR\u2019s IP). For example, an appropriate static IP address for your compute could be 192.168.1.100 .","title":"2.1.2 Setting Up on Personal Computer"},{"location":"getting-started/config-connect/#213-testing-velodyne-sensors","text":"Now, let's test your lidar sensors. To test the Velodyne VLP-16 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_velodyne.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.1.3 Testing Velodyne Sensors"},{"location":"getting-started/config-connect/#22-ouster-driver","text":"","title":"2.2 Ouster Driver"},{"location":"getting-started/config-connect/#221-setting-up-on-sensor","text":"By default, the Ouster LIDAR sensor IP address is factory set on your IPv6/IPv4 link-local address. The addresses lie within the block 169.254.0.0 to 169.254.255.255 . To change the static IP address for Ouster, refer to the Ouster Documentation . It is recommended to set up your own static IP address.","title":"2.2.1 Setting Up on Sensor"},{"location":"getting-started/config-connect/#222-setting-up-on-personal-computer","text":"You'll need to configure a static IP address for your computer to use an address within the range 192.0.2.XXX where XXX may be any integer from 2 to 254. For example, an appropriate static IP address for your compute could be 192.0.2.123 .","title":"2.2.2 Setting Up on Personal Computer"},{"location":"getting-started/config-connect/#213-testing-ouster-sensors","text":"To test the Ouster OS1-32 lidar sensor, run the following command: cd dash_sdk/launch roslaunch autonomy_ouster.launch Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: rostopic echo /velodyne_points","title":"2.1.3 Testing Ouster Sensors"},{"location":"getting-started/config-spot/","text":"Configuring Spot This section of the d.ASH SDK documentation provides details about setting up Spot with the d.ASH SDK. To configure Spot, you will need to set up on the robot itself and on your personal computer. For further enquiries of setting up Spot, follow Boston Dynamics Documentation . 1.1 Setting Up On Spot By default, user and admin credentials are printed on the label of the robot's battery compartment. Otherwise, you can create your own account through the admin console by creating a user with admin privileges. Check out Boston Dynamics Documentation for more information on how to do so. Remember your credentials! Remember your Spot credentials as you will need those same credentials to set up the next section on your personal computer. 1.2 Setting Up On PC By default, the Spot robot IP address is 10.0.0.3 . If you have more than one Spot robot, refer to the Boston Dynamics Documentation to use the admin console to change the default IP of additional robots to avoid address conflicts. You'll need to configure a static IP address for your computer to use an address within the range 10.0.0.X where X may be any integer from 2 to 254, except 3 (which is the Spot's IP). For example, an appropriate static IP address for your compute could be 10.0.0.100 . You will then be asked to enter a valid admin or operator username and password. These credentials will match the credentials on Spot's battery compartment.","title":"1.0 Configuring Spot"},{"location":"getting-started/config-spot/#configuring-spot","text":"This section of the d.ASH SDK documentation provides details about setting up Spot with the d.ASH SDK. To configure Spot, you will need to set up on the robot itself and on your personal computer. For further enquiries of setting up Spot, follow Boston Dynamics Documentation .","title":"Configuring Spot"},{"location":"getting-started/config-spot/#11-setting-up-on-spot","text":"By default, user and admin credentials are printed on the label of the robot's battery compartment. Otherwise, you can create your own account through the admin console by creating a user with admin privileges. Check out Boston Dynamics Documentation for more information on how to do so. Remember your credentials! Remember your Spot credentials as you will need those same credentials to set up the next section on your personal computer.","title":"1.1 Setting Up On Spot"},{"location":"getting-started/config-spot/#12-setting-up-on-pc","text":"By default, the Spot robot IP address is 10.0.0.3 . If you have more than one Spot robot, refer to the Boston Dynamics Documentation to use the admin console to change the default IP of additional robots to avoid address conflicts. You'll need to configure a static IP address for your computer to use an address within the range 10.0.0.X where X may be any integer from 2 to 254, except 3 (which is the Spot's IP). For example, an appropriate static IP address for your compute could be 10.0.0.100 . You will then be asked to enter a valid admin or operator username and password. These credentials will match the credentials on Spot's battery compartment.","title":"1.2 Setting Up On PC"},{"location":"getting-started/dash-eng/","text":"Interfacing d.ASH Autonomy Engine with ROS This section of the d.ASH SDK documentation provides details about using ROS with the d.ASH autonomy engine. Described below are ROS topics, along with their type and functionality. 4.1 Publications Topic Type Function /active_path nav_mgs/Path Returns current path being executed. /image sensor_msgs/Image Returns sensor image. /initial_pose geometry_msgs/PoseWithCovarianceStamped Returns initial pose estimate for localization. /localization_status std_msgs/String Returns status of localization certainty. /mcl_pose_marker visualization_msgs/Marker Returns current localization position. /nearest_wpts visualization_msgs/Marker Returns nearest waypoints for the robot to follow. /odom nav_msgs/Odometry Returns odometry reading. /original_path nav_msgs/Path Returns original path before processing. /particle_array geometry_msgs/PoseArray Returns localization particle certainty. /tracking_wpt std_msgs/Float32MultiArray Returns nearest waypoints for the robot to follow. 4.2 Subscriptions Topic Type Function /cmd_vel geometry_msgs/Twist Accepts manual command velocity. /imu sensor_msgs/Imu Accepts imu sensor data. /initial_pose geometry_msgs/PoseWithCovarianceStamped Accepts initial pose estimate for localization. /joy sensor_msgs/Joy Accepts joystick message. /move_base_simple/goal geometry_msgs/PoseStamped Accepts final goal from RVIZ. /odom nav_msgs/Odometry Accepts odometry reading. /lidar_points sensor_msgs/PointCloud2 Accepts lidar scan.","title":"4.0 d.ASH with ROS"},{"location":"getting-started/dash-eng/#interfacing-dash-autonomy-engine-with-ros","text":"This section of the d.ASH SDK documentation provides details about using ROS with the d.ASH autonomy engine. Described below are ROS topics, along with their type and functionality.","title":"Interfacing d.ASH Autonomy Engine with ROS"},{"location":"getting-started/dash-eng/#41-publications","text":"Topic Type Function /active_path nav_mgs/Path Returns current path being executed. /image sensor_msgs/Image Returns sensor image. /initial_pose geometry_msgs/PoseWithCovarianceStamped Returns initial pose estimate for localization. /localization_status std_msgs/String Returns status of localization certainty. /mcl_pose_marker visualization_msgs/Marker Returns current localization position. /nearest_wpts visualization_msgs/Marker Returns nearest waypoints for the robot to follow. /odom nav_msgs/Odometry Returns odometry reading. /original_path nav_msgs/Path Returns original path before processing. /particle_array geometry_msgs/PoseArray Returns localization particle certainty. /tracking_wpt std_msgs/Float32MultiArray Returns nearest waypoints for the robot to follow.","title":"4.1 Publications"},{"location":"getting-started/dash-eng/#42-subscriptions","text":"Topic Type Function /cmd_vel geometry_msgs/Twist Accepts manual command velocity. /imu sensor_msgs/Imu Accepts imu sensor data. /initial_pose geometry_msgs/PoseWithCovarianceStamped Accepts initial pose estimate for localization. /joy sensor_msgs/Joy Accepts joystick message. /move_base_simple/goal geometry_msgs/PoseStamped Accepts final goal from RVIZ. /odom nav_msgs/Odometry Accepts odometry reading. /lidar_points sensor_msgs/PointCloud2 Accepts lidar scan.","title":"4.2 Subscriptions"},{"location":"getting-started/map-loading/","text":"Map Loading This section of the d.ASH SDK documentation provides details about file organisation of autonomy maps for the d.ASH SDK. To load a new map, upload the autonomy map files in the folder maps found in /dash_sdk/.data/maps . Please ensure that the following files are in the folder: dash-sdk/ \u2514\u2500 .data/ \u2514\u2500 maps \u2514\u2500 <MAP_NAME>.png # 2D Autonomy Map \u2514\u2500 <MAP_NAME>.pcd # 3D Autonomy Map \u2514\u2500 <MAP_NAME>.json # Global Planner Configuration To activate the new map, ensure the map name in auto_config.json file matches <MAP_NAME> . For example: \"map_name\": \"outdoor_map\",","title":"3.0 Map Loading"},{"location":"getting-started/map-loading/#map-loading","text":"This section of the d.ASH SDK documentation provides details about file organisation of autonomy maps for the d.ASH SDK. To load a new map, upload the autonomy map files in the folder maps found in /dash_sdk/.data/maps . Please ensure that the following files are in the folder: dash-sdk/ \u2514\u2500 .data/ \u2514\u2500 maps \u2514\u2500 <MAP_NAME>.png # 2D Autonomy Map \u2514\u2500 <MAP_NAME>.pcd # 3D Autonomy Map \u2514\u2500 <MAP_NAME>.json # Global Planner Configuration To activate the new map, ensure the map name in auto_config.json file matches <MAP_NAME> . For example: \"map_name\": \"outdoor_map\",","title":"Map Loading"},{"location":"sdk-config/auto-config/","text":"Auto Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the robot - auto_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure autonomy. 4.1 Config File { \"py_address\" : \"0.0.0.0:50051\" , \"ue_address\" : \"0.0.0.0:50052\" , \"ssl\" : true , \"motion_planner\" : true , \"localization\" : true , \"sim_mode\" : false , \"send_data_gui\" : true , \"camera\" : \"RealsenseCam\" , \"retrieveImg\" : false , \"map_name\" : \"office_lvl4\" , \"pc_topic\" : \"velodyne_points\" , \"odom_topic\" : \"odom\" , \"controller\" :{ \"linear_window\" : 0.5 , \"linear_min_v\" : 0.0 , \"linear_max_v\" : 0.8 , \"angular_max_w\" : 3.142 , \"linear_max_a\" : 1.0 , \"angular_max_a\" : 5.0 , \"robot_width\" : 0.4 , \"robot_length\" : 1.0 , \"obstacle_cost_gains\" : 3.0 , \"speed_cost_gains\" : 1.0 , \"goal_cost_gains\" : 4.0 , \"angular_speed_cost_scaling_factor\" : 0.1 , \"linear_num_window_steps\" : 50 , \"angular_num_window_steps\" : 30 , \"prediction_window\" : 5.0 , \"costmap_size\" : 20.0 , \"costmap_scale\" : 0.1 , \"max_pc_height\" : 0.2 , \"min_pc_height\" : - 0.5 , \"x_filter\" :[ - 0.2 , 0.2 ], \"y_filter\" :[ - 0.1 , 0.1 ], \"costmap_obs_inflation\" : 1.0 , \"occ_obs_deadzone\" : 0.2 , \"dt\" : 0.1 , \"visualise\" : false }, \"state_estimator\" :{ \"initial_x\" : - 7.7 , \"initial_y\" : - 14.5 , \"initial_z\" : 1.0 , \"initial_w\" : - 0.177 , \"kImuTopic\" : \"imu\" , \"kPoseTopic\" : \"mcl_pose\" , \"ktfUpdate\" : 0.02 , \"kStatusUpdate\" : 1.0 , \"kLoggingUpdate\" : 15.0 , \"kposeDiffmax\" : 5.0 , \"KUse_imu_ori\" : false , \"kBadCovThres\" : 2.0 , \"kGoodCovThres\" : 0.7 , \"kCovBadMax\" : 10 , \"kCovGoodtMax\" : 5 , \"kFilter_z\" : true , \"klimit_min\" : - 0.3 , \"klimit_max\" : 5.0 }, \"planner\" :{ \"lookAheadIndex\" : 15 , \"enable_self_rotate\" : false , \"self_rotation_speed\" : 0.5 , \"self_rotation_speed_final\" : 0.3 , \"dis_threshold\" : 0.5 , \"theta_threshold\" : 0.2 , \"cmd_Smoothing\" : true , } } 4.2 Definitions 4.2.1 Main Variable Definition py_address The address of the d.ASH server in the formal <IP>:<PORT> . ue_address The address of the GUI server in the formal <IP>:<PORT> . ssl Enables secure SSL messaging and encryption. motion_planner Enables autonomy motion planning. localization Enables robot localisation, returning users position and orientation in relation to map. sim_mode Enables Spot odometry retrieval. send_data_gui Enables ability to send data to GUI server for visualisation. camera Camera active for the current session to retrieve data ie. RealsenseCam, TestCam . retrieveImg Enables image retrieval. map_name Map name used for autonomy (as mentioned in File Organisation ). pc_topic ROS point cloud topic name for subscribing odom_topic ROS odometry topic name for subscribing. 4.2.2 Controller For the following parameters, ensure the value is within limits of the robot as per its documentation. Variable Definition linear_window Sets DWA (dynamic window approach) size. linear_min_v Sets minimum linear velocity for autonomy. linear_max_v Sets maximum linear velocity for autonomy. angular_max_w Sets maximum angular velocity for autonomy. linear_max_a Sets maximum linear acceleration for autonomy. angular_max_a Sets maximum angular acceleration for autonomy. robot_width Reflects width of robot. robot_length Reflects the length of robot. obstacle_cost_gains Sets weight for an obstacle course based on the weighted sum of the map. speed_cost_gains Sets weight for speed cost. goal_cost_gains Sets weight for goal cost. angular_speed_cost_scaling_factor Sets weight for angular velocity. Note that a higher value of the variable discourages the robot from turning. linear_num_window_steps Sets number of linear velocity values to consider. Note that a higher value of the variable slows down the computations. angular_num_window_steps Sets number of angular velocity values to consider. Note that a higher value of the variable slows down the computations. prediction_window Sets prediction horizion (in seconds). Note that a higher value of the variable slows down the computations. costmap_size Sets local costmap size (in meters). costmap_scale Sets scale to convert map from meter to pixels. max_pc_height Sets maximum point cloud height to be considered as an obstacle. min_pc_height Sets minimum point cloud height to be considered as an obstacle. Note that the point cloud height is measured from the center of the lidar. If the ground is detected, it will be considered as an obstacle. Therefore, set the minimum value to be above the ground. x_filter Sets vector of size 2 consisting the minimum and maximum x-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. y_filter Sets vector of size 2 consisting the minimum and maximum y-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. costmap_obs_inflation Sets inflation radius of obstacles to be considered in planning. Note that a higher value of the variable results in more conservative planning. occ_obs_deadzone Sets minimum distances from obstacles and robots for autonomy. dt Sets timestep. Note that a higher timestamp slows down the computation. visualise Enables visualisation of costmap. This is used only for debugging. 4.2.3 State Estimator Variable Definition initial_x Sets initialization of x-axis for localizaition (in meters). initial_y Sets initialization of y-axis for localizaition (in meters). initial_z Sets initialization of z-axis for localizaition (in meters). initial_w Sets initialization of orientation for localizaition. kImuTopic ROS IMU (Inertial Measurement Unit) topic name for subscribing. kPoseTopic Enables localization result. ktfUpdate Sets ROS tf publishing frequency. kStatusUpdate Sets localisation status of publishing frequency. kLoggingUpdate Sets data logging period. kposeDiffmax Sets the maximum distance between two consecutive pose estimation. KUse_imu_ori Enables IMU (Inertial Measurement Unit) or odom orientation for odometry estimation. If this variable is set to true, ensure kImuTopic is available. kBadCovThres Sets localization quality. kGoodCovThres Sets localization quality. kCovBadMax Sets localization quality. kCovGoodtMax Sets localization quality. kFilter_z Enables pass through filter application for localization. klimit_min Sets minimum range of pass through filter. klimit_max Sets maximum range of pass through filter. 4.2.4 Planner Variable Definition lookAheadIndexv Sets look-ahead index from the nearest waypoint for path to follow. Note that a lower index slows down the movement of the robot. Similarly, a higher index results in the robot not follow path properly. enable_self_rotate Enables one round of rotation around the robot itself before performing autonomy. This is to ensure that localisation is working before starting autonomy. self_rotation_speed Sets angular velocity of robot to turn around itself before performing autonomy (in radiants/second). self_rotation_speed_final Sets angular velocity of robot to turn around itself after performing autonomy (in radiants/second). This ensures that the final orientation of robot aligns with its goal. dis_threshold Sets maximum euclidean distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. theta_threshold Sets maximum orientation distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. cmd_Smoothing Enables smoothing control commands.","title":"4.0 Auto Configuration"},{"location":"sdk-config/auto-config/#auto-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the robot - auto_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure autonomy.","title":"Auto Configuration"},{"location":"sdk-config/auto-config/#41-config-file","text":"{ \"py_address\" : \"0.0.0.0:50051\" , \"ue_address\" : \"0.0.0.0:50052\" , \"ssl\" : true , \"motion_planner\" : true , \"localization\" : true , \"sim_mode\" : false , \"send_data_gui\" : true , \"camera\" : \"RealsenseCam\" , \"retrieveImg\" : false , \"map_name\" : \"office_lvl4\" , \"pc_topic\" : \"velodyne_points\" , \"odom_topic\" : \"odom\" , \"controller\" :{ \"linear_window\" : 0.5 , \"linear_min_v\" : 0.0 , \"linear_max_v\" : 0.8 , \"angular_max_w\" : 3.142 , \"linear_max_a\" : 1.0 , \"angular_max_a\" : 5.0 , \"robot_width\" : 0.4 , \"robot_length\" : 1.0 , \"obstacle_cost_gains\" : 3.0 , \"speed_cost_gains\" : 1.0 , \"goal_cost_gains\" : 4.0 , \"angular_speed_cost_scaling_factor\" : 0.1 , \"linear_num_window_steps\" : 50 , \"angular_num_window_steps\" : 30 , \"prediction_window\" : 5.0 , \"costmap_size\" : 20.0 , \"costmap_scale\" : 0.1 , \"max_pc_height\" : 0.2 , \"min_pc_height\" : - 0.5 , \"x_filter\" :[ - 0.2 , 0.2 ], \"y_filter\" :[ - 0.1 , 0.1 ], \"costmap_obs_inflation\" : 1.0 , \"occ_obs_deadzone\" : 0.2 , \"dt\" : 0.1 , \"visualise\" : false }, \"state_estimator\" :{ \"initial_x\" : - 7.7 , \"initial_y\" : - 14.5 , \"initial_z\" : 1.0 , \"initial_w\" : - 0.177 , \"kImuTopic\" : \"imu\" , \"kPoseTopic\" : \"mcl_pose\" , \"ktfUpdate\" : 0.02 , \"kStatusUpdate\" : 1.0 , \"kLoggingUpdate\" : 15.0 , \"kposeDiffmax\" : 5.0 , \"KUse_imu_ori\" : false , \"kBadCovThres\" : 2.0 , \"kGoodCovThres\" : 0.7 , \"kCovBadMax\" : 10 , \"kCovGoodtMax\" : 5 , \"kFilter_z\" : true , \"klimit_min\" : - 0.3 , \"klimit_max\" : 5.0 }, \"planner\" :{ \"lookAheadIndex\" : 15 , \"enable_self_rotate\" : false , \"self_rotation_speed\" : 0.5 , \"self_rotation_speed_final\" : 0.3 , \"dis_threshold\" : 0.5 , \"theta_threshold\" : 0.2 , \"cmd_Smoothing\" : true , } }","title":"4.1 Config File"},{"location":"sdk-config/auto-config/#42-definitions","text":"","title":"4.2 Definitions"},{"location":"sdk-config/auto-config/#421-main","text":"Variable Definition py_address The address of the d.ASH server in the formal <IP>:<PORT> . ue_address The address of the GUI server in the formal <IP>:<PORT> . ssl Enables secure SSL messaging and encryption. motion_planner Enables autonomy motion planning. localization Enables robot localisation, returning users position and orientation in relation to map. sim_mode Enables Spot odometry retrieval. send_data_gui Enables ability to send data to GUI server for visualisation. camera Camera active for the current session to retrieve data ie. RealsenseCam, TestCam . retrieveImg Enables image retrieval. map_name Map name used for autonomy (as mentioned in File Organisation ). pc_topic ROS point cloud topic name for subscribing odom_topic ROS odometry topic name for subscribing.","title":"4.2.1 Main"},{"location":"sdk-config/auto-config/#422-controller","text":"For the following parameters, ensure the value is within limits of the robot as per its documentation. Variable Definition linear_window Sets DWA (dynamic window approach) size. linear_min_v Sets minimum linear velocity for autonomy. linear_max_v Sets maximum linear velocity for autonomy. angular_max_w Sets maximum angular velocity for autonomy. linear_max_a Sets maximum linear acceleration for autonomy. angular_max_a Sets maximum angular acceleration for autonomy. robot_width Reflects width of robot. robot_length Reflects the length of robot. obstacle_cost_gains Sets weight for an obstacle course based on the weighted sum of the map. speed_cost_gains Sets weight for speed cost. goal_cost_gains Sets weight for goal cost. angular_speed_cost_scaling_factor Sets weight for angular velocity. Note that a higher value of the variable discourages the robot from turning. linear_num_window_steps Sets number of linear velocity values to consider. Note that a higher value of the variable slows down the computations. angular_num_window_steps Sets number of angular velocity values to consider. Note that a higher value of the variable slows down the computations. prediction_window Sets prediction horizion (in seconds). Note that a higher value of the variable slows down the computations. costmap_size Sets local costmap size (in meters). costmap_scale Sets scale to convert map from meter to pixels. max_pc_height Sets maximum point cloud height to be considered as an obstacle. min_pc_height Sets minimum point cloud height to be considered as an obstacle. Note that the point cloud height is measured from the center of the lidar. If the ground is detected, it will be considered as an obstacle. Therefore, set the minimum value to be above the ground. x_filter Sets vector of size 2 consisting the minimum and maximum x-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. y_filter Sets vector of size 2 consisting the minimum and maximum y-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. costmap_obs_inflation Sets inflation radius of obstacles to be considered in planning. Note that a higher value of the variable results in more conservative planning. occ_obs_deadzone Sets minimum distances from obstacles and robots for autonomy. dt Sets timestep. Note that a higher timestamp slows down the computation. visualise Enables visualisation of costmap. This is used only for debugging.","title":"4.2.2 Controller"},{"location":"sdk-config/auto-config/#423-state-estimator","text":"Variable Definition initial_x Sets initialization of x-axis for localizaition (in meters). initial_y Sets initialization of y-axis for localizaition (in meters). initial_z Sets initialization of z-axis for localizaition (in meters). initial_w Sets initialization of orientation for localizaition. kImuTopic ROS IMU (Inertial Measurement Unit) topic name for subscribing. kPoseTopic Enables localization result. ktfUpdate Sets ROS tf publishing frequency. kStatusUpdate Sets localisation status of publishing frequency. kLoggingUpdate Sets data logging period. kposeDiffmax Sets the maximum distance between two consecutive pose estimation. KUse_imu_ori Enables IMU (Inertial Measurement Unit) or odom orientation for odometry estimation. If this variable is set to true, ensure kImuTopic is available. kBadCovThres Sets localization quality. kGoodCovThres Sets localization quality. kCovBadMax Sets localization quality. kCovGoodtMax Sets localization quality. kFilter_z Enables pass through filter application for localization. klimit_min Sets minimum range of pass through filter. klimit_max Sets maximum range of pass through filter.","title":"4.2.3 State Estimator"},{"location":"sdk-config/auto-config/#424-planner","text":"Variable Definition lookAheadIndexv Sets look-ahead index from the nearest waypoint for path to follow. Note that a lower index slows down the movement of the robot. Similarly, a higher index results in the robot not follow path properly. enable_self_rotate Enables one round of rotation around the robot itself before performing autonomy. This is to ensure that localisation is working before starting autonomy. self_rotation_speed Sets angular velocity of robot to turn around itself before performing autonomy (in radiants/second). self_rotation_speed_final Sets angular velocity of robot to turn around itself after performing autonomy (in radiants/second). This ensures that the final orientation of robot aligns with its goal. dis_threshold Sets maximum euclidean distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. theta_threshold Sets maximum orientation distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. cmd_Smoothing Enables smoothing control commands.","title":"4.2.4 Planner"},{"location":"sdk-config/register-bot/","text":"Register Payload Configuration This section of the d.ASH SDK documentation provides details about the configuration file for payload registration - register_payload_config - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure payload registration. 2.1 Config File { \"robot_name\" : \"<ROBOT_NAME>\" , \"robot_username\" : \"<DC_USERNAME>\" } 2.2 Definitions Variable Definition robotName Set the name of your robot - this can be any string. robotUserName Set the name of your username - this has to match your dConstruct cloud admin username.","title":"2.0 Register Payload Configuration"},{"location":"sdk-config/register-bot/#register-payload-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for payload registration - register_payload_config - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure payload registration.","title":"Register Payload Configuration"},{"location":"sdk-config/register-bot/#21-config-file","text":"{ \"robot_name\" : \"<ROBOT_NAME>\" , \"robot_username\" : \"<DC_USERNAME>\" }","title":"2.1 Config File"},{"location":"sdk-config/register-bot/#22-definitions","text":"Variable Definition robotName Set the name of your robot - this can be any string. robotUserName Set the name of your username - this has to match your dConstruct cloud admin username.","title":"2.2 Definitions"},{"location":"sdk-config/rest-config/","text":"d.ASH Service Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the rest server - dash_service_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure the d.ASH service. 1.1 Config File { \"port\" : 3000 , \"cert_filename\" : \"./cert.pem\" , \"key_filename\" : \"./key.pem\" , \"dh_params_filename\" : \"\" , \"robot_register_native_cert\" : true , \"active_IP_idx\" : 1 , \"preferred_IP\" : \"10.8.0.5\" , \"run_cmds\" : { \"py_server\" : { \"cmd_str\" : \"python ./spot_server.py ./configs/dash-service-config.json <!TOKEN!>\" , \"cmd_path\" : \"C:/Users/dc/Documents/Projects/dc/dash_code/py_server\" } } } 1.2 Definitions 1.2.1 Main Variable Definition port Fixed port number. cert_filename Fixed certification filename. key_filename Fixed certification key filename. dh_params_filename Fixed parameter filename. robot_register_native_cert If you registed with register_bot_native, the data will be encrypted. Always set this variable to true. active_IP_idx Selects the IP address you will send to the backend cloud service for robot discovery. This is an integer index ( from 0 to N ), based on the IP addresses available on your system. When the rest service starts up, you should see a list. Set the value to the appropriate index you want. This index will map the the IP which the clients will try to connect to. preferred_IP Selects your preferred IP from the list of IPs. Specify the IP as a string in this case. 1.2.2 d.ASH Server Commands Variable Definition cmd_str Sets command to run d.ASH server. cmd_path Sets command path.","title":"1.0 d.ASH Service Configuration"},{"location":"sdk-config/rest-config/#dash-service-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the rest server - dash_service_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions to configure the d.ASH service.","title":"d.ASH Service Configuration"},{"location":"sdk-config/rest-config/#11-config-file","text":"{ \"port\" : 3000 , \"cert_filename\" : \"./cert.pem\" , \"key_filename\" : \"./key.pem\" , \"dh_params_filename\" : \"\" , \"robot_register_native_cert\" : true , \"active_IP_idx\" : 1 , \"preferred_IP\" : \"10.8.0.5\" , \"run_cmds\" : { \"py_server\" : { \"cmd_str\" : \"python ./spot_server.py ./configs/dash-service-config.json <!TOKEN!>\" , \"cmd_path\" : \"C:/Users/dc/Documents/Projects/dc/dash_code/py_server\" } } }","title":"1.1 Config File"},{"location":"sdk-config/rest-config/#12-definitions","text":"","title":"1.2 Definitions"},{"location":"sdk-config/rest-config/#121-main","text":"Variable Definition port Fixed port number. cert_filename Fixed certification filename. key_filename Fixed certification key filename. dh_params_filename Fixed parameter filename. robot_register_native_cert If you registed with register_bot_native, the data will be encrypted. Always set this variable to true. active_IP_idx Selects the IP address you will send to the backend cloud service for robot discovery. This is an integer index ( from 0 to N ), based on the IP addresses available on your system. When the rest service starts up, you should see a list. Set the value to the appropriate index you want. This index will map the the IP which the clients will try to connect to. preferred_IP Selects your preferred IP from the list of IPs. Specify the IP as a string in this case.","title":"1.2.1 Main"},{"location":"sdk-config/rest-config/#122-dash-server-commands","text":"Variable Definition cmd_str Sets command to run d.ASH server. cmd_path Sets command path.","title":"1.2.2 d.ASH Server Commands"},{"location":"sdk-config/robot-config/","text":"Robot Configuration This section of the d.ASH SDK documentation provides details about the configuration file for the robot - robot_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions used to configure the d.ASH server. 3.1 Config File { \"server_address\" : \"localhost:50051\" , \"robot_hostname\" : \"192.168.80.3\" , \"username\" : \"<USERNAME>\" , \"cam_list\" : [ \"RealsenseCam\" ], \"payloads\" : [], \"data_state_log_folder\" : \"G:/Temp/logs\" , \"ssl\" : true , \"fast_server\" : false , \"fast_server_hostname\" : \"localhost:7777\" , \"secure_default_token\" : false , \"test_mode\" : true , \"with_audio\" : true , \"real_sense_config\" : { \"test\" : true , \"test_filenames\" : [ \"../../test_videos/nus_left.mp4\" , \"../../test_videos/nus_center.mp4\" , \"../../test_videos/nus_right.mp4\" ], \"flip_options\" : { \"0\" : [ false , false ], \"1\" : [ true , true ], \"2\" : [ false , false ] }, \"base_width\" : 640 , \"base_height\" : 480 , \"codec\" : \"video\" , \"width\" : 320 , \"height\" : 240 , \"bitrate\" : 3600000 } } 3.2 Definitions 3.2.1 Main Variable Definition server_address Sets address of the d.ASH server in <HOSTNAME>:<PORT> format. robot_hostname Sets hostname of the Spot to connect to robot's IP. username Sets username for d.ASH server credentials. cam_list Sets a list of cameras active for the current session. payloads Optional payloads list. data_state_log_folder Sets folder to write out the recorded msgpack data of the robot. ssl Enables secure SSL messaging and encryption. test_mode Enables the d.ASH server to enter into test mode. with_audio Enables audio streaming playback. 3.2.2 Intel RealSense Configuration Variable Definition test Enables simulation of camera streaming via provided custom mp4 video files specified as a list in test_filenames . test_filenames List of test files. flip_options Specify how each camera flips long the x-axis and y-axis following the format {\"index\" : [x-flip, y-flip]} . baseWidth Sets processing width of the camera stream. Note that a minimum baseWidth of 640 is required. baseHeight Sets the processing height of the camera stream. Note that a minimum baseHeight of 360 is required. codec Sets jpg/video options, with jpg being regular jpeg encoding and video using VP9 encoding. width Adjusts the final returned/resized width dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. height Adjusts the final returned/resized height dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. bitrate This is the quality of the video encoding. Note for HD Streaming, RealSense requires a high bitrate of 3600000.","title":"3.0 Robot Configuration"},{"location":"sdk-config/robot-config/#robot-configuration","text":"This section of the d.ASH SDK documentation provides details about the configuration file for the robot - robot_config.json - found in the folder \\dash-sdk\\configs . Information in this section includes variable and definitions used to configure the d.ASH server.","title":"Robot Configuration"},{"location":"sdk-config/robot-config/#31-config-file","text":"{ \"server_address\" : \"localhost:50051\" , \"robot_hostname\" : \"192.168.80.3\" , \"username\" : \"<USERNAME>\" , \"cam_list\" : [ \"RealsenseCam\" ], \"payloads\" : [], \"data_state_log_folder\" : \"G:/Temp/logs\" , \"ssl\" : true , \"fast_server\" : false , \"fast_server_hostname\" : \"localhost:7777\" , \"secure_default_token\" : false , \"test_mode\" : true , \"with_audio\" : true , \"real_sense_config\" : { \"test\" : true , \"test_filenames\" : [ \"../../test_videos/nus_left.mp4\" , \"../../test_videos/nus_center.mp4\" , \"../../test_videos/nus_right.mp4\" ], \"flip_options\" : { \"0\" : [ false , false ], \"1\" : [ true , true ], \"2\" : [ false , false ] }, \"base_width\" : 640 , \"base_height\" : 480 , \"codec\" : \"video\" , \"width\" : 320 , \"height\" : 240 , \"bitrate\" : 3600000 } }","title":"3.1 Config File"},{"location":"sdk-config/robot-config/#32-definitions","text":"","title":"3.2 Definitions"},{"location":"sdk-config/robot-config/#321-main","text":"Variable Definition server_address Sets address of the d.ASH server in <HOSTNAME>:<PORT> format. robot_hostname Sets hostname of the Spot to connect to robot's IP. username Sets username for d.ASH server credentials. cam_list Sets a list of cameras active for the current session. payloads Optional payloads list. data_state_log_folder Sets folder to write out the recorded msgpack data of the robot. ssl Enables secure SSL messaging and encryption. test_mode Enables the d.ASH server to enter into test mode. with_audio Enables audio streaming playback.","title":"3.2.1 Main"},{"location":"sdk-config/robot-config/#322-intel-realsense-configuration","text":"Variable Definition test Enables simulation of camera streaming via provided custom mp4 video files specified as a list in test_filenames . test_filenames List of test files. flip_options Specify how each camera flips long the x-axis and y-axis following the format {\"index\" : [x-flip, y-flip]} . baseWidth Sets processing width of the camera stream. Note that a minimum baseWidth of 640 is required. baseHeight Sets the processing height of the camera stream. Note that a minimum baseHeight of 360 is required. codec Sets jpg/video options, with jpg being regular jpeg encoding and video using VP9 encoding. width Adjusts the final returned/resized width dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. height Adjusts the final returned/resized height dimensions of the input camera stream. Video will be processed at this base resolution before being resized via width and height . Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. bitrate This is the quality of the video encoding. Note for HD Streaming, RealSense requires a high bitrate of 3600000.","title":"3.2.2 Intel RealSense Configuration"},{"location":"setup/dash/","text":"Setting Up d.ASH As mentioned previously, the d.ASH consists of three main components - d.ASH server, d.ASH service, and d.ASH autonomy engine. This section of the d.ASH SDK documentation provides details about setting up the d.ASH components including compiling and testing. 4.1 Installing d.ASH Dependencies To install the remaining d.ASH dependencies using pip, the following desktop dependencies must be set up prior: Intel RealSense SDK 2.0 ROS Melodic on Ubuntu 18.04 FFmpeg and others If the above dependencies have been installed, proceed by running the following command to install the rest of the python packages: python3.7 config_libs.py Please ensure you are in the \\dash-sdk directory before running. Following the instructions prompted by the terminal to proceed with installation. 4.2 Setting up d.ASH Server To set up the d.ASH server, you will need to configure the d.ASH server configuration file - robot_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 robot_config.json \u2514\u2500 ... Follow the variable definitions for robot_config.json to set up the file correctly for the d.ASH server. Once robot_config.json has been set up, run the d.ASH server by executing the following command on your terminal: python3 .7 ./ dash_server . py robot_config . json 4.3 Setting up d.ASH Service To set up the d.ASH service, you will need to configure the d.ASH service configuration file - dash_service_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 dash_service_config.json \u2514\u2500 ... First, run runrest to see available IP address for your rest server: runrest Pick the index of the IP address you like and append it to the activeIPIdx variable in dash_service_config.json : \"activeIPIdx\" : 1, # where '1' is the chosen IP address index Then, you will need to set your preferredIP address, that is, the IP address for the computer onboard your robot. This IP address will have precedence over activeIPIdx . Similarly, replace the default IP address with your preferred IP address in dash_service_config.json : \"preferredIP\" : \"10.8.0.5\", # where '10.8.0.5' is the preferred IP address Ensure that the IP address of the onboard computer is within the same subnet by the remote client. Lastly, you will need to change the <PATH_OF_SDK> of cmdPath in dash_service_config.json : \"cmdPath\" : \"<PATH>\" To do this, use pwd to print your current working directory path and replace <PATH_OF_SDK> with the path printed. For example, if your current directory is /home/dash_sdk/py_server : \"cmdPath\" : \"/home/dash_sdk\" To test the d.ASH service, you'll need to run the d.ASH server by running the following command: ./ robot_rest < PATH_TO_SDK >/ configs / dash_service_config . json Now that your d.ASH service is running, you can use our d.ASH Pilot app. To launch the d.ASH Pilot app, simply search for it in your Windows search bar. Now, login to the system and connect to your robot to start controlling your robot. For more information on the d.ASH Pilot, refer to the d.ASH Pilot guide . 4.4 Setting up d.ASH Autonomy Engine To set up the d.ASH autonomy engine, you will need to configure the d.ASH autonomy configuration file - auto_config.json - located in the folder /dash-sdk/configs/ . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 auto_config.json \u2514\u2500 ... Follow the variable definitions for auto_config.json to set up the file correctly for the d.ASH autonomy engine. Once auto_config.json has been set up, test the d.ASH autonomy engine by run the executable below to start autonomy driver. Note to replace <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: ./dash_autonomy <PATH_TO_SDK>/config/auto_config.json To find your current working directory, use pwd . For example, if your directory is /home/dash-sdk , you would run the following command to test d.ASH autonomy: ./dash_autonomy /home/dash-sdk/config/auto_config.json You will need to run d.ASH service first before running the d.ASH server and the d.ASH autonomy engine. On a seperate terminal, start a simple roslaunch test by running the following prompt, replacing <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: cd \\launch roslaunch <PATH_TO_SDK>\\dash_sdk\\launch\\simple_joy.launch Launch files have been prepared for setup - either with the Velodyne VLP-16 lidar sensor or the Ouster OS1-32 lidar sensor. These lauch files can be found in under the \\dash-sdk\\launch folder. You can also create your own sensor launch files for your tests.","title":"4.0 Setting up d.ASH"},{"location":"setup/dash/#setting-up-dash","text":"As mentioned previously, the d.ASH consists of three main components - d.ASH server, d.ASH service, and d.ASH autonomy engine. This section of the d.ASH SDK documentation provides details about setting up the d.ASH components including compiling and testing.","title":"Setting Up d.ASH"},{"location":"setup/dash/#41-installing-dash-dependencies","text":"To install the remaining d.ASH dependencies using pip, the following desktop dependencies must be set up prior: Intel RealSense SDK 2.0 ROS Melodic on Ubuntu 18.04 FFmpeg and others If the above dependencies have been installed, proceed by running the following command to install the rest of the python packages: python3.7 config_libs.py Please ensure you are in the \\dash-sdk directory before running. Following the instructions prompted by the terminal to proceed with installation.","title":"4.1 Installing d.ASH Dependencies"},{"location":"setup/dash/#42-setting-up-dash-server","text":"To set up the d.ASH server, you will need to configure the d.ASH server configuration file - robot_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 robot_config.json \u2514\u2500 ... Follow the variable definitions for robot_config.json to set up the file correctly for the d.ASH server. Once robot_config.json has been set up, run the d.ASH server by executing the following command on your terminal: python3 .7 ./ dash_server . py robot_config . json","title":"4.2 Setting up d.ASH Server"},{"location":"setup/dash/#43-setting-up-dash-service","text":"To set up the d.ASH service, you will need to configure the d.ASH service configuration file - dash_service_config.json - located in the folder \\dash-sdk\\configs . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 dash_service_config.json \u2514\u2500 ... First, run runrest to see available IP address for your rest server: runrest Pick the index of the IP address you like and append it to the activeIPIdx variable in dash_service_config.json : \"activeIPIdx\" : 1, # where '1' is the chosen IP address index Then, you will need to set your preferredIP address, that is, the IP address for the computer onboard your robot. This IP address will have precedence over activeIPIdx . Similarly, replace the default IP address with your preferred IP address in dash_service_config.json : \"preferredIP\" : \"10.8.0.5\", # where '10.8.0.5' is the preferred IP address Ensure that the IP address of the onboard computer is within the same subnet by the remote client. Lastly, you will need to change the <PATH_OF_SDK> of cmdPath in dash_service_config.json : \"cmdPath\" : \"<PATH>\" To do this, use pwd to print your current working directory path and replace <PATH_OF_SDK> with the path printed. For example, if your current directory is /home/dash_sdk/py_server : \"cmdPath\" : \"/home/dash_sdk\" To test the d.ASH service, you'll need to run the d.ASH server by running the following command: ./ robot_rest < PATH_TO_SDK >/ configs / dash_service_config . json Now that your d.ASH service is running, you can use our d.ASH Pilot app. To launch the d.ASH Pilot app, simply search for it in your Windows search bar. Now, login to the system and connect to your robot to start controlling your robot. For more information on the d.ASH Pilot, refer to the d.ASH Pilot guide .","title":"4.3 Setting up d.ASH Service"},{"location":"setup/dash/#44-setting-up-dash-autonomy-engine","text":"To set up the d.ASH autonomy engine, you will need to configure the d.ASH autonomy configuration file - auto_config.json - located in the folder /dash-sdk/configs/ . dash-sdk/ \u2514\u2500 configs/ \u2514\u2500 auto_config.json \u2514\u2500 ... Follow the variable definitions for auto_config.json to set up the file correctly for the d.ASH autonomy engine. Once auto_config.json has been set up, test the d.ASH autonomy engine by run the executable below to start autonomy driver. Note to replace <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: ./dash_autonomy <PATH_TO_SDK>/config/auto_config.json To find your current working directory, use pwd . For example, if your directory is /home/dash-sdk , you would run the following command to test d.ASH autonomy: ./dash_autonomy /home/dash-sdk/config/auto_config.json You will need to run d.ASH service first before running the d.ASH server and the d.ASH autonomy engine. On a seperate terminal, start a simple roslaunch test by running the following prompt, replacing <PATH_TO_SDK> with your current working directory containing the d.ASH SDK: cd \\launch roslaunch <PATH_TO_SDK>\\dash_sdk\\launch\\simple_joy.launch Launch files have been prepared for setup - either with the Velodyne VLP-16 lidar sensor or the Ouster OS1-32 lidar sensor. These lauch files can be found in under the \\dash-sdk\\launch folder. You can also create your own sensor launch files for your tests.","title":"4.4 Setting up d.ASH Autonomy Engine"},{"location":"setup/desktop-dep/","text":"Installing Dependencies on the Desktop While most of the d.ASH SDK build is hermetic, some system dependencies on the Desktop are required. This section of the d.ASH SDK documentation provides details for Intel RealSense SDK, Ubuntu, ROS Melodic, and FFmpeg installations. 1.1 Ubuntu Installation Ubuntu is a complete Linux operating system, which will serve as the primary platform for ROS. Currently, the d.ASH SDK only supports Linux Ubuntu 18.04 LTS for development and simulation from your workstation. Ubuntu Installation via Bootable USB If you would like to install Ubuntu via a bootable USB, you can do so for both Windows and MacOS . Ubuntu Installation via Virtual Machine If you would like to install Ubuntu via a virtual machine, you can do so using VirtualBox to kickstart your installation process. Once Ubuntu is installed, check that your version of Ubuntu has the release code 18.04 . Open the terminal and type the command: lsb_release - a This should print the following result: No LSB modules are available . Distributor ID : Ubuntu Description : Ubuntu 18.04.5 LTS Release : 18.04 Codename : bionic 1.2 ROS Installation ROS (Robot Operating System) is a open-source framework that helps researchers and developers build and reuse code between robotics applications. Currently, the d.ASH SDK only supports ROS Melodic for development and simulation from your workstation. Use Ubuntu to install ROS Melodic onto your computer system. Once ROS has been installed on your Linux system, check that your version of ROS is melodic . Open the terminal and type the command: rosversion - d This should print melodic . Otherwise, ensure that you installed the correct version of ROS - ROS Melodic . 1.3 Intel RealSense SDK Installation Intel RealSense is an RGB camera with channels designed for depth perception capabilities. The RealSense SDK 2.0 provides installation packages for Intel X86 / AMD64-based Debian distributions in dpkg format for Ubuntu 16/18/20 LTS. You'll be able to configure custom settings for any Intel RealSense cameras attached to the system to stream images to remote clients. Use Ubuntu to install Intel RealSense SDK 2.0 onto your computer system. 1.4 FFmpeg Installation FFmpeg is an open-source software project consisting of libraries and programs that handle video, audio, and other multimedia files and streams. To install FFmpeg, run the following commands on your Ubuntu terminal: sudo add-apt-repository ppa:jonathonf/ffmpeg-4 sudo apt-get install ffmpeg libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev libavutil-dev libpostproc-dev libswresample-dev libswscale-dev libgoogle-glog-dev 1.5 Python Requirements The d.ASH SDK works with Python 3.7 . To properly run the server, you will also need to install a python package installer, pip. 1.5.1 apt-get Installed in Ubuntu and any Ubuntu-based Linux distribution, apt-get is tool for installing, upgrading, and cleaning packages. To set up the new environment, execute the following command on your Ubuntu terminal: sudo apt-get install -y python3.7-dev 1.5.2 Pip Installation Pip is a package installer for Python. The d.ASH SDK and the third-party packages used by many of its programming examples use pip to install. To install pip, run the following command on your Ubuntu terminal: sudo apt install python3 .7 python3 - pip python - pip python3 .7 - m pip instal -- upgrade pip","title":"1.0 Installing Desktop Dependencies"},{"location":"setup/desktop-dep/#installing-dependencies-on-the-desktop","text":"While most of the d.ASH SDK build is hermetic, some system dependencies on the Desktop are required. This section of the d.ASH SDK documentation provides details for Intel RealSense SDK, Ubuntu, ROS Melodic, and FFmpeg installations.","title":"Installing Dependencies on the Desktop"},{"location":"setup/desktop-dep/#11-ubuntu-installation","text":"Ubuntu is a complete Linux operating system, which will serve as the primary platform for ROS. Currently, the d.ASH SDK only supports Linux Ubuntu 18.04 LTS for development and simulation from your workstation. Ubuntu Installation via Bootable USB If you would like to install Ubuntu via a bootable USB, you can do so for both Windows and MacOS . Ubuntu Installation via Virtual Machine If you would like to install Ubuntu via a virtual machine, you can do so using VirtualBox to kickstart your installation process. Once Ubuntu is installed, check that your version of Ubuntu has the release code 18.04 . Open the terminal and type the command: lsb_release - a This should print the following result: No LSB modules are available . Distributor ID : Ubuntu Description : Ubuntu 18.04.5 LTS Release : 18.04 Codename : bionic","title":"1.1 Ubuntu Installation"},{"location":"setup/desktop-dep/#12-ros-installation","text":"ROS (Robot Operating System) is a open-source framework that helps researchers and developers build and reuse code between robotics applications. Currently, the d.ASH SDK only supports ROS Melodic for development and simulation from your workstation. Use Ubuntu to install ROS Melodic onto your computer system. Once ROS has been installed on your Linux system, check that your version of ROS is melodic . Open the terminal and type the command: rosversion - d This should print melodic . Otherwise, ensure that you installed the correct version of ROS - ROS Melodic .","title":"1.2 ROS Installation"},{"location":"setup/desktop-dep/#13-intel-realsense-sdk-installation","text":"Intel RealSense is an RGB camera with channels designed for depth perception capabilities. The RealSense SDK 2.0 provides installation packages for Intel X86 / AMD64-based Debian distributions in dpkg format for Ubuntu 16/18/20 LTS. You'll be able to configure custom settings for any Intel RealSense cameras attached to the system to stream images to remote clients. Use Ubuntu to install Intel RealSense SDK 2.0 onto your computer system.","title":"1.3 Intel RealSense SDK Installation"},{"location":"setup/desktop-dep/#14-ffmpeg-installation","text":"FFmpeg is an open-source software project consisting of libraries and programs that handle video, audio, and other multimedia files and streams. To install FFmpeg, run the following commands on your Ubuntu terminal: sudo add-apt-repository ppa:jonathonf/ffmpeg-4 sudo apt-get install ffmpeg libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev libavutil-dev libpostproc-dev libswresample-dev libswscale-dev libgoogle-glog-dev","title":"1.4 FFmpeg Installation"},{"location":"setup/desktop-dep/#15-python-requirements","text":"The d.ASH SDK works with Python 3.7 . To properly run the server, you will also need to install a python package installer, pip.","title":"1.5 Python Requirements"},{"location":"setup/desktop-dep/#151-apt-get","text":"Installed in Ubuntu and any Ubuntu-based Linux distribution, apt-get is tool for installing, upgrading, and cleaning packages. To set up the new environment, execute the following command on your Ubuntu terminal: sudo apt-get install -y python3.7-dev","title":"1.5.1 apt-get"},{"location":"setup/desktop-dep/#152-pip-installation","text":"Pip is a package installer for Python. The d.ASH SDK and the third-party packages used by many of its programming examples use pip to install. To install pip, run the following command on your Ubuntu terminal: sudo apt install python3 .7 python3 - pip python - pip python3 .7 - m pip instal -- upgrade pip","title":"1.5.2 Pip Installation"},{"location":"setup/payload-reg/","text":"Payload Registration Before running the d.ASH SDK, please make sure that all of your credentials have been set up correctly. This means using the right username and the right password. This section of the d.ASH SDK documentation provides details about setting up credentials for the d.ASH server, your robot, and d.ASH autonomy. Files in this section can be found in the folder registration : dash-sdk/ \u2514\u2500 registration \u2514\u2500 set_spot_cred \u2514\u2500 register_payload \u2514\u2500 set_autonomy_cred 2.1 d.ASH Server Credentials To set up the local credentials for the d.ASH server, you will need to run the file set_spot_cred . Run the following command replacing <USERNAME> with your chosen username and <PASSWORD> with your chosen password. ./set_spot_cred -u <USERNAME> -p <PASSWORD> For example, if your username is user123 and your password is pw123 , your command would look like this: ./ set_spot_cred - u user123 - p pw123 Username in Robot Configuration Please ensure that the username for the d.ASH server is the same as the one defined in the robot configuration file - robot_config.json . That is, you would replace <USERNAME> with your chosen username in \"username\" : \"<USERNAME>\" . 2.2 Robot Registration To register the payload computer with d.ASH's backend system, you will need to run the file register_payload . However, you will first need to configure the register_payload_config.json found in the \\dash-sdk\\configs folder of the SDK. Set <ROBOT_NAME> to any name you like, and set <DC_USERNAME> to your dConstruct cloud admin username. For example, if your robot name is robot1 and your cloud admin user name is user123 , your register_payload_config.json would look like this: { RobotName: robot1, RobotUserName: user123 } Now, run the following command to register your robot, replacing <PATH_TO_SDK> with your local path to the d.ASH SDK. ./register_payload -i <PATH_TO_SDK>/dash_sdk/configs/register_payload_config 2.3 d.ASH Autonomy Credentials To set up the local credentials for d.ASH autonomy, you will need to run the file set_autonomy_cred . Run the following command replacing <USERNAME> with your cloud admin username. cd ./ set_auto_cred / build ./ set_autonomy_cred - u < USERNAME > For example, if your username is user123 , your command would look like this: cd ./ set_auto_cred / build ./ set_autonomy_cred - u user123 You will then be prompted to enter a password, which will match your cloud admin password. Enter","title":"2.0 Payload Registration"},{"location":"setup/payload-reg/#payload-registration","text":"Before running the d.ASH SDK, please make sure that all of your credentials have been set up correctly. This means using the right username and the right password. This section of the d.ASH SDK documentation provides details about setting up credentials for the d.ASH server, your robot, and d.ASH autonomy. Files in this section can be found in the folder registration : dash-sdk/ \u2514\u2500 registration \u2514\u2500 set_spot_cred \u2514\u2500 register_payload \u2514\u2500 set_autonomy_cred","title":"Payload Registration"},{"location":"setup/payload-reg/#21-dash-server-credentials","text":"To set up the local credentials for the d.ASH server, you will need to run the file set_spot_cred . Run the following command replacing <USERNAME> with your chosen username and <PASSWORD> with your chosen password. ./set_spot_cred -u <USERNAME> -p <PASSWORD> For example, if your username is user123 and your password is pw123 , your command would look like this: ./ set_spot_cred - u user123 - p pw123 Username in Robot Configuration Please ensure that the username for the d.ASH server is the same as the one defined in the robot configuration file - robot_config.json . That is, you would replace <USERNAME> with your chosen username in \"username\" : \"<USERNAME>\" .","title":"2.1 d.ASH Server Credentials"},{"location":"setup/payload-reg/#22-robot-registration","text":"To register the payload computer with d.ASH's backend system, you will need to run the file register_payload . However, you will first need to configure the register_payload_config.json found in the \\dash-sdk\\configs folder of the SDK. Set <ROBOT_NAME> to any name you like, and set <DC_USERNAME> to your dConstruct cloud admin username. For example, if your robot name is robot1 and your cloud admin user name is user123 , your register_payload_config.json would look like this: { RobotName: robot1, RobotUserName: user123 } Now, run the following command to register your robot, replacing <PATH_TO_SDK> with your local path to the d.ASH SDK. ./register_payload -i <PATH_TO_SDK>/dash_sdk/configs/register_payload_config","title":"2.2 Robot Registration"},{"location":"setup/payload-reg/#23-dash-autonomy-credentials","text":"To set up the local credentials for d.ASH autonomy, you will need to run the file set_autonomy_cred . Run the following command replacing <USERNAME> with your cloud admin username. cd ./ set_auto_cred / build ./ set_autonomy_cred - u < USERNAME > For example, if your username is user123 , your command would look like this: cd ./ set_auto_cred / build ./ set_autonomy_cred - u user123 You will then be prompted to enter a password, which will match your cloud admin password. Enter","title":"2.3 d.ASH Autonomy Credentials"},{"location":"setup/vpn/","text":"Setting Up d.ASH VPN When setting up VPN for d.ASH, two separate login credentials are required for two seperate VPN connections - one for the robot onboard computer and one for the remote client. This section of the d.ASH SDK documentation provides details about setting up the d.ASH VPN for both your robot and your remote client. 3.1 Setting Up VPN Onboard Computer To start, you will need to install some packages to configure automatic VPN connection on Ubuntu 18.04 LTS by executing the following command: sudo apt install network - manager - openvpn network - manager - openvpn - gnome openvpn openvpn - systemd - resolved - y This will install an openvpn package, which creates a /etc/openvpn/client/ directory into which you can place the OpenVPN client configuration file. You will need to configure the VPN configuration file - client.ovpn which can be found in your vpn folder /dash_sdk/vpn . dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Note that <USER> in this instance is replaced by your dConstruct admin username. Now, you will need to copy client.ovpn and your user certifications - ca.crt , <USER>.crt , <USER>.key - into the new open vpn directory. In the /dash_sdk directory, execute the following commands: python3 .7 config_vpn . py sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt < USER >. crt < USER >. key / etc / openvpn / client For example, if your dConstruct admin username is user123 , you would replacing <USER> with user123 : sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt user123 . crt user123 . key / etc / openvpn / client To check that your files have been copied and renamed correctly, cd into the /etc/openvpn/client directory and ls to see your list of files. You should have client.conf and your user certification files, namely ca.crt <USER>.crt <USER>.key : etc/ \u2514\u2500 openvpn/ \u2514\u2500 client/ \u2514\u2500 client.conf \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Now, let's test that the VPN service was set up correctly by running the following command: sudo systemctl start openvpn - client @client . service If there is no error print, proceed onto the next step. If you come across a failure, ensure that the path in client.conf matches the following format: cat \\ etc \\ openvpn \\ client \\ ca . crt cert \\ etc \\ openvpn \\ client \\ < USER >. crt key \\ etc \\ openvpn \\ client \\ < USER >. crt Now, to check your VPN status, enter the following command: sudo systemctl status openvpn - client @client . service If successful, you should be able to see the status Initialization Sequence Completed . Lastly, enable the VPN onboard your computer by executing the following command: sudo systemctl enable openvpn - client @client . service 3.2 Setting Up VPN Remote Client Remember to use a separate login credential from the robot onboard computer credentials as at any point in time, there can only be one active user session. Firstly, download OpenVPN Connect . Once OpenVPN has been launched, click on the tab - 'Import from File' tab and drag-and-drop the client.ovpn file located in \\dash-sdk\\vpn . It is important to note that the client.ovpn file has to be in the same directory as there certification files, namely ca.crt <USER>.crt <USER>.key : dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key","title":"3.0 Setting up d.ASH VPN"},{"location":"setup/vpn/#setting-up-dash-vpn","text":"When setting up VPN for d.ASH, two separate login credentials are required for two seperate VPN connections - one for the robot onboard computer and one for the remote client. This section of the d.ASH SDK documentation provides details about setting up the d.ASH VPN for both your robot and your remote client.","title":"Setting Up d.ASH VPN"},{"location":"setup/vpn/#31-setting-up-vpn-onboard-computer","text":"To start, you will need to install some packages to configure automatic VPN connection on Ubuntu 18.04 LTS by executing the following command: sudo apt install network - manager - openvpn network - manager - openvpn - gnome openvpn openvpn - systemd - resolved - y This will install an openvpn package, which creates a /etc/openvpn/client/ directory into which you can place the OpenVPN client configuration file. You will need to configure the VPN configuration file - client.ovpn which can be found in your vpn folder /dash_sdk/vpn . dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Note that <USER> in this instance is replaced by your dConstruct admin username. Now, you will need to copy client.ovpn and your user certifications - ca.crt , <USER>.crt , <USER>.key - into the new open vpn directory. In the /dash_sdk directory, execute the following commands: python3 .7 config_vpn . py sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt < USER >. crt < USER >. key / etc / openvpn / client For example, if your dConstruct admin username is user123 , you would replacing <USER> with user123 : sudo cp client . ovpn / etc / openvpn / client / client . conf sudo cp ca . crt user123 . crt user123 . key / etc / openvpn / client To check that your files have been copied and renamed correctly, cd into the /etc/openvpn/client directory and ls to see your list of files. You should have client.conf and your user certification files, namely ca.crt <USER>.crt <USER>.key : etc/ \u2514\u2500 openvpn/ \u2514\u2500 client/ \u2514\u2500 client.conf \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key Now, let's test that the VPN service was set up correctly by running the following command: sudo systemctl start openvpn - client @client . service If there is no error print, proceed onto the next step. If you come across a failure, ensure that the path in client.conf matches the following format: cat \\ etc \\ openvpn \\ client \\ ca . crt cert \\ etc \\ openvpn \\ client \\ < USER >. crt key \\ etc \\ openvpn \\ client \\ < USER >. crt Now, to check your VPN status, enter the following command: sudo systemctl status openvpn - client @client . service If successful, you should be able to see the status Initialization Sequence Completed . Lastly, enable the VPN onboard your computer by executing the following command: sudo systemctl enable openvpn - client @client . service","title":"3.1 Setting Up VPN Onboard Computer"},{"location":"setup/vpn/#32-setting-up-vpn-remote-client","text":"Remember to use a separate login credential from the robot onboard computer credentials as at any point in time, there can only be one active user session. Firstly, download OpenVPN Connect . Once OpenVPN has been launched, click on the tab - 'Import from File' tab and drag-and-drop the client.ovpn file located in \\dash-sdk\\vpn . It is important to note that the client.ovpn file has to be in the same directory as there certification files, namely ca.crt <USER>.crt <USER>.key : dash-sdk/ \u2514\u2500 vpn/ \u2514\u2500 client.ovpn \u2514\u2500 ca.crt \u2514\u2500 <USER>.crt \u2514\u2500 <USER>.key","title":"3.2 Setting Up VPN Remote Client"}]}