{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"dConstruct d.ASH SDK","text":"<p>The dConstruct d.ASH SDK is a cross-platform library for autonomous robot navigation. Use the d.ASH SDK to develop applications for your own Spot from Boston Dynamics or any other robot you wish. This section of the d.ASH SDK documentation provides details about the components of the SDK.</p> <p></p> Component Description d.ASH Server  The d.ASH server acts as the main server responsible for sending control commands to the robot. At the same time, the d.ASH server also broadcasts secured data to any given remote systems. d.ASH Autonomy Engine  The d.ASH Autonomy Engine is the autonomy backend code that runs on the edge of the robot. It empowers the robot with robust multi-terrain (indoor and outdoor) autonomous navigation capabilities. It handles secure communication between automony engine and the remote autonomy controller. d.ASH Autonomy Controller  The d.ASH autonomy controller is the GUI (graphical user interface) for the d.ASH autonomy engine. It enable users to monitor and have full remote control of autonomy by allowing users to plot waypoints and activate autonomy on a fleet of robots. Stream real-time data via a secure connection between robots and the controller using 4G or 5G. <p>If you decide to use your own custom GUI in place of the d.ASH autonomy controller, or you do not want to run autonomy, you will still need to implement the d.ASH server and the d.ASH autonomy engine to operate your robot. </p>"},{"location":"dash-auto/autonomy-client-v2-api-reference/","title":"SCRIPT API REFERENCE","text":"<p>d.ASH Nav supports custom scripting by the user, allowing the user to edit what functions are called at certain waypoints. The way d.ASH Nav allows for this is through it's own scripting API.</p>"},{"location":"dash-auto/autonomy-client-v2-api-reference/#missions","title":"Missions","text":"<code>clearMission()</code> <code>Clears all current missions</code> Parameters Name description N/A N/A <code>setMissionName(string missionName, bool upload)</code> <code>Creates new mission, call before any mission is run</code> Parameters Name description missionName Name of mission upload Upload status to cloud (Default: False)"},{"location":"dash-auto/autonomy-client-v2-api-reference/#waypoints","title":"Waypoints","text":"<code>endWaypoint()</code> <code>Command issued to end autonomous movement. Must be the last action called if waypoint3D is used</code> Parameters Name description N/A N/A <code>waypoint3D(int seg, float x, float y, float z)</code> <code>Makes robot move to a specific coordinate on a map</code> Parameters Name description seg Segment of path. Set as zero x X coordinate on the map y Y coordinate on the map z Z coordinate on the map (Height) <code>capture(int camID)</code> <code>Takes an image for camera specified in camID</code> Parameters Name description camID ID of camera used <code>capturePano(string fileName)</code> <code>Takes a panoramic image and saves it as fileName.jpg</code> Parameters Name description fileName Name of file <code>DockingAction(bool isDockOn)</code> <code>EXPERIMENTAL | BOSDYN SPOT ONLY | Pauses robot movement and docks robot</code> Parameters Name description isDockOn If docking is supported on the robot <code>AutoDocking(bool isDockOn)</code> <code>Pauses robot movement and docks robot</code> Parameters Name description isDockOn If docking is supported on the robot <code>pause(int dur)</code> <code>Pauses robot movement for dur seconds</code> Parameters Name description dur Time in seconds to pause the robot for <code>scanRTC(string jobName, int res, bool enableImaging, bool enableDoubleScan, bool enableVis)</code> <code>Sets robot to scan using Leica\u2122 RTC360 at a selected waypoint</code> Parameters Name description jobName Name of scan job res Resolution of scan enableImaging Whether to scan with colour (imaging) enableDoubleScan Enable Leica\u2122 Double scan enableVis Enable Leica\u2122 Visual Inertial System <code>scanBLK(string jobName, int res, int imgQly)</code> <code>Sets robot to scan using Leica\u2122 BLK360 at a selected waypoint</code> Parameters Name description jobName Name of scan job res Resolution of scan imgQly Image quality to scan at <code>scanARC(bool isStart)</code> <code>Sets robot to scan using Leica\u2122 BLK ARC at a selected waypoint</code> Parameters Name description isStart Start or stop scanning"},{"location":"dash-auto/autonomy-client-v2/","title":"2.0 d.ASH Nav","text":""},{"location":"dash-auto/autonomy-client-v2/#1-dash-nav","title":"1. d.ASH Nav","text":"<p>d.ASH Nav is the platform for autonomous control of robots. Being seamlessly integrated in the d.ASH Fleet Management workflow, you can enjoy easy planning and deployment of your robots for various use cases. d.ASH Nav allows you to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning, as well as overall monitoring of your robots.</p> <p>Because d.ASH Nav is fully integrated with d.ASH Fleet Management system, an internet connection is required. Should you require d.ASH Nav without an internet connection, please contact us for more details.</p>"},{"location":"dash-auto/autonomy-client-v2/#11-minimum-system-requirements","title":"1.1 Minimum System Requirements","text":"<ol> <li>PC with a CPU equivalent to or greater than an Intel i5 4th Gen or AMD R5 1000 series</li> <li>Nvidia GTX 960</li> <li>8GB of RAM</li> <li>Internet Connection</li> <li>Windows 10/11</li> <li>Gamepad/Joystick (e.g. Logitech F710 Gamepad)</li> </ol> <p>We recommend using a discrete Nvidia GPU greater than or equivalent to an RTX 3060. Some features may run slower on other GPUs. A joystick is recommended for manual tele-operation control.</p>"},{"location":"dash-auto/autonomy-client-v2/#12-tutorial","title":"1.2 Tutorial","text":"<p>Control Scheme</p> <p>d.ASH Nav's control scheme is as follows:</p> <ul> <li>Tilt/Camera: Hold down the Left Mouse Button and drag</li> <li>Zoom: Use the mouse scroll wheel to zoom in/zoom out</li> <li>Move Around: Use the WASD keys to pan/move around the world</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#13-quick-start","title":"1.3 Quick Start","text":"<p>The general workflow to operate and run an autonomous waypoint mission is as follows:</p> <ol> <li>Login to d.ASH Nav</li> <li>Create a new project, this allows you to save any routes created for use later on</li> <li>Load the map of your choice</li> <li>Create a new mission Route and plot the waypoints</li> <li>Connect to your desired robot in your robot fleet</li> <li>Set the robot's initial starting pose on the 3D map</li> <li>Start the robot with the route for your new mission</li> </ol>"},{"location":"dash-auto/autonomy-client-v2/#2-login-process","title":"2. Login process","text":""},{"location":"dash-auto/autonomy-client-v2/#21-fleet-manager","title":"2.1 Fleet Manager","text":"<p>First, login to Fleet Manager with your given credentials to download the latest build of d.ASH Nav. Next, login to d.ASH Nav. If you encounter any difficulties logging in, please contact us.</p>"},{"location":"dash-auto/autonomy-client-v2/#3-project-management","title":"3. Project management","text":"<p>Once you've logged in, you will be greeted by the project window. Here, you can manage all existing projects as well as create new projects. These projects are synced to the cloud, thus allowing you to manage your projects and use d.ASH Nav from anywhere in the world!</p>"},{"location":"dash-auto/autonomy-client-v2/#31-creating-a-project","title":"3.1 Creating a project","text":"<p>To create a new project, simply click on the \"New Project\" button. You will then be prompted to enter a project name. After creating your new project, you will be redirected to the Map Browser.  If a project with the same name exists, a prompt will pop up asking you to choose another name for the project.</p>"},{"location":"dash-auto/autonomy-client-v2/#32-loading-an-existing-project","title":"3.2 Loading an existing project","text":"<p>To load an existing project, select an existing project saved to the cloud using the file browser on the right hand side of the screen. Alternatively, if you are loading a project saved locally, click on the \"Browse\" button and navigate to the local location of the project. After creating your new project, you will be redirected to the Map Browser.</p>"},{"location":"dash-auto/autonomy-client-v2/#33-map-browser","title":"3.3 Map Browser","text":"<p>After creating/loading an existing a project, you will be taken to the Map Selection Screen. This screen allows you to select the map which relates to your deployment location. After selecting your map, you can begin to deploy your robots. Maps can be sorted by whether they are coloured or not.</p>"},{"location":"dash-auto/autonomy-client-v2/#4-main-menu","title":"4. Main Menu","text":"<p>This is the main hub of all things d.ASH Nav. Everything concerning deployment of your robots can be found here.</p>"},{"location":"dash-auto/autonomy-client-v2/#41-top-menu","title":"4.1 Top Menu","text":"<p>The top bar contains several crucial pieces of information, such as which part of the deployment process you are currently in and actions that you can perform in each part of deployment. In the Main Menu, options to manage your projects and browse through available maps are available. The arrows indicate the proper flow of how a deployment should be run.</p>"},{"location":"dash-auto/autonomy-client-v2/#411-project-options","title":"4.1.1 Project Options","text":"<ul> <li>New Project: Create a brand new project</li> <li>Open Project: Load an existing project</li> <li>Save: Save any changes to the current project</li> <li>Save as: Save any changes to the current project under a different file/project name</li> <li>Preferences: Edit d.ASH Nav settings</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#412-map-browser","title":"4.1.2 Map Browser","text":"<ul> <li>Map Browser: Browse through all maps saved to your account</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#42-view-port","title":"4.2 View Port","text":"<p>This is a visual representation of the map you have loaded for your project. </p> <ul> <li>View Toggles: A widget in the top left corner of the View Port which allows you to toggle the visiblity of certain objects in the View Port.</li> <li>Orientation Gizmo: A gizmo in the top right corner of the View Port shows the current orientation of the map, relative to the orientation of the floor.</li> <li>Height Sliders: Adjust the cut off points for rendering of the loaded map.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#43-side-bar","title":"4.3 Side Bar","text":"<p>The Side Bar contains all information to do with any planned routes, connected robots and View Port visualisation tweaks</p> <ul> <li>Routes: Contains all planned routes in the project with the ability to toggle the preview of the route in the View Port, view all robots assigned to this route, assign new robots to this route and delete existing routes. This also reflects the current mission's route and status.</li> <li>Robot List: Shows you all currently connected robots and their status.</li> <li>Visualisation: Allows for you to tweak the colour of elements in the rendered point cloud as well as the scale (size) of the rendered robot and waypoints. This is more useful for those who experience colour blindness. We recommend leaving these settings at their default value.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#5-plan-tab","title":"5. Plan Tab","text":"<p>This tab contains all actions to do with planning routes.</p>"},{"location":"dash-auto/autonomy-client-v2/#51-actions","title":"5.1 Actions","text":"<p>Three actions are available for you to use:</p> <ul> <li>Autodrive: Using machine learning and computer vision to analyze and understand your robot's surroundings, hands-free Level 2 Autonomy allows for the navigation of complex, unstructured environments using just cameras alone.</li> <li>Record Waypoints: Records and plots waypoints as you manually navigate the robot in real life.</li> <li>Create Route: Creates an empty route for you to edit and add waypoints later on.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#52-waypoint","title":"5.2 Waypoint","text":"<p>This menu contains all available actions for editing waypoints on a route. This is greyed out by default and will only be accessible after selecting a route to edit. Several options are available to you.</p> <ul> <li>Edit Waypoint: Enters a seperate mode containing actions to edit waypoints in a selected route</li> <li>Interpolation by distance: Adds additional waypoints between two existing waypoints which are too far apart. This allows for more actions (such as scans) to be excuted along a given path. The default interval is set at 1m.</li> <li>Set scan points: The robot will stop to perform a scan with 3rd party scanners.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#53-schedule","title":"5.3 Schedule","text":"<p>This menu allows you to set a start date and time for your robots to automatically execute pre-planned missions.</p>"},{"location":"dash-auto/autonomy-client-v2/#54-robots","title":"5.4 Robots","text":"<p>Clicking this button will show a popup containing a list of all available robots. Connect to your preferred robot from this popup menu.</p>"},{"location":"dash-auto/autonomy-client-v2/#6-ready-tab","title":"6. Ready Tab","text":"<p>This tab contains all actions necessary to deploy your robot</p>"},{"location":"dash-auto/autonomy-client-v2/#61-e-stopresume","title":"6.1 E-Stop/Resume","text":"<p>Controls for stopping and resuming a mission/robot movement can be found here.</p>"},{"location":"dash-auto/autonomy-client-v2/#62-list-of-robots","title":"6.2 List of robots","text":"<p>Shows a list of all connected robots with several different pieces of information tied to each robot. - Health Monitor: The health monitor shows the status of all sensors on the robot. - Robot Info: Contains info such as the robot's serial number, date of purchase etc - Robot Settings: Adjust the tag settings of a selected robot through colour tags.</p>"},{"location":"dash-auto/autonomy-client-v2/#63-robot-actions","title":"6.3 Robot Actions","text":"<ul> <li>Localise: Give the robot an estimate of where it currently is on the map in order for the robot to fine tune its position.</li> <li>Follow Cam: Sets the camera of the View Port to follow and track the robot as it moves throughout the map.</li> <li>Auto/Manual Control: Manually change the operating mode of the selected robot.</li> <li>Sit/Stand Robot: SPOT ONLY. Sit or stand Boston Dynamics Spot Robot.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#64-assign-route-to-robot","title":"6.4 Assign Route to Robot","text":"<ul> <li>Drop Down: Choose the route to assign.</li> <li>Tag Robot: Choose the robot to assign the route to (i.e: tagging the robot)</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#7-monitor-tab","title":"7. Monitor Tab","text":"<p>This tab contains all actions and information about the mission in progress.</p>"},{"location":"dash-auto/autonomy-client-v2/#71-e-stopresume","title":"7.1 E-Stop/Resume","text":"<p>Controls for stopping and resuming a mission/robot movement can be found here.</p>"},{"location":"dash-auto/autonomy-client-v2/#72-live-views","title":"7.2 Live views","text":"<p>Views from the cameras on the robots can be found here. To add a view, simply drag and drop a robot from the right side bar into an empty view slot and select which camera to view. There are three templates to follow.</p> <ul> <li>Map View: Shows less of the view from the robot cameras to make space for viewing the Point Cloud Map.</li> <li>Four View: This view will completely hide the Point Cloud Map and instead show four slots for different robot camera views.</li> <li>Focus: This view will completely hide the Point Cloud Map and instead show only one robot camera view.</li> </ul>"},{"location":"dash-auto/autonomy-client-v2/#73-robot-controls","title":"7.3 Robot Controls","text":"<ul> <li>Run Route: Issues the command to the selected robot to run its assigned route</li> <li>Autodrive: See above</li> <li>Auto/Manual | Sit/Stand: See above</li> </ul>"},{"location":"dash-auto/autonomy-client/","title":"d.ASH Autonomy Controller","text":"<p>As mentioned previously, the d.ASH autonomy controller is a GUI (graphical user interface) for the d.ASH SDK. It allows users to plot waypoints for autonomous navigation on maps, tracking and monitoring path planning. This section of the d.ASH SDK documentation provides details about setting up the d.ASH autonomy controller, including information on its respective components.</p> d.ASH Autonomy Controller Description  Pair d.C Pilot with d.ASH Autonomy Controller for remote autonomous operations. This app allows you to control multiple robots and author + run autonomous waypoint missions configured with different payloads."},{"location":"dash-auto/autonomy-client/#camera-controls","title":"Camera Controls","text":"<p>You can pan/zoom/fly around the 3D Map Visualization World via the following controls:</p> <ul> <li>Tilt/Camera LookAt: Hold down the Left Mouse Button and drag</li> <li>Zoom: Use the mouse scroll wheel to zoom in/zoom out</li> <li>Move Around: Use the WASD keys to pan/move around the world</li> </ul>"},{"location":"dash-auto/autonomy-client/#general-workflow","title":"General Workflow","text":"<p>The general workflow to operate and run an autonomous waypoint mission is as follows:</p> <ol> <li>Login to the Autonomy Controller</li> <li>Load the point cloud map of your deployment location generated with d.ASH Pack into the app</li> <li>Create a new mission Route and plot the waypoints</li> <li>Connect to your desired robot in your robot fleet</li> <li>Set the robot's initial starting pose on the 3D map</li> <li>Start the robot with the route for your new mission</li> </ol>"},{"location":"dash-auto/autonomy-client/#10-load-point-cloud-map","title":"1.0 Load Point Cloud Map","text":"<p>Click on the Point Cloud icon to open up the point cloud loading window. Then click on Load Point Cloud. A file dialog will pop up to allow you to load your desired point cloud from disk. Make sure the same point cloud map is also configured on the robot(s).</p>"},{"location":"dash-auto/autonomy-client/#11-robot-fleet-manager","title":"1.1 Robot Fleet Manager","text":"<p>The lower expandable panel opens up the Robot Fleet Manager. This displays the list of robots currently registered and also alive under your user account. You connect your desired robot by locating your robot in the icon list and then clicking on the connect icon. When the robot is connected, the following display appears: </p> <p>You are now able to inspect various properties of the robot ( battery status, LIDAR color etc. ) as well as start launching autonomous waypoint missions for this connected robot.</p>"},{"location":"dash-auto/autonomy-client/#12-general-settings","title":"1.2 General Settings","text":"<p>The General Settings expandable panel from the left side of the screen. In here you can configure various options to streamline robot operations.</p> <ul> <li>General: This allows the customization of route/waypoint + map display settings</li> <li>Robot Viz: Visualization settings pertaining to the robots operated in the app</li> <li>Map Viz: Visualization settings for the 3D map display. In particular, use the Floor and Ceiling sliders to adjust how much of the 3D map height-wise </li> </ul>"},{"location":"dash-auto/autonomy-client/#13-routes-waypoints","title":"1.3 Routes + Waypoints","text":"<p>This subpanel can be accessed by expanding the panel on the right side of the screen. It allows you to manage the various mission routes available for your robots. To create a new route, you do the following:</p> <ol> <li>Enter a new Route Name in the textbox provided</li> <li>Click the + button to add a new route</li> <li>Select the newly route by clicking on it</li> <li>Now go into the main 3D Map display to start plotting your waypoints for the route.</li> </ol> <p>You can Append/Splice/Modify a route via the subpanel below: </p> <p>With the desired waypoint plotting option selected, you can go ahead and plot the waypoint directly with the mouse:</p> <p></p> <p>Tap the ESC key to exit the waypoint plotting operation. If you need to delete a waypoint, you can select it via a mouse click on the 3D Map, then press the Delete key.</p>"},{"location":"dash-auto/autonomy-client/#14-settings-the-initial-robot-pose","title":"1.4 Settings the Initial Robot Pose","text":"<p>When you activate a new robot into the app, the first required step is to tell the system where the robot is and where it is facing in relation to the 3D map. This step is defined as setting the Initial Pose of the robot. You set the Initial Pose via the following steps:</p> <ol> <li> <p>Click on the Initial Pose arrow button on the lower expandable panel to start the Initial Pose operation: </p> </li> <li> <p>Go to the 3D map, hold down your mouse on the part of the map where the robot is. Drag a direction and release to set the pose of the robot </p> </li> <li> <p>If the pose was set incorrectly, you can repeat steps 1 and 2 until the LIDAR scans of the robot matches that of the 3D map. This is when you know the Initial Pose is setup correctly.</p> </li> </ol> <p>Take Note: It is very important the Initial Pose of the robot is setup correctly before starting any Waypoint Autonomy Mission! Incorrect initial poses will result in the robot unable to localize correctly leading to mission failure.</p>"},{"location":"dash-auto/autonomy-client/#15-mission-routesmanagement","title":"1.5 Mission Routes/Management","text":"<p>This expandable panel located at the top part of the screen allows you to start new waypoint missions as well as manage existing missions. To start a new mission:</p> <ol> <li>Enter a new mission name in the textbox, then press the + button to add a new mission</li> <li>Select the new mission and press the Run button to start it</li> <li>You should now see your robot move in the 3D map viewer along the mission route</li> </ol>"},{"location":"dash-auto/autonomy-client/#16-robot-camera-streaming","title":"1.6 Robot Camera Streaming","text":"<p>You can activate any available cameras on the robot via the Camera Stream button circled red above. When pressed, a new Camera Stream window pops up:</p> <p></p> <p>Select the robot which you will want to stream the camera from via the top drop down box. Then use the lower drop down box to select which of the available robot cameras to stream from.</p>"},{"location":"dash-auto/autonomy-client/#17-robot-remote-pilotingteleops","title":"1.7 Robot Remote Piloting/TeleOps","text":"<p>The app also allows basic remote manual piloting of your robots. Just like the Pilot Client, plug in a regular joystick into your system to begin manually piloting your robots. You will have to activate the robot for manual control via the manual control button located in the lower expandable panel before piloting is enabled.</p>"},{"location":"dash-pack/dash-pack-mobile-tablet/","title":"d.ASH Pack Mobile Tablet","text":"<p>d.ASH Pack Mobile Tablet is a brand new visualisation system, allowing you to see where you've mapped on the fly in just two easy steps! The point clouds are generated in full colour and at real time, giving you a preview of what the final generated map would look like. Get our app on android Here.</p>"},{"location":"dash-pack/dash-pack-mobile-tablet/#requirements","title":"Requirements","text":"<ul> <li>Android Tablet</li> <li>Android Version 13 | Tiramisu | API Level 33</li> </ul>"},{"location":"dash-pack/dash-pack-mobile-tablet/#11-quick-start","title":"1.1 Quick Start","text":"<ol> <li>Connect to your d.ASH Pack's Hotspot via the android settings</li> <li>Click start recording and start your walk</li> <li>Enjoy your preview!</li> </ol>"},{"location":"dash-pack/dash-pack/","title":"d.ASH Pack","text":"<p>|  |</p> <p>d.ASH Pack is a mobile sensor system that allows users to record 3D point cloud data for various applications, including robot autonomous navigation and Digital Twin generation. d.ASH Pack can either be worn on the back of the user (just like a backpack) or mounted on a robot. It ships together with d.ASH Xplorer application, which is used to generate a 3D point cloud. The entire workflow is fully integrated with d.ASH Fleet Management system.</p> <p>|  |</p> <p>You can view a short video overview of how d.ASH Pack integrates into your Autonomous Robot Deployment workflow here</p>"},{"location":"dash-pack/dash-pack/#requirements","title":"Requirements","text":"<ul> <li>A Windows PC with d.ASH Xplorer</li> <li>d.ASH Pack device</li> </ul> <p>*Users can plug in a 4G USB dongle into the side USB port of d.ASH Pack to remotely control it</p>"},{"location":"dash-pack/dash-pack/#11-quick-start","title":"1.1 Quick Start","text":"<p>A 3D point cloud is created in two steps: Data Collection and Data Processing.</p> <p>Data collection requires the d.ASH Pack device. There are 3 different ways to activate the data collection process, as listed below. If you do not have access to an internet connection, please make sure to use Option 1 which allows you to activate the data collection via your phone.</p> <p>Data processing requires the d.ASH Xplorer application and an internet connection. The d.ASH Xplorer software is used to process the recorded data, create and edit 3D point clouds, and upload data to the Fleet Management cloud.</p> <p>Please ensure that others do not stand near the LiDAR while recording as this could cause undesirable results. Also take note that the d.ASH Pack should not undergo large (1 story tall), sudden changes in elevation while recording.</p> <p>Recording cannot be paused for later continuation. If you would like to pause momentarily, please restart the recording. Ensure some overlap in area between the two separate recordings. Do note that the results may not be as accurate as one full walkthrough.</p> <p>Loop Closure is the act of walking and intersecting paths which you had walked before, an example of this would be walking in the shape of a figure 8, where you meet in the middle and the paths walked intersect one another. Loop Closure is important as it allows for more accuracy during point cloud generation. While recording, try to ensure that there is as much Loop Closure as possible.</p>"},{"location":"dash-pack/dash-pack/#12-connecting-to-dash-pack","title":"1.2 Connecting to d.ASH Pack","text":"<p>The d.ASH Pack Wi-Fi network SSID and Password will be provided to you on the access panel of the d.ASH Pack itself.</p> <p>Use this to connect to your d.ASH Pack and access the user interface by keying this IP Address (https://192.168.10.1/) into a web browser from any device of your choice. Users can check the status of their d.ASH Pack and start/stop recordings here.</p> <p>Mobile interface: |  |</p> <p>Status LEDs The status LEDs are able to show different colours with each colour representing a different status. These LEDs are located on the side of the d.ASH Pack itself. Green LEDs means that the d.ASH Pack has been booted up fully and is ready for recording. Red LEDs means that something has gone wrong with d.ASH Pack. Use the status reflected in your d.ASH Pack's website to help trouble shoot the error. Slow, Flashing Yellow LEDs mean that the d.ASH Pack is currently recording.</p>"},{"location":"dash-pack/dash-pack/#13-data-collection","title":"1.3 Data Collection","text":"<p>Option 1 - Connect d.ASH Pack via Wi-Fi Network (No internet connection required)</p> <ol> <li>Power up d.ASH Pack</li> <li>Connect to d.ASH Pack's Wi-Fi network from your phone or other electronic devices.</li> <li>Open your web browser and key in \"https://192.168.10.1/\".</li> <li>Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans.</li> <li>Put on the d.ASH Pack and stand stationary for a short moment (e.g. 1s). Then, press start recording.</li> <li>Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas.</li> <li>Once you are done, press stop recording.</li> </ol> <p>Option 2 - Use d.ASH Xplorer</p> <ol> <li>Power up d.ASH Pack</li> <li>Load your d.ASH Xplorer application on your PC</li> <li>Login with your d.ASH credentials.</li> <li>Click on the \"d.ASH Pack Manager\" tab at the top.</li> <li>Select your d.ASH Pack.</li> <li>Click on \"d.ASH Pack Recording Control\"</li> <li>Name your d.ASH Pack recording file and select if you would like imaging (colour) in your scans.</li> <li>Press start</li> <li>Walk around to cover the area that you would like to record. For better quality, please make sure to walk in loops back to previously visited areas.</li> <li>Once you are done, press stop recording.</li> </ol>"},{"location":"dash-pack/dash-pack/#14-data-processing","title":"1.4 Data Processing","text":"<p>For a more in-depth guide, please head to the d.ASH Xplorer documentation page.</p> <ol> <li>Load up the d.ASH Xplorer Application</li> <li>Login and click \"d.ASH Pack Manager\" tab at the top.</li> <li>Your d.ASH Pack device should appear in the list. Select it by clicking on it.</li> <li>Select the recording files that you wish to download.</li> <li>If you connect an Ethernet cable between d.ASH Pack and your PC, you will have options to download the recordings via either an Ethernet cable or wirelessly. For fast download speeds, using an Ethernet cable is recommended.</li> <li>Change 3D point cloud generation configurations to suite the environment of the recording. For generation configuration explanations/tips, please refer to Generation Configs section in Xplorer guide.</li> <li>Select the preferred recording file and click \"Generate Point Cloud\" to start the point cloud generation.</li> <li> <p>While it is running, you will have the following options:     <ul> <li>Pause: Pause the generation process (Appears if generation is running)</li> <li>Resume: Resume the generation process (Appears if generation is paused)</li> <li>Cancel: Cancel the generation process</li> <li>Checkpoint: Export the current 3D point cloud to Point Cloud Editor. This is used to back up the generation progress. If problems arise in the future, some good results can still be restored.</li> </ul></p> </li> <li> <p>Once completed, click \"Point Cloud Editor\" to edit the generated 3D point cloud. The name of the new point cloud is the same as the recording file's name.</p> </li> <li>Follow the d.ASH Xplorer guide to edit the point cloud accordingly.</li> <li>Once you are satisfied with the 3D point cloud, click \"Upload\" to upload the point cloud to your d.ASH Fleet Management account in the cloud.</li> </ol>"},{"location":"dash-pack/dash-pack/#tips-for-data-collection","title":"Tips for Data Collection","text":"<ol> <li>It is recommended to walk in small loops back to previously visited areas for point cloud autocorrection. You will notice some automatic corrections being done during the generation process on d.ASH Xplorer. These corrections are called loop-closures. Walking in the shape of the figure eight is recommended.</li> </ol> <p>Good example of a well defined loop:</p> <p>Bad example where there is no loop:</p> <ol> <li>Where the loops/paths criss-cross should have recognisable static/stationary features (e.g. buildings)</li> </ol> <p>Good examples of easily recognisable features:</p> <p>|  |</p> <p>|  |</p> <p>|  |</p> <p>Bad examples of features (AKA: Dynamic features):</p> <p>|  | </p> <p>|  |</p> <ol> <li>Tighten the d.ASH Pack straps before recording</li> <li>Move at a steady pace</li> <li>Ensure LiDAR is above your head and do not block the sensor when recording (Stand about 5 metres away from person recording)</li> <li>Do not turn quickly in narrow corridors</li> <li>Do not record while in a lift</li> <li>Not recommended to record in narrow stairwells</li> <li>Put on the d.ASH Pack before starting the scan</li> <li>For recording with imaging, please tilt the LiDAR by 30\u00b0. Otherwise a horizontal configuration is recommended</li> <li>If on a vehicle, please dismount and walk through bumpy areas</li> <li>Attempting to loop close long corridors (&gt;20m) is discouraged</li> <li>Avoid large empty areas (e.g. fields) when recording as there are a lack of features</li> </ol>"},{"location":"dash-pack/dash-xplorer/","title":"d.ASH Xplorer","text":"<p>|  |</p> <p>d.ASH Xplorer is the 3D point cloud management application, allowing users to create, edit and export 3D point clouds for the purposes of (but not limited to) Autonomous Navigation and Digital Twin Applications. d.ASH Xplorer is designed to work with d.ASH Pack and equipped with state-of-the-art Simultaneous Localisation And Mapping (SLAM) technology for 3D point cloud generation. Users can view, edit and export the 3D point cloud through the use of d.ASH Xplorer. 2D maps can be generated from the 3D point clouds using the built-in grid map generator. The entire point cloud generation workflow is fully integrated with d.ASH Fleet Management to shorten and streamline the preparation process for autonomous navigation significantly.</p> <p>Two versions of d.ASH Xplorer are available, the standard d.ASH Xplorer and d.ASH Xplorer Pro.</p> <p>d.ASH Xplorer Pro is a premium edition of the standard d.ASH Xplorer offering an additional suite of features not found in the standard edition such as Scan Manager and Auto Merge which respectively provides scanning support and automatic stitching of dense 3D point clouds, and sensor fusion resulting in automatic scan alignment and scale-accurate stitching, currently supporting the Leica BLK360.</p> <p>Because d.ASH Xplorer is fully integrated with d.ASH Fleet Management system, an internet connection is required. Should you require d.ASH Xplorer without an internet connection, please contact us for more details.</p>"},{"location":"dash-pack/dash-xplorer/#21-minimum-system-requirements","title":"2.1 Minimum System Requirements","text":"<ol> <li>PC with a CPU equivalent to or greater than an Intel i5 4th Gen or AMD R5 2000 series</li> <li>Nvidia GTX 960</li> <li>16GB of RAM</li> <li>Internet Connection</li> <li>Windows 10/11</li> </ol> <p>We recommend using a discrete Nvidia GPU greater than or equivalent to an RTX 3060. Some features such as \"HD View\" are disabled on other GPUs.</p> <p>d.ASH Xplorer is built for Windows 10/11. Therefore, please ensure that you are running a discrete Nvidia GPU in High-Performance mode. Otherwise, some functionalities may be unsupported. You can enable this by going into Windows GPU Settings, and adding d.ASH Xplorer as an app and setting the \"Graphics preference\" to \"High performance\".</p>"},{"location":"dash-pack/dash-xplorer/#22-tutorial","title":"2.2 Tutorial","text":"<p>|  |</p> <p>You can watch the video tutorial to get a quick overview of how to run d.ASH Xplorer above here.</p> <p>Control Scheme</p> <p>d.ASH Xplorer's control scheme is as follows:</p> <ul> <li>WASD: Navigate around the point cloud</li> <li>LMB/MB1: Drag mouse to pan around the point cloud</li> <li>RMB/MB2: Drag mouse to zoom in and out</li> <li>MMB/MB3: Drag mouse to navigate around the point cloud</li> <li>Space: Move upwards(positive) in the Y-axis</li> <li>L Ctrl: Move downwards(negative) in the Y-axis</li> <li>F: Returns view to origin</li> </ul> <p>Additionally, at the top of the workspace exists a toolbar with buttons that can be clicked.</p> <p></p> <p>The grey buttons are fixed buttons focusing on camera control. From left to right, are as follows:</p> <ul> <li>Set Camera to Origin</li> <li>View Along X-Axis</li> <li>View Along Y-Axis</li> <li>View Along Z-Axis</li> </ul> <p>The buttons in blue are mutable based on the current mode of d.ASH Xplorer, for the Point Cloud Editor mode, these functions are: - Show/Hide Grid - Show/Hide Point Cloud - Show/Hide Mesh - Show/Hide Photo360</p>"},{"location":"dash-pack/dash-xplorer/#23-credit-system","title":"2.3 Credit system","text":"<p>The credit system defines the costs associated with exporting new file from the d.ASH Xplorer software (more on this later).</p> <p>For every export of a point cloud (.dcloud file) to an external file, a price is imposed upon the user's account. The external file can only be exported if the user has met the credit requirements and is connected to the internet.</p> <p>NOTE: As of April 2023, there is currently no way to top-up credits as a user. Should you need to add additional credits, please contact us.</p>"},{"location":"dash-pack/dash-xplorer/#24-quick-start","title":"2.4 Quick Start","text":"<p>The following section will detail the basic steps needed to generate a point cloud for further processing. Additional features offered by d.ASH Xplorer are listed in the subsequent sections.</p> <ol> <li>Login to d.ASH Xplorer <p>NOTE: d.ASH Xplorer will automatically log the current user out after one hour of being offline.</p> </li> <li>Launch d.ASH Xplorer and click on the d.ASHPack Manager tab at the top of the window.    </li> <li>Download the .dpack recording from a d.ASHPack and click on the Generate Point Cloud button.    </li> <li>When prompted, select the desired .dpack file and click Generate Point Cloud on the bottom left.  <p>NOTE: For the purposes of this quick start guide, we will use the default values for point cloud generation.</p> </li> </ol> <p> 4. Once the map is generated, configure the Post-processing Settings by clicking on the Post-Process button in the popup that follows     5. The following window will pop up. Configure the post processing as follows and click on Post Process.</p> <p>NOTE: In the current post processing configuration, the \"Human removal\" feature is not active in order to save on processing time. To activate this feature in the future, simply click on the Activate Dynamic Removal checkbox.</p> <p> 6. Once the post processing completes, click on Export to Point Cloud Editor. Enter a desired name and click Export.      7. Click on the Point Cloud Editor tab at the top navigation bar to start editing the point cloud</p> <p>The generated recording can now be used for autonomous navigation with the d.ASH Fleet Management system.</p>"},{"location":"dash-pack/dash-xplorer/#25-dash-xplorer","title":"2.5 d.ASH Xplorer","text":"<p>d.ASH Xplorer provides 2 separate means to load, process and export point clouds, namely the Point Cloud Editor and d.ASH Pack Manager pages.</p>"},{"location":"dash-pack/dash-xplorer/#251-point-cloud-editor","title":"2.5.1 Point Cloud Editor","text":"<p>The Point Cloud Editor page encompases the main features associated with point cloud manipulation, including the editing of the cloud's rotation, translation and downsampling among other 3D cloud editing features.</p> <p></p> <p>The functions offered by the Point Cloud Editor (in a left-to-right, top-to-bottom format) are as follows:</p>"},{"location":"dash-pack/dash-xplorer/#2511-load-file","title":"2.5.1.1 Load File","text":"<p>Allows users to load .dcloud, .pcd, .las, .e57, ply or .gltf files into d.ASH Xplorer. When clicked, d.ASH Xplorer prompts the user to select a valid file from their system.</p> <p>NOTE: No other feature of Point Cloud Explorer is available for use without a valid file loaded and selected. </p>"},{"location":"dash-pack/dash-xplorer/#2512-export-files","title":"2.5.1.2 Export Files","text":"<p>Allows users to export the currently selected point clouds to the .dcloud, .pcd, .las, .e57, ply and .gltf formats. Export costs differ based on the size of each individual export but cost amount of credits remains the same for all file types.</p> <p>NOTE: To export multiple files, hold ctrl and click on desired files under the Loaded File List section in the Toolbar before clicking Export Files.</p>"},{"location":"dash-pack/dash-xplorer/#2513-upload-navigation-map","title":"2.5.1.3 Upload Navigation Map","text":"<p>Uploads the selected 3D map to the d.ASH Cloud Fleet Management System. Uploading maps to the cloud costs credits as it exports the selected map in the upload process.</p>"},{"location":"dash-pack/dash-xplorer/#2514-file-info","title":"2.5.1.4 File Info","text":"<p>Displays the selected point cloud's information.</p> <p>NOTE: File Info is the default menu that is shown when exiting most functions.</p>"},{"location":"dash-pack/dash-xplorer/#2515-hd-view","title":"2.5.1.5 HD View","text":"<p>Displays the current point cloud at a high resolution by attempting to render all points within the cloud in full colour. May cause lag when attempting to view large point clouds.</p> <p>NOTE: A discrete Nvidia GPU with CUDA capabilities is required for this feature.</p>"},{"location":"dash-pack/dash-xplorer/#2516-translation-and-rotation","title":"2.5.1.6 Translation and Rotation","text":"<p>Allows users to edit the translation and rotation data of the point cloud using the respective XYZ and quaternion values of the point cloud as an object.</p> <p>Adjustment of these values is done through one of two methods:</p> <ul> <li>A widget panel within the Toolbar</li> </ul> <p></p> <ul> <li>A gizmo found on or near the point cloud generation in the main workspace</li> </ul> <p></p>"},{"location":"dash-pack/dash-xplorer/#2517-point-cloud-aligner","title":"2.5.1.7 Point Cloud Aligner","text":"<p>Does a \"best fit\" alignment of any two selected point clouds.</p> <p>To align the point clouds, click the Point Cloud Aligner button and swap the point clouds (if necessary) and click the align icon. (Icons from left to right are: Align Point Cloud, Swap Point Cloud, Exit).</p> <p></p> <p>NOTE: Point Cloud Aligner is not available if only a single point cloud is selected. To select more than one point cloud, hold ctrl and click on the desired point clouds in the Loaded File List widget.</p>"},{"location":"dash-pack/dash-xplorer/#2518-point-cloud-downsample","title":"2.5.1.8 Point Cloud Downsample","text":"<p>Allows the user to reduce the number of points within the selected point cloud using the Downsample Grid Size option as a reference</p> <p>The options for the downsampling include:</p> <ul> <li>Downsample: Executes the down sampling</li> <li>Reset to Original: Resets the downsampled point cloud to it's state before downsampling</li> <li>Exit: Exits the downsampling tool and display the current selected point cloud's information</li> </ul>"},{"location":"dash-pack/dash-xplorer/#2519-point-cloud-cropper","title":"2.5.1.9 Point Cloud Cropper","text":"<p>Allows the user to crop an area within the currently selected point cloud. The user can specify the exact area of the selected point cloud to crop through the widget panel by either entering the numbers or clicking and dragging on the textbox.</p> <p>Visualise Cropping Bounds allows for a priview of the area to be cropped, surrounding the cropped area with a white box, Keep points outside bounds which specifies whether the point clouds outside of the specified ranges should be kept after the cropping is complete and Create a Copy creates a separate point cloud for the cropped point cloud instead of overwriting the selected cloud.</p> <p></p> <p>Lastly, the options for the cropper include:</p> <ul> <li>Auto Set Crop Ranges: Sets the range automatically based on the 3D point cloud</li> <li>Crop: Executes the cropping using the specified crop ranges</li> <li>Split: Creates two separate point clouds, an inside which is the area within the specified ranges, and an outside, which is the remainding area after the inside has been generated</li> <li>Reset Crop: Resets the currently selected crop area</li> <li>Exit: Exits the cropping tool and displays the selected point cloud's information in the toolbar</li> </ul>"},{"location":"dash-pack/dash-xplorer/#25110-point-cloud-denoiser","title":"2.5.1.10 Point Cloud Denoiser","text":"<p>The point cloud denoiser aims to remove outlier points and smoothen the selected point cloud.</p> <p></p> <p>The features of the point cloud denoiser include:</p> <ul> <li>Denoise Quality: Selector to specify the number of iterations the denoise algorithm will run, wherein the default setting is Rough. In the above image, the quality is set to Refined, respectively indicating that the denoise algorithm will run at an increased quantity, resulting in a more accurate final point cloud output.</li> <li>Denoise Aggressiveness: Used to determine how the algorithm should treat infracting points, wherein a higher setting results in the removal and shifting of more points while the opposite holding true for lower settings.</li> <li>Chunk Size (m): Specifies the volume by which the equally sized chunks of the point cloud is split for denoising. <p>NOTE: Setting the chunk size to a high value may result in instabilities and/or crashing.</p> </li> <li>Uniform Sampling: Specifies wheter inferential surfaces in the point cloud should be accentuated. This setting should be switched off should shapes in the point cloud appear distorted.</li> <li>With Smoothing: Specifies whether points within the cloud should be shifted in order to make surfaces more pronounced. Disable this option if distortions are observed within the point cloud.</li> </ul>"},{"location":"dash-pack/dash-xplorer/#25111-point-cloud-merger","title":"2.5.1.11 Point Cloud Merger","text":"<p>Attempts to merge all selected point clouds.</p> <p></p> <p>The only setting for the point cloud merger is for the name of the new point cloud created post merge. The two buttons are Merge Point Cloud which executes the merge and Exit.</p> <p>NOTE: Point Cloud Merger is not available if only a single point cloud is selected. To select more than one point cloud, hold ctrl and click on the desired point clouds in the Loaded File List widget.</p>"},{"location":"dash-pack/dash-xplorer/#25112-point-cloud-to-mesh","title":"2.5.1.12 Point Cloud to Mesh","text":"<p>Converts and exports the currently selected point cloud into a mesh, exported as either a .PLY or .GLTF format.</p> <p></p> <p>The settings found in the toolbar for this feature are as follows:</p> <ul> <li>Set Mesh Output Location: Allows the user to specify the desired output location of the mesh.</li> <li>Export Format: Determines the output file format (.PLY or .GLTF)</li> <li>Level of Detail: Specifies the density of the vertex mesh, with a higher setting resulting in more details but a larger output file size and vice versa</li> <li>Clean Up Level: Specifies the tolerance by which outlier points should be removed, wherein a higher value removes more points. <p>NOTE: When set to high values, unintentional removal of points may occur, lowering the value lower may remedy this issue</p> </li> <li>Smoothing Cycles: Determines the number of cycles used in the meshing algorithm. Setting a higher value will result in a smoother mesh but may be slower than the alternative.</li> <li>Level of Sub-Details: Determines the value of details within a local scope. Setting a high value may result in a considerable increase in size as compared to a lower value.</li> <li>Color Smoothing Quality: Determines the smoothness of colours that appear on the final mesh where a higher value results in a smoother color but may take a longer time as compared to alternative options.</li> <li>Point Simplification: Option to simplify the original file before being processed for meshing by removing outlying or redundant points</li> <li>3D Engine Compatible: Option to take viewing the final exported in a three-dimensional engine such as the Unity or Unreal game engines into consideration.</li> </ul> <p>Lastly, the buttons at the bottom of the toolbar widget are Start, which executes the conversion and export, and Exit, which reverts the toolbar widget view to the File Info.</p>"},{"location":"dash-pack/dash-xplorer/#25113-2d-map-generator","title":"2.5.1.13 2D Map Generator","text":"<p>Creates a 2-dimensional map of the point cloud through projecting the specified section of the point cloud to an image file using a top-down perspective.</p> <p></p> <p>The configuration options for the generator area are as follows:</p> <ul> <li>Max Height: The highest point that will be captured in the map generation</li> <li>Min Height: The lowest point that will be captured in the map generation</li> <li>Resolution (m./pixel): The number of meters per pixel of the 2 dimensional capture of the selected point cloud</li> <li>Show Height Bounds: Visualises the highest and lowest points that will be captured using translucent planes</li> </ul> <p></p> <p>Additionally, the three options that are present at the bottom of the toolbar widget are: Generate, which executes the two-dimensional map generation, Reset Config, which resets the configuration settings to their default values and Exit, which reverts the toolbar widget view to the File Info.</p>"},{"location":"dash-pack/dash-xplorer/#25114-point-cloud-comparison","title":"2.5.1.14 Point Cloud Comparison","text":"<p>Highlights and displays selected point clouds in contrasting colours, where red is shown to be the points removed from the first selected point cloud relative to the second selected point cloud, green is the colour of the points added to the first selected point cloud and blue is the colour of the points that remain unchanged between the two point clouds. The settings found within the Toolbar are as follows:</p> <p></p> <p>Comparison Resolution: Determines the accuracy to be considered for the comparison in meters</p> <p>Compare: Executes the comparison</p> <p>Exit: Exits the cropping tool and displays the selected point cloud's information in the toolbar</p> <p>The results of the comparison are shown below:</p> <p>Before</p> <p></p> <p>After</p> <p></p> <p>As seen from the pictures above, the point clouds are compared using red, blue and green (not shown here) colours to represent removed points, unchanged points and added points respectively.</p> <p>NOTE: Point Cloud Comparison is ONLY available for use if exactly TWO point clouds are selected.</p>"},{"location":"dash-pack/dash-xplorer/#25115-bim-manager","title":"2.5.1.15 BIM Manager","text":"<p>WORK IN PROGRESS</p>"},{"location":"dash-pack/dash-xplorer/#252-dashpack-manager","title":"2.5.2 d.ASHPack Manager","text":"<p>d.ASHPack Manager mode provides an easy and convenient way to interface with a valid d.ASHPack system, including the downloading and processing of the files found within a d.ASHPack.</p> <p>The toolbar found on the workspace has also changed, wherein the mutable buttons (blue buttons) have changed in functionality. The blue buttons now have the following functionality (from left to right):</p> <ul> <li>Show Grid</li> <li>Hide Keyframe Poses</li> <li>Hide Constraints</li> <li>Hide Photo360 Poses</li> </ul> <p>The functions offered by the d.ASHPack Manager (in a left-to-right, top-to-bottom format) are as follows:</p>"},{"location":"dash-pack/dash-xplorer/#2521-connect-to-a-dashpack","title":"2.5.2.1 Connect to a d.ASHPack","text":"<p>Attempts to connect to a visible d.ASHPack either through the devices' Ethernet port or through a connection with the d.ASHPack's hotspot.</p> <p>Upon clicking the button, a window is displayed for the user to select the d.ASHPack that they wish to connect to if there are d.ASHPacks available.</p> <p></p> <p>Upon seeing the window, clicking on the name of the desired d.ASHPack will connect d.ASH Xplorer to it. After a connection has been established, the Connect to a d.ASHPack icon will change to its disconnect counterpart. Clicking it will disconnect the currently connected d.ASHPack.</p> <p></p> <p>NOTE: If no d.ASHPack is currently connected, the About d.ASHPack, d.ASHPack Scan Control and Download d.ASHPack recording buttons will be disabled.</p>"},{"location":"dash-pack/dash-xplorer/#2522-about-dashpack","title":"2.5.2.2 About d.ASHPack","text":"<p>Displays a window to show information on the currently connected d.ASHPack.</p> <p></p>"},{"location":"dash-pack/dash-xplorer/#2523-dashpack-scan-control","title":"2.5.2.3 d.ASHPack Scan Control","text":"<p>Displays a window to allow the user to start a recording on the currently connected d.ASHPack.</p> <p></p> <p>Shows the user the current status of the connected d.ASHPack with an input field for the desired recording name below the status display. With Imaging allows the recording to capture colour data via the mounted camera beside the LiDAR module on the d.ASHPack.</p> <p>NOTE: Should the Recording Name field be left blank, the recording will be named as the current date and time in the format of <code>YYYY-MM-dd_HH-mm-ss.dpack</code> (E.g. 2023-12-31_23-59-58.dpack).</p>"},{"location":"dash-pack/dash-xplorer/#2524-download-dashpack-recording","title":"2.5.2.4 Download d.ASHPack Recording","text":"<p>Opens a window that allows the user to view, search for, download and remove any recording that is saved on the currently connected d.ASHPack's on-board storage.</p> <p></p> <p>As shown above, the window provides a search bar and refresh button to refresh or search for a desired .dpack file contained within the on-board memory of the currently connected d.ASHPack. To perform an action, first click on the desired .dpack file to select it and then on either the Download or Remove Recording buttons. Clicking Download will prompt the user to specify a download path while clicking Remove Recording will prompt for a confirmation to remove the selected recording.</p>"},{"location":"dash-pack/dash-xplorer/#2525-generate-point-cloud","title":"2.5.2.5 Generate Point Cloud","text":"<p>When clicked, the user will be prompted to select the .dpack file that they wish to use to generate a point cloud. Afterwhich, a Map Generation window will appear, providing several configuration options.</p> <p></p> <p>The main options listed in the Map Generation window are as follows:</p> <ul> <li>Start/Stop Time (%): The percentage of the d.ASHPack scan to generate a point cloud from. (E.g from 10% to 50% of a scan)</li> <li>Number of Threads: Specifies number of threads to be used for the point cloud generation operation. More threads are favoured but may cause a performance decrease in other applications.</li> <li>Loop-closure Similarity Score: Specifies the tolarance for loop closures (ie. lower values equate to stricter the program becomes when finding similar points).</li> <li>Auto Pause: The generation operation will automatically be paused when a significant change in position is detected. This option is used in cases where point cloud generation may fail to allow for the back up of the data that has already been generated.</li> </ul> <p>Advanced options are listed as follows:</p> <ul> <li>Loop-closure Search Radius (m): Value used for automatic loop closure detection, where points within the stipulated radius are considered for loop closure.</li> <li>Loop-closure Minimum Time Difference (s): States the time that must pass before potential points are considered for loop closure.</li> <li>Scan-matching Sub-map Search Radius: Controls the neighbouring distance from the current pose inwhich scan matching is done during scan to map matching.</li> <li>Minimum Keyframe Distance Difference: Determines the minimum distance between each LiDAR scan to be used for mapping.</li> <li>Minimum Keyframe Angle Difference: Determines the minimum angular displacement between each LiDAR scan to be used to mapping</li> <li>Fast Mode: Specifies whether to use singular or multiple threads for point cloud generation. Pragmatically results in faster generation but may reduce map quality, particularly in complex areas with little features such as that of buildings.</li> <li>Scan Context Loop Closure: Specifies whether to utilise an advanced loop closure algorithm. Results in more scan positions being considered for loop closure which results in a higher quality map but may use more system resources.</li> </ul>"},{"location":"dash-pack/dash-xplorer/#2526-manual-loop-closure","title":"2.5.2.6 Manual Loop Closure","text":"<p>Manual Loop Closure allows for the manual stitching and combination of points within a generated point cloud. This function serves to allow for manual override of loop closures (a pair of keyframes with similar locations) in the event that the points within a point cloud fail to be merged by the algorithm. This is done through attempting to pair every point at each selected keyframe  with each other in all possible permutations.</p> <p>The options available when performing a Manual Loop Closure operation are as follows:</p> <p></p> <p>Selected Keyframe List: (Only shown if there are Keyframes selected) Displays a list of keyframes and their relation to their neightbours if Add Neighbour Keyframes is enabled, otherwise will only display selected keyframes and their relation to each other.</p> <p>Max Similarity Score: Determines the tolarance to be used during consideration of points to be paired with each other</p> <p>Neighbour Size (Only if Add Neighbour Keyframes is enabled): The number of keyframes to the left and right of the selected keyframes to be selected</p> <p>Add Neighbour Keyframes: Specifies whether to select all keyframes that are to the left and right of the two currently selected keyframes as specified by the Neighbour Size option.</p> <p>The following will be a demonstration of a Manual Loop Closure operation:</p> <p></p> <p>For the purposes of demonstration, the center points are the closest in the preceeding image and will be used. After selecting Manual Loop Closure from the mode bar and clicking the keyframes, the selected keyframes will be highlighted.</p> <p></p> <p>Lastly, after clicking the check mark in the toolbar will execute the loop closure operation.</p>"},{"location":"dash-pack/dash-xplorer/#2527-post-processing","title":"2.5.2.7 Post Processing","text":"<p>After the generation of a point cloud, the user may choose to post process the point cloud in order to refine the result. The Post Process Point Cloud menu enables this by allowing for more granular control over the generated point cloud.</p> <p>In the following screenshot, the Activate Dynamic Removal box is not checked.</p> <p></p> <p>The options displayed are as follows:</p> <p>Post-Processing Options:</p> <p></p> <ul> <li>Nav Map: Autonomous Navigation Map meant for waypoint plotting for a compatible robot</li> <li>Colour Nav Map: A Nav Map with colours</li> <li>Sparse Coloured Map: A coloured point cloud with as few points as possible</li> <li>Dense Coloured Map: A coloured point cloud with all available points</li> </ul> <p>Denoise Quality:</p> <p></p> <ul> <li>Rich: Most aggresive denoise of the generated point cloud</li> <li>Sharp: Moderate denoising of the generated point cloud</li> <li>Raw: No denoising of the generated point cloud</li> </ul> <p>Max Point Cloud Range Per Scan (m.)</p> <p></p> <p>Determins the distance from the origin where points will be considered and added to the final, post-processed cloud. Increasing this value is recommended for point clouds of wider areas, especially scans of outdoor areas.</p> <p>Activate Dynamic Removal:</p> <p></p> <p>Dynamic removal refers to the automatic removal of objects and/or artifacts through an internal algorithm of d.ASH Xplorer. Objects considered for removal include (but may not be limited to) pedestrians, cars and animals.</p> <p>Checking the box presents the user with two new options. These are as follows:</p> <p></p> <p>Use GPU for Inference: Specifies whether the Graphics Processing Unit on the device running d.ASH Xplorer should be utilised. It is recommended to leave this option enabled for most situations.</p> <p>Point Removal Level: Specifies the extent of which points around moving objects should be removed.</p>"},{"location":"dash-pack/dash-xplorer/#26-dash-xplorer-pro","title":"2.6 d.ASH Xplorer Pro","text":"<p>d.ASH Xplorer Pro provides additional features that allow for more granular control over generated point clouds, providing the aforementioned features mentione above, along with a Scan Manager and AutoMerge feature.</p>"},{"location":"dash-pack/dash-xplorer/#261-scan-manager","title":"2.6.1 Scan Manager","text":"<p>Scan Manager allows users to manage third-party 3D scanners and integrate them with d.ASH Xplorer. As of April 2023 only the Leica BLK360 3D scanner is supported.</p> <p>Scan Manager serves the following purposes: 1. Downloading .scanMeta files from the d.ASHPack 2. Downloading scan data from a scanner 3. Performing AutoMerge on scans</p>"},{"location":"dash-pack/dash-xplorer/#2611-downloading-scanmeta-files","title":"2.6.1.1 Downloading .scanMeta files","text":"<p>UPDATE WORK IN PROGRESS, PLEASE REFER TO THE CURRENT DOCUMENTATION OF SCAN MANAGER.</p>"},{"location":"dash-pack/dash-xplorer/#2612-generate-point-cloud","title":"2.6.1.2 Generate Point Cloud","text":"<p>UPDATE WORK IN PROGRESS, PLEASE REFER TO THE CURRENT DOCUMENTATION OF SCAN MANAGER.</p>"},{"location":"dash-pack/dash-xplorer/#262-automerge","title":"2.6.2 AutoMerge","text":"<p>UPDATE WORK IN PROGRESS, PLEASE REFER TO THE CURRENT DOCUMENTATION OF SCAN MANAGER.</p>"},{"location":"dash-pack/dash-xplorer/#scan-manager-plugin","title":"Scan Manager (Plugin)","text":"<p>This plugin allows users to manage 3rd-party 3D scanners. Currently, the Leica BLK360 scanner is supported. This is currently limited to users of d.ASH Xplorer Pro.</p> <p>This plugin is used to perform the following:</p> <ol> <li>Download scanMeta files from the robot</li> <li>Download scan data from the scanner</li> <li>Perform AutoMerge on all scans.</li> </ol> <p>Download ScanMeta Files</p> <p>scanMeta file (<code>*.scanMeta</code>) holds critical information for each scan point. Each 3D scan activated by the d.ASH robotics stack will generate a scanMeta file. The scanMeta data can be used to perform AutoMerge for creating a digital twin (high accuracy/density 3D point cloud model). scanMeta files are grouped by their project names which are set by d.ASH Autonomy Mission.</p> <p>To download the scanMeta files, perform the following:</p> <ol> <li>Connect your PC running d.ASH Xplorer Pro to the Internet and make sure that the robot is online</li> <li>Log in to d.ASH Xplorer Pro, then connect to the server.</li> <li>Click on the robot from the Online Robot List in the Scan Manager tab.</li> <li>Select the desired data folder by clicking the Folder icon. This folder will be used to store downloaded scanMeta files. We recommend choosing an empty folder. Otherwise, scanMeta files from previous/other projects will be overwritten.</li> <li>Click on Download Files to expand the window.</li> </ol> <p>|  |</p> <ol> <li>Click Download to download ScanMeta files for the entire project.</li> </ol> <p>|  |</p> <ol> <li>After downloading, all ScanMeta files will be stored in the folder selected in Step 3.</li> </ol> <p>Download 3D Scan Data from the Scanner</p> <p>This step performs downloading of 3D scan data from the 3D scanner by using the downloaded ScanMeta files.</p> <ol> <li>Connect your PC running d.ASH Xplorer Pro to the 3D scanner.</li> <li>Select the desired data folder by clicking the Folder icon . This folder should have ScanMeta files.</li> <li>Click on Download Files to expand the window.</li> <li>Under \"Download scan data from scanner\", click Download</li> <li>There will be a window popup showing all ScanMeta filenames found in the folder selected in Step 2. If 3D scan files and ScanMeta files with the same name exist, the filename will have \"[Downloaded]\" appended at the back of their names.</li> <li>Use the checkboxes on the left to mark 3D scan data for downloading. Users can use Select All or Unselect All buttons for file selections.</li> </ol> <p>|  |</p> <ol> <li>Click Download to start the 3D scan downloading process.</li> <li>Once completed, Click Close to close the popup.</li> </ol> <p>AutoMerge</p> <p>This step performs AutoMerge on the 3D Scan data. AutoMerge utilizes sensor fusion techniques to automatically stitch and align multiple 3D scans for scale-consistent digital twin reconstruction. AutoMerge supports both colored and non-colored point clouds. To perform AutoMerge, perform the following steps:</p> <ol> <li>Select the desired data folder by clicking Change. This folder should have both ScanMeta files and 3D scan data files.</li> <li>Click on AutoMerge to expand the window.</li> <li>AutoMerge Scan File List displays a list of files in the selected folder for AutoMerge. Only filenames with <code>.scanMeta</code> and <code>.pcd</code> are considered for AutoMerge.</li> <li>Since AutoMerge relies on the orientation of the 3D scanner to perform stitching, users are encouraged to preview some scans first. This is done by selecting a few scans (greater than two) and clicking Preview.</li> <li>After scan previews have loaded, expand Options and change the Scanner Rotation so that the selected scans are roughly aligned. These rotations will rotate the 3D scan about their centres. As the scanner rotation is changed, the 3D scan previews will also be rotated accordingly. Users do not have to perfectly align the 3D scans manually. Just a rough estimate is sufficient.</li> <li>After configuring the scanner rotation, users can start AutoMerge. Click AutoMerge to start the AutoMerge process on the selected files (greater than one). You will see the 3D scans popping up and aligning themselves automatically after some time.</li> <li>When AutoMerge has completed, users have the following options:     <ul> <li>Export: Save the AutoMerge results and individual scans with corrected poses. Users can choose to export as <code>.pcd</code>, <code>.dcloud</code>, <code>.las</code>, or <code>.e57</code> file formats.</li> <li>Edit: Export the AutoMerge results to Map Editor for editing.</li> </ul></li> </ol> <p>Options</p> <p>There are 3 different options available for Scan Manager:</p> <ol> <li>Scanner Rotation: Rotation in degrees of the scanner relative to the robot heading. As this value is changed, the 3D scan preview will also be updated in real-time.</li> <li>Optimize Visualization: Check this to optimize rendering. Check this if you notice a laggy visualization.</li> <li>Auto save AutoMerge results: Automatically save AutoMerge results to the data folder once AutoMerge has completed.</li> </ol>"},{"location":"dc-pilot/pilot-guide/","title":"dC Pilot Client","text":"<p>The dC pilot is a GUI (graphical user interface) for the d.ASH SDK. It encompasses interactive visual components for you to control your robot both manually and autonomously. Operate your robots safely and precisely, from any location with our reliable and high-performance  BVLOS (Beyond Vision Line of Sight) System with high quality video streams and responsive controls. This section of the d.ASH SDK documentation provides details about using the d.C Pilot Client.</p>"},{"location":"dc-pilot/pilot-guide/#11-introduction","title":"1.1 Introduction","text":"<p>|  |</p> <p>The pilot client allows you to operate your robots safely and precisely, from any location via its high-performance Remote TeleOps/BVLOS (Beyond Vision Line of Sight) system. It is also equipped with high quality video streams and responsive controls for seamless naviation. The system can also be used for fleet management, to discover, monitor and control multiple robots anytime, anywhere with real time video streaming and data collection. You can view a quick introduction of dc Pilot here</p> <p>|  |</p> <p>The Vision AutoDrive is another key feature of the d.C Pilot, using machine learning and computer vision to analyze and understand your robot's surroundings. This allows hands-free Level 2 Autonomy for the navigation of complex, unstructured environments using just cameras alone.  A demonstration of what Vision AutoDrive is capable of can be viewed here</p> <p>Some requirements before starting the d.C Pilot are: </p> <ol> <li>Nvidia CUDA GPU enabled PC ( At least 2 GB of GPU Memory )</li> <li>Joystick connected to the PC</li> <li>1 GB local storage space</li> <li>16 GB of CPU Memory</li> <li>Intel i5 CPU or equivalent</li> <li>Windows 10 64-bit OS or higher</li> </ol>"},{"location":"dc-pilot/pilot-guide/#12-robot-login","title":"1.2 Robot Login","text":"<p>When you first load up the pilot client, you will be asked to login via your user account. After authentication, you will be presented with the following screen below:</p> <p>|  | </p> <p>The screen above shows you the robots switched ON and discovered via dashBoard ( the Fleet Management System ). Any robot currently registered under your user account and is alive will be displayed. Select the robot you want and click on Take Control to proceed to control the robot. If you want to restart the robot ( due to any unforseen previously encountered issues, ), click Restart to do so.</p>"},{"location":"dc-pilot/pilot-guide/#13-main-controls","title":"1.3 Main Controls","text":"<p>|  | </p>"},{"location":"dc-pilot/pilot-guide/#robot-power-onoff","title":"Robot Power ON/OFF","text":"<p>This is an optional step depending on the type of robot you are running. For most robots the robot is automatically turned ON when you physically attach a battery ( or press the actual Power ON button/switch ). For robots that need to be turned ON via software ( like the Boston Dynamics Spot ), you should turn it on by pressing the Power ON button before piloting the robot. Similary, you can Power OFF the robot if it supports such functionality.</p> Basic Manual Piloting  To start the robot from rest, apply pressure on the joystick.  To stop the robot from moving, release your hold on the joystick.  To move the robot forwards, push front on the joystick.  To move the robot backwards, pull back on the joystick.  To turn the robot to the left, tilt left on the joystick.  To turn the robot to the right, tilt right on the joystick.  To get the robot to stand or sit ( if the Robot supports it ), click the <code>stand</code> or <code>sit</code> button under the Basic Control panel on the right side of the main screen."},{"location":"dc-pilot/pilot-guide/#robot-reconnectionrestart-connectivity-issues","title":"Robot Reconnection/Restart ( Connectivity issues )","text":"<p>If you encounter situations where you lose connection to the robot ( or encounter unstable video/control streams ), you should consider Restarting/Reconnecting with the robot. There are 2 options available:</p> <p>|  |</p> <ul> <li>Reconnect: This issues a fast reconnection between the pilot client and the robot. Run this if you suspect there was issue with connectivity between the client and the robot.</li> <li>Full Restart: This will flush + restart the robot system, then reconnect the client to the robot when the robot system is ready. Run this if you need to do a full restart with the robot possibly due to issues other than connectivity.</li> </ul>"},{"location":"dc-pilot/pilot-guide/#14-control-panel","title":"1.4 Control Panel","text":"Control Panel  (1)  \u00a0 Unmute the microphone to allow dual-communication between the pilot client and the robot.  (2)  \u00a0 Toggle between audio to broadcast speakers.  (3)  \u00a0 Record videos in mp4 format.  (4)  \u00a0 Upload/download video recordings.  (5)  \u00a0 Configure settings for your preference ie. night mode.  (6)  \u00a0 Broadcast live video streaming using either a RTSP server or an HSL server."},{"location":"dc-pilot/pilot-guide/#15-basic-controls","title":"1.5 Basic Controls","text":"Component Description  (1) \u00a0 Monitor the joystick position with respect to your robot. Control the robot by pushing further on the joystick.  (2) \u00a0 Adjust the cruise control speed using the slider control or if your joystick has a secondary lever, push the lever to activate.  (3)  \u00a0 Activate auto-drive for your robot to switch to Smart AI Assisted Cruise Autonomy.  -  \u00a0 Use the <code>spacebar</code> shortcut key to activate auto-drive.   -  \u00a0 Use the <code>z</code> shortcut key for your robot to take the next few possible left turns.   -  \u00a0 Use the <code>x</code> shortcut key for your robot to return to forward position after turning left or right.   -  \u00a0 Use the <code>c</code> shortcut key for your robot to take the next few possible right turns."},{"location":"dc-pilot/pilot-guide/#16-cameras","title":"1.6 Cameras","text":"Component Description  (1) \u00a0 Select from a list of cameras onboard Spot, which are automatically detected by the pilot client.   (2) \u00a0 Adjust the order of cameras for a wider view scope. Ticking the flipped settings will adjust the camera orientation.  (3) \u00a0 Click on sync to sync up the default camera layout/settings from the robot. You can also manually change the camera order via the Cameras drop-down combo box.  (4)  \u00a0 Activate human tracking for people detection and labelling."},{"location":"dc-pilot/pilot-guide/#17-autodrive","title":"1.7 AutoDrive","text":"<p>|  | </p> <p>AutoDrive is our state of the art ML/Computer Vision Level 2 Autonomy system for robots. It requires a calibrated 3 camera setup in order to properly function. Please make sure you have the proper setup before continuing. You can watch an overview video of what AutoDrive is capable of here</p> <p>|  | </p> <p>The following options/controls are available:</p> <ul> <li>Run Motors: This starts/stops the AutoDrive system</li> <li>Avoid Grass: Checking this ON/OFF will tell the system whether to make the robot avoid/ignore a grassy area during Autonomy</li> <li>Log Data: This will record any required data for sending during operation</li> </ul>"},{"location":"dc-pilot/pilot-guide/#17-leica-blk360-laser-scanner","title":"1.7 Leica BLK360 Laser Scanner","text":"<p>|  | </p> <p>This panel enables you to run scanning with the Leica BLK360 Laser Scanner. Please make sure the scanner is properly mounted/connected before proceeding. Run the following steps to start scanning:</p> <ol> <li>Type in your Job Name in the textbox. This name will be used for the entire set of scans.</li> <li>Select your Scan quality via the Quality combo box.</li> <li>Select whether you want Color ( None, HDR, LDR ) via the Color combo box.</li> <li>Click Start to start the scanning operation.</li> </ol>"},{"location":"dc-pilot/pilot-guide/#18-leica-rtc360-laser-scanner","title":"1.8 Leica RTC360 Laser Scanner","text":"<p>|  | </p> <p>This panel enables you to run scanning with the Leica RTC360 Laser Scanner. Please make sure the scanner is properly mounted/connected before proceeding.  Run the following steps to start scanning:</p> <ol> <li>Type in your Job Name in the textbox. This name will be used for the entire set of scans.</li> <li>Select your Scan quality via the Quality combo box.</li> <li>Check the options Imaging, Double Scan, VIS for your RTC 360. Please consult your scanner user manual for more information on what those options do.</li> <li>Click Start to start the scanning operation.</li> </ol>"},{"location":"dc-pilot/pilot-guide/#19-boston-dynamics-spot-arm","title":"1.9 Boston Dynamics Spot Arm","text":"<p>|  | </p> <p>This panel enables you to operate the Boston Dynamics Spot Arm if your Spot robot has been configured with one. Please take note that your cameras should be set to Spot's Default Black and White Cameras in order for this to function. </p> <ol> <li>Click Operate to start the Arm operation</li> <li>This will pop up a separate window that shows the black and white cameras on Spot.</li> <li>Click on the desired target area to run the arm manipulation operation.</li> <li>Click Run to start the arm operation.</li> </ol>"},{"location":"dc-pilot/pilot-guide/#110-rtsp-streaming","title":"1.10 RTSP Streaming","text":"<p>This button allows you to start a RTSP stream which can be used to broadcast camera footage from the robot to clients. FFMPEG is required for this feature. However, FFMPEG is not packaged with Dash Pilot. If you would like to use RTSP streaming, please download FFMPEG here and move ffmpeg.exe to the Dash Pilot Application's data folder. This is typically located in C:\\Program Files (x86)\\Dash Pilot.</p> <p>|  | </p> <p>There are several settings for customising the RTSP stream. |  |</p> Setting Default Value  RTSP Channel Please enter only alphabetical letters  RTSP Server NIL  RTSP Cam Index NIL"},{"location":"dc-pilot/pilot-sdk/","title":"dC Pilot SDK","text":"<p>The dC Pilot SDK allows you to develop your own custom robot Teleoperations apps easily. You will need:</p> <ul> <li>C++14 compatible compiler ( VS2022 recommended )</li> <li>For AutoDrive: CUDA enabled GPU</li> <li>Windows 10</li> </ul>"},{"location":"dc-pilot/pilot-sdk/#21-discovering-your-robots","title":"2.1 Discovering your robots","text":"<p>The first step you need to perform is to run the discovery service to find the robot you want registered in your fleet.</p> <p>Here are the required includes: <pre><code>#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cxxopts.hpp&gt;\n#include &lt;robotDiscovery.h&gt;\n#include &lt;robotPilot.h&gt;\n#include &lt;robotNode.h&gt;\n#include &lt;unordered_map&gt;\n#include &lt;functional&gt;\n#include &lt;algorithm&gt;\n#include &lt;chrono&gt;\n#include &lt;thread&gt;\n</code></pre></p> <p>Next, start the robot discovery service: <pre><code>// Create the robot discovery service\nauto rDiscovery = DashMicroSv::getRobotDiscovery();\n// Login with your credetials\nif (!rDiscovery-&gt;loginCloud(userName, pwd)) {\nstd::cout &lt;&lt; \"ERROR! Invalid Login Credentials.\" &lt;&lt; std::endl;\nreturn;\n}\n// Start the discovery\nrDiscovery-&gt;startDiscovery();\n</code></pre></p> <p>You can now write a simple function like the one below to find the robot you want: <pre><code>std::shared_ptr&lt;DashMicroSv::RobotNode&gt; findRobotWithName(\nDashMicroSv::RobotDiscovery&amp; rDiscoveryIn, const std::string&amp; robotName, bool printList) {\nstd::shared_ptr&lt;DashMicroSv::RobotNode&gt; retBot = nullptr;\nauto aliveBots = rDiscoveryIn.getAliveRobots();\nif (printList) {\nprintRobotList(aliveBots);\n}\n\nfor (const auto&amp; aBot : aliveBots) {\nif (aBot-&gt;getName() == robotName) {\nretBot = aBot;\nbreak;\n}\n}\nreturn retBot;\n}\n</code></pre></p> <p>So go ahead and retrieve your robot: <pre><code>auto myRobotNode = findRobotWithName(*rDiscovery, \"myRobot\", true);\n</code></pre></p> <p>With your robot found, it is now time to construct the Pilot and control it via teleoperation commands.</p>"},{"location":"dc-pilot/pilot-sdk/#22-teleoperations","title":"2.2 Teleoperations","text":"<p>Use the robot you found in the previous section to construct your Pilot:</p> <pre><code>auto myPilot = std::make_shared(*rDiscovery, *myRobotNode);\n\n// Now connect to the robot\nif(!myPilot-&gt;connect()) {\nstd::cout &lt;&lt; \"ERROR! Unable to connect to robot!\" &lt;&lt; std::endl;\nreturn;\n}\n</code></pre>"},{"location":"dc-pilot/pilot-sdk/#game-loop-ticking-moving-robot-retrieving-images","title":"Game Loop Ticking, Moving Robot, Retrieving images","text":"<p>The recommended implementation to operate the robot is via a simple Game Loop. From there you can tick and send velocity commands as well as retrieve images from your robot. Some pseudo code of how it will look like is presented below:</p> <pre><code>    std::vector&lt;cv::Mat&gt; camImgs;\nwhile(true) {\n\n// Retrieve camera images\nmyPilot-&gt;tick(camImgs);\nProcessCamImgs(camImgs);\n\n// Move robot\nfloat x = 0, y = 0, rot = 0;\nRetrieveJoystick(x, y, rot);\nmyPilot-&gt;setFreeMoveVel(x, y, rot);\n\n// In MS\nPause(1.0);\n}\n</code></pre> <p>This concludes the simple tutorial/writeup on how to use the Pilot SDK to teleoperate your own robots.</p>"},{"location":"getting-started/config-connect/","title":"Configuring Sensors","text":""},{"location":"getting-started/config-connect/#21-velodyne-driver","title":"2.1 Velodyne Driver","text":""},{"location":"getting-started/config-connect/#211-setting-up-on-sensor","title":"2.1.1 Setting Up on Sensor","text":"<p>By default, the Velodyne LIDAR sensor IP address is factory set on default value <code>192.168.1.201</code>. The d.ASH SDK will assume the default Velodyne IP address.</p>"},{"location":"getting-started/config-connect/#212-setting-up-on-personal-computer","title":"2.1.2 Setting Up on Personal Computer","text":"<p>You'll need to configure a static IP address for your computer to use an address within the range <code>192.168.1.XXX</code> where <code>XXX</code> may be any integer from 2 to 254, except 201 (which is the LIDAR\u2019s IP). For example, an appropriate static IP address for your compute could be <code>192.168.1.100</code>. </p>"},{"location":"getting-started/config-connect/#213-testing-velodyne-sensors","title":"2.1.3 Testing Velodyne Sensors","text":"<p>Now, let's test your lidar sensors. To test the Velodyne VLP-16 lidar sensor, run the following command: <pre><code>cd dash_sdk/launch\nroslaunch autonomy_velodyne.launch\n</code></pre> Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: <pre><code>rostopic echo /velodyne_points\n</code></pre></p>"},{"location":"getting-started/config-connect/#22-ouster-driver","title":"2.2 Ouster Driver","text":""},{"location":"getting-started/config-connect/#221-setting-up-on-sensor","title":"2.2.1 Setting Up on Sensor","text":"<p>By default, the Ouster LIDAR sensor IP address is factory set on your IPv6/IPv4 link-local address. The addresses lie within the block <code>169.254.0.0</code> to <code>169.254.255.255</code>. To change the static IP address for Ouster, refer to the Ouster Documentation. It is recommended to set up your own static IP address. </p>"},{"location":"getting-started/config-connect/#222-setting-up-on-personal-computer","title":"2.2.2 Setting Up on Personal Computer","text":"<p>You'll need to configure a static IP address for your computer to use an address within the range <code>192.0.2.XXX</code> where <code>XXX</code> may be any integer from 2 to 254. For example, an appropriate static IP address for your compute could be <code>192.0.2.123</code>. </p>"},{"location":"getting-started/config-connect/#213-testing-ouster-sensors","title":"2.1.3 Testing Ouster Sensors","text":"<p>To test the Ouster OS1-32 lidar sensor, run the following command: <pre><code>cd dash_sdk/launch\nroslaunch autonomy_ouster.launch\n</code></pre> Finally, to check if the ROS messages are published correctly, in another terminal, run the following command: <pre><code>rostopic echo /velodyne_points\n</code></pre></p>"},{"location":"getting-started/config-spot/","title":"1.0 Configuring Spot","text":""},{"location":"getting-started/config-spot/#configuring-spot","title":"Configuring Spot","text":"<p>This section of the d.ASH SDK documentation provides details about setting up Spot with the d.ASH SDK. To configure Spot, you will need to set up on the robot itself and on your personal computer. For further enquiries of setting up Spot, follow Boston Dynamics Documentation.</p>"},{"location":"getting-started/config-spot/#11-setting-up-on-spot","title":"1.1 Setting Up On Spot","text":"<p>By default, user and admin credentials are printed on the label of the robot's battery compartment. Otherwise, you can create your own account through the admin console by creating a user with admin privileges. Check out Boston Dynamics Documentation for more information on how to do so.</p> <p>Remember your credentials!</p> <p>Remember your Spot credentials as you will need those same credentials to set up the next section on your personal computer.</p>"},{"location":"getting-started/config-spot/#12-setting-up-on-pc","title":"1.2 Setting Up On PC","text":"<p>By default, the Spot robot IP address is <code>10.0.0.3</code>. If you have more than one Spot robot, refer to the Boston Dynamics Documentation to use the admin console to change the default IP of additional robots to avoid address conflicts.</p> <p>You'll need to configure a static IP address for your computer to use an address within the range <code>10.0.0.X</code> where <code>X</code> may be any integer from 2 to 254, except 3 (which is the Spot's IP). For example, an appropriate static IP address for your compute could be <code>10.0.0.100</code>. You will then be asked to enter a valid admin or operator username and password. These credentials will match the credentials on Spot's battery compartment.</p>"},{"location":"getting-started/dash-eng/","title":"Interfacing d.ASH Autonomy Engine with ROS","text":"<p>This section of the d.ASH SDK documentation provides details about using ROS with the d.ASH autonomy engine. Described below are ROS topics, along with their type and functionality.</p>"},{"location":"getting-started/dash-eng/#41-publications","title":"4.1 Publications","text":"Topic Type Function <code>/active_path</code> <code>nav_mgs/Path</code> Returns current path being executed. <code>/image</code> <code>sensor_msgs/Image</code> Returns sensor image. <code>/initial_pose</code> <code>geometry_msgs/PoseWithCovarianceStamped</code> Returns initial pose estimate for localization. <code>/localization_status</code> <code>std_msgs/String</code> Returns status of localization certainty. <code>/mcl_pose_marker</code> <code>visualization_msgs/Marker</code> Returns current localization position. <code>/nearest_wpts</code> <code>visualization_msgs/Marker</code> Returns nearest waypoints for the robot to follow. <code>/odom</code> <code>nav_msgs/Odometry</code> Returns odometry reading. <code>/original_path</code> <code>nav_msgs/Path</code> Returns original path before processing. <code>/particle_array</code> <code>geometry_msgs/PoseArray</code> Returns localization particle certainty. <code>/tracking_wpt</code> <code>std_msgs/Float32MultiArray</code> Returns nearest waypoints for the robot to follow."},{"location":"getting-started/dash-eng/#42-subscriptions","title":"4.2 Subscriptions","text":"Topic Type Function <code>/cmd_vel</code> <code>geometry_msgs/Twist</code> Accepts manual command velocity. <code>/imu</code> <code>sensor_msgs/Imu</code> Accepts imu sensor data. <code>/initial_pose</code> <code>geometry_msgs/PoseWithCovarianceStamped</code> Accepts initial pose estimate for localization. <code>/joy</code> <code>sensor_msgs/Joy</code> Accepts joystick message. <code>/move_base_simple/goal</code> <code>geometry_msgs/PoseStamped</code> Accepts final goal from RVIZ. <code>/odom</code> <code>nav_msgs/Odometry</code> Accepts odometry reading. <code>/lidar_points</code> <code>sensor_msgs/PointCloud2</code> Accepts lidar scan."},{"location":"getting-started/map-loading/","title":"Map Loading","text":"<p>This section of the d.ASH SDK documentation provides details about file organisation of autonomy maps for the d.ASH SDK. </p> <p>To load a new map, upload the autonomy map files in the folder <code>maps</code> found in <code>/dash_sdk/.data/maps</code>. Please ensure that the following files are in the folder:</p> <pre><code>dash-sdk/\n\u2514\u2500 .data/\n    \u2514\u2500 maps\n        \u2514\u2500 &lt;MAP_NAME&gt;.png       # 2D Autonomy Map\n        \u2514\u2500 &lt;MAP_NAME&gt;.pcd       # 3D Autonomy Map\n        \u2514\u2500 &lt;MAP_NAME&gt;.json      # Global Planner Configuration\n</code></pre> <p>To activate the new map, ensure the map name in <code>auto_config.json</code> file matches <code>&lt;MAP_NAME&gt;</code>. For example: </p> <pre><code>\"map_name\": \"outdoor_map\",\n</code></pre>"},{"location":"home/products/","title":"Our Products","text":"Download d.ASH Pack Brochure Download d.ASH-ER Brochure Download d.ASH Xplorer Brochure"},{"location":"home/workflow/","title":"Download Workflow Manual 1.0 Here","text":""},{"location":"sdk-config/auto-config/","title":"Auto Configuration","text":"<p>This section of the d.ASH SDK documentation provides details about the configuration file for the robot - <code>auto_config.json</code> - found in the folder <code>\\dash-sdk\\configs</code>. Information in this section includes variable and definitions to configure autonomy.</p>"},{"location":"sdk-config/auto-config/#41-config-file","title":"4.1 Config File","text":"<pre><code>{ \n    \"py_address\"                            : \"0.0.0.0:50051\",\n    \"ue_address\"                            : \"0.0.0.0:50052\",\n    \"ssl\"                                   : true,\n    \"motion_planner\"                        : true,\n    \"localization\"                          : true,\n    \"sim_mode\"                                : false,\n    \"send_data_gui\"                         : true,\n    \"camera\"                                : \"RealsenseCam\",\n    \"retrieveImg\"                           : false,\n    \"map_name\"                              : \"office_lvl4\",\n    \"pc_topic\"                              : \"velodyne_points\",\n    \"odom_topic\"                            : \"odom\",\n\n    \"controller\":{\n        \"linear_window\"                     : 0.5,\n        \"linear_min_v\"                      : 0.0,\n        \"linear_max_v\"                      : 0.8,\n        \"angular_max_w\"                     : 3.142,\n        \"linear_max_a\"                      : 1.0,\n        \"angular_max_a\"                     : 5.0,\n        \"robot_width\"                       : 0.4,\n        \"robot_length\"                      : 1.0,\n        \"obstacle_cost_gains\"               : 3.0,\n        \"speed_cost_gains\"                  : 1.0,\n        \"goal_cost_gains\"                   : 4.0,\n        \"angular_speed_cost_scaling_factor\" : 0.1,\n        \"linear_num_window_steps\"           : 50,\n        \"angular_num_window_steps\"          : 30,\n        \"prediction_window\"                 : 5.0,\n        \"costmap_size\"                      : 20.0,\n        \"costmap_scale\"                     : 0.1,\n        \"max_pc_height\"                     : 0.2,\n        \"min_pc_height\"                     : -0.5,\n        \"x_filter\"                          :[-0.2, 0.2],\n        \"y_filter\"                          :[-0.1, 0.1],\n        \"costmap_obs_inflation\"             : 1.0,\n        \"occ_obs_deadzone\"                  : 0.2,\n        \"dt\"                                : 0.1,\n        \"visualise\"                         : false\n    },\n    \"state_estimator\":{\n        \"initial_x\"                         : -7.7, \n        \"initial_y\"                         : -14.5, \n        \"initial_z\"                         : 1.0, \n        \"initial_w\"                         : -0.177,     \n        \"kImuTopic\"                         : \"imu\", \n        \"kPoseTopic\"                        : \"mcl_pose\",\n        \"ktfUpdate\"                         : 0.02,\n        \"kStatusUpdate\"                     : 1.0,\n        \"kLoggingUpdate\"                    : 15.0,\n        \"kposeDiffmax\"                      : 5.0, \n        \"KUse_imu_ori\"                      : false,\n        \"kBadCovThres\"                      : 2.0,\n        \"kGoodCovThres\"                     : 0.7,\n        \"kCovBadMax\"                        : 10, \n        \"kCovGoodtMax\"                      : 5,\n        \"kFilter_z\"                         : true,\n        \"klimit_min\"                        : -0.3,\n        \"klimit_max\"                        : 5.0 \n    },\n    \"planner\":{\n        \"lookAheadIndex\"                    : 15,\n        \"enable_self_rotate\"                : false,\n        \"self_rotation_speed\"               : 0.5,\n        \"self_rotation_speed_final\"         : 0.3,\n        \"dis_threshold\"                     : 0.5,\n        \"theta_threshold\"                   : 0.2,\n        \"cmd_Smoothing\"                     : true,\n    }\n}\n</code></pre>"},{"location":"sdk-config/auto-config/#42-definitions","title":"4.2 Definitions","text":""},{"location":"sdk-config/auto-config/#421-main","title":"4.2.1 Main","text":"Variable Definition <code>py_address</code> The address of the d.ASH server in the formal <code>&lt;IP&gt;:&lt;PORT&gt;</code>. <code>ue_address</code> The address of the GUI server in the formal <code>&lt;IP&gt;:&lt;PORT&gt;</code>. <code>ssl</code> Enables secure SSL messaging and encryption. <code>motion_planner</code> Enables autonomy motion planning. <code>localization</code> Enables robot localisation, returning users position and orientation in relation to map. <code>sim_mode</code> Enables Spot odometry retrieval. <code>send_data_gui</code> Enables ability to send data to GUI server for visualisation. <code>camera</code> Camera active for the current session to retrieve data ie. RealsenseCam, TestCam. <code>retrieveImg</code> Enables image retrieval. <code>map_name</code> Map name used for autonomy (as mentioned in File Organisation). <code>pc_topic</code> ROS point cloud topic name for subscribing <code>odom_topic</code> ROS odometry topic name for subscribing."},{"location":"sdk-config/auto-config/#422-controller","title":"4.2.2 Controller","text":"<p>For the following parameters, ensure the value is within limits of the robot as per its documentation.</p> Variable Definition <code>linear_window</code> Sets DWA (dynamic window approach) size. <code>linear_min_v</code> Sets minimum linear velocity for autonomy. <code>linear_max_v</code> Sets maximum linear velocity for autonomy. <code>angular_max_w</code> Sets maximum angular velocity for autonomy. <code>linear_max_a</code> Sets maximum linear acceleration for autonomy. <code>angular_max_a</code> Sets maximum angular acceleration for autonomy. <code>robot_width</code> Reflects width of robot. <code>robot_length</code> Reflects the length of robot. <code>obstacle_cost_gains</code> Sets weight for an obstacle course based on the weighted sum of the map. <code>speed_cost_gains</code> Sets weight for speed cost. <code>goal_cost_gains</code> Sets weight for goal cost. <code>angular_speed_cost_scaling_factor</code> Sets weight for angular velocity. Note that a higher value of the variable discourages the robot from turning. <code>linear_num_window_steps</code> Sets number of linear velocity values to consider. Note that a higher value of the variable slows down the computations. <code>angular_num_window_steps</code> Sets number of angular velocity values to consider. Note that a higher value of the variable slows down the computations. <code>prediction_window</code> Sets prediction horizion (in seconds). Note that a higher value of the variable slows down the computations. <code>costmap_size</code> Sets local costmap size (in meters). <code>costmap_scale</code> Sets scale to convert map from meter to pixels. <code>max_pc_height</code> Sets maximum point cloud height to be considered as an obstacle. <code>min_pc_height</code> Sets minimum point cloud height to be considered as an obstacle. Note that the point cloud height is measured from the center of the lidar. If the ground is detected, it will be considered as an obstacle. Therefore, set the minimum value to be above the ground. <code>x_filter</code> Sets vector of size 2 consisting the minimum and maximum x-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. <code>y_filter</code> Sets vector of size 2 consisting the minimum and maximum y-value of point cloud to be removed. Do not remove too much from the point cloud filter as obstacles around the robot might not be considered. <code>costmap_obs_inflation</code> Sets inflation radius of obstacles to be considered in planning. Note that a higher value of the variable results in more conservative planning. <code>occ_obs_deadzone</code> Sets minimum distances from obstacles and robots for autonomy. <code>dt</code> Sets timestep. Note that a higher timestamp slows down the computation. <code>visualise</code> Enables visualisation of costmap. This is used only for debugging."},{"location":"sdk-config/auto-config/#423-state-estimator","title":"4.2.3 State Estimator","text":"Variable Definition <code>initial_x</code> Sets initialization of x-axis for localizaition (in meters). <code>initial_y</code> Sets initialization of y-axis for localizaition (in meters). <code>initial_z</code> Sets initialization of z-axis for localizaition (in meters). <code>initial_w</code> Sets initialization of orientation for localizaition. <code>kImuTopic</code> ROS IMU (Inertial Measurement Unit) topic name for subscribing. <code>kPoseTopic</code> Enables localization result. <code>ktfUpdate</code> Sets ROS tf publishing frequency. <code>kStatusUpdate</code> Sets localisation status of publishing frequency. <code>kLoggingUpdate</code> Sets data logging period. <code>kposeDiffmax</code> Sets the maximum distance between two consecutive pose estimation. <code>KUse_imu_ori</code> Enables IMU (Inertial Measurement Unit) or odom orientation for odometry estimation. If this variable is set to true, ensure <code>kImuTopic</code> is available. <code>kBadCovThres</code> Sets localization quality. <code>kGoodCovThres</code> Sets localization quality. <code>kCovBadMax</code> Sets localization quality. <code>kCovGoodtMax</code> Sets localization quality. <code>kFilter_z</code> Enables pass through filter application for localization. <code>klimit_min</code> Sets minimum range of pass through filter. <code>klimit_max</code> Sets maximum range of pass through filter."},{"location":"sdk-config/auto-config/#424-planner","title":"4.2.4 Planner","text":"Variable Definition <code>lookAheadIndexv</code> Sets look-ahead index from the nearest waypoint for path to follow. Note that a lower index slows down the movement of the robot. Similarly, a higher index results in the robot not follow path properly. <code>enable_self_rotate</code> Enables one round of rotation around the robot itself before performing autonomy. This is to ensure that localisation is working before starting autonomy. <code>self_rotation_speed</code> Sets angular velocity of robot to turn around itself before performing autonomy (in radiants/second). <code>self_rotation_speed_final</code> Sets angular velocity of robot to turn around itself after performing autonomy (in radiants/second). This ensures that the final orientation of robot aligns with its goal. <code>dis_threshold</code> Sets maximum euclidean distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. <code>theta_threshold</code> Sets maximum orientation distance from the robot to the final goal for destination to be considered having reached its goal. Note that a smaller threshold discourages the robot from determing if it has reached its goal. <code>cmd_Smoothing</code> Enables smoothing control commands."},{"location":"sdk-config/register-bot/","title":"Register Payload Configuration","text":"<p>This section of the d.ASH SDK documentation provides details about the configuration file for payload registration - <code>register_payload_config</code> - found in the folder <code>\\dash-sdk\\configs</code>. Information in this section includes variable and definitions to configure payload registration.</p>"},{"location":"sdk-config/register-bot/#21-config-file","title":"2.1 Config File","text":"<pre><code>{\n    \"robot_name\" : \"&lt;ROBOT_NAME&gt;\",\n    \"robot_username\"  : \"&lt;DC_USERNAME&gt;\"\n}\n</code></pre>"},{"location":"sdk-config/register-bot/#22-definitions","title":"2.2 Definitions","text":"Variable Definition <code>robotName</code> Set the name of your robot - this can be any string. <code>robotUserName</code> Set the name of your username - this has to match your dConstruct cloud admin username."},{"location":"sdk-config/rest-config/","title":"d.ASH Service Configuration","text":"<p>This section of the d.ASH SDK documentation provides details about the configuration file for the rest server - <code>dash_service_config.json</code> - found in the folder <code>\\dash-sdk\\configs</code>. Information in this section includes variable and definitions to configure the d.ASH service.</p>"},{"location":"sdk-config/rest-config/#11-config-file","title":"1.1 Config File","text":"<pre><code>{\n    \"port\" : 3000,\n    \"cert_filename\" : \"./cert.pem\",\n    \"key_filename\" : \"./key.pem\",\n    \"dh_params_filename\" : \"\",\n    \"robot_register_native_cert\" : true,\n    \"active_IP_idx\" : 1, \n    \"preferred_IP\" : \"10.8.0.5\", \n    \"run_cmds\" : {\n        \"py_server\" : {\n            \"cmd_str\" : \"python ./spot_server.py ./configs/dash-service-config.json &lt;!TOKEN!&gt;\",\n            \"cmd_path\" : \"C:/Users/dc/Documents/Projects/dc/dash_code/py_server\"\n        }\n    }\n}\n</code></pre>"},{"location":"sdk-config/rest-config/#12-definitions","title":"1.2 Definitions","text":""},{"location":"sdk-config/rest-config/#121-main","title":"1.2.1 Main","text":"Variable Definition <code>port</code> Fixed port number. <code>cert_filename</code> Fixed certification filename. <code>key_filename</code> Fixed certification key filename. <code>dh_params_filename</code> Fixed parameter filename. <code>robot_register_native_cert</code> If you registed with register_bot_native, the data will be encrypted. Always set this variable to true. <code>active_IP_idx</code> Selects the IP address you will send to the backend cloud service for robot discovery. This is an integer index ( from 0 to N ), based on the IP addresses available on your system. When the rest service starts up, you should see a list. Set the value to the appropriate index you want. This index will map the the IP which the clients will try to connect to. <code>preferred_IP</code> Selects your preferred IP from the list of IPs. Specify the IP as a string in this case."},{"location":"sdk-config/rest-config/#122-dash-server-commands","title":"1.2.2 d.ASH Server Commands","text":"Variable Definition <code>cmd_str</code> Sets command to run d.ASH server. <code>cmd_path</code> Sets command path."},{"location":"sdk-config/robot-config/","title":"Robot Configuration","text":"<p>This section of the d.ASH SDK documentation provides details about the configuration file for the robot - <code>robot_config.json</code> - found in the folder <code>\\dash-sdk\\configs</code>. Information in this section includes variable and definitions used to configure the d.ASH server.</p>"},{"location":"sdk-config/robot-config/#31-config-file","title":"3.1 Config File","text":"<pre><code>{\n\"server_address\" : \"localhost:50051\",\n\"robot_hostname\" : \"192.168.80.3\",\n\"username\" : \"&lt;USERNAME&gt;\",\n\"cam_list\" : [\"RealsenseCam\"],\n\"payloads\" : [],\n\"data_state_log_folder\" : \"G:/Temp/logs\",\n\"ssl\" : true,\n\"fast_server\" : false,\n\"fast_server_hostname\" : \"localhost:7777\",\n\"secure_default_token\" : false,\n\"test_mode\" : true,\n\"with_audio\" : true,\n\"real_sense_config\" : {\n\"test\" : true,\n\"test_filenames\" : [\"../../test_videos/nus_left.mp4\", \"../../test_videos/nus_center.mp4\",\"../../test_videos/nus_right.mp4\"],\n\"flip_options\" : {\n\"0\" : [false, false],\n\"1\" : [true, true],\n\"2\" : [false, false]\n},\n\"base_width\" : 640,\n\"base_height\" : 480,\n\"codec\" : \"video\",\n\"width\" : 320,\n\"height\" : 240,\n\"bitrate\" : 3600000\n}\n}\n</code></pre>"},{"location":"sdk-config/robot-config/#32-definitions","title":"3.2 Definitions","text":""},{"location":"sdk-config/robot-config/#321-main","title":"3.2.1 Main","text":"Variable Definition <code>server_address</code> Sets address of the d.ASH server in <code>&lt;HOSTNAME&gt;:&lt;PORT&gt;</code> format. <code>robot_hostname</code> Sets hostname of the Spot to connect to robot's IP. <code>username</code> Sets username for d.ASH server credentials. <code>cam_list</code> Sets a list of cameras active for the current session. <code>payloads</code> Optional payloads list. <code>data_state_log_folder</code> Sets folder to write out the recorded msgpack data of the robot. <code>ssl</code> Enables secure SSL messaging and encryption. <code>test_mode</code> Enables the d.ASH server to enter into test mode. <code>with_audio</code> Enables audio streaming playback."},{"location":"sdk-config/robot-config/#322-intel-realsense-configuration","title":"3.2.2 Intel RealSense Configuration","text":"Variable Definition <code>test</code> Enables simulation of camera streaming via provided custom mp4 video files specified as a list in <code>test_filenames</code>. <code>test_filenames</code> List of test files. <code>flip_options</code> Specify how each camera flips long the x-axis and y-axis following the format <code>{\"index\" : [x-flip, y-flip]}</code>. <code>baseWidth</code> Sets processing width of the camera stream. Note that a minimum <code>baseWidth</code> of 640 is required. <code>baseHeight</code> Sets the processing height of the camera stream. Note that a  minimum <code>baseHeight</code> of 360 is required. <code>codec</code> Sets jpg/video options, with jpg being regular jpeg encoding and video using VP9 encoding. <code>width</code> Adjusts the final returned/resized width dimensions of the input camera stream. Video will be processed at this base resolution before being resized via <code>width</code> and <code>height</code>. Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. <code>height</code> Adjusts the final returned/resized height dimensions of the input camera stream. Video will be processed at this base resolution before being resized via <code>width</code> and <code>height</code>. Use these variables to change the actual processed resolution for power/efficiency considerations of the RealSense devices. <code>bitrate</code> This is the quality of the video encoding. Note for HD Streaming, RealSense requires a high bitrate of 3600000."},{"location":"setup/dash/","title":"Setting Up d.ASH","text":"<p>As mentioned previously, the d.ASH consists of three main components - d.ASH server, d.ASH service, and d.ASH autonomy engine. This section of the d.ASH SDK documentation provides details about setting up the d.ASH components including compiling and testing.</p>"},{"location":"setup/dash/#41-installing-dash-dependencies","title":"4.1 Installing d.ASH Dependencies","text":"<p>To install the remaining d.ASH dependencies using pip, the following desktop dependencies must be set up prior:</p> <ul> <li> Intel RealSense SDK 2.0</li> <li> ROS Melodic on Ubuntu 18.04</li> <li> FFmpeg and others</li> </ul> <p>If the above dependencies have been installed, proceed by running the following command to install the rest of the python packages: <pre><code>python3.7 config_libs.py\n</code></pre> Please ensure you are in the <code>\\dash-sdk</code> directory before running. Following the instructions prompted by the terminal to proceed with installation.</p>"},{"location":"setup/dash/#42-setting-up-dash-server","title":"4.2 Setting up d.ASH Server","text":"<p>To set up the d.ASH server, you will need to configure the d.ASH server configuration file - <code>robot_config.json</code> - located in the folder <code>\\dash-sdk\\configs</code>. </p> <pre><code>dash-sdk/\n\u2514\u2500 configs/\n    \u2514\u2500 robot_config.json\n    \u2514\u2500 ...\n</code></pre> <p>Follow the variable definitions for <code>robot_config.json</code> to set up the file correctly for the d.ASH server.</p> <p>Once <code>robot_config.json</code> has been set up, run the d.ASH server by executing the following command on your terminal:</p> <pre><code>python3.7 ./dash_server.py robot_config.json\n</code></pre>"},{"location":"setup/dash/#43-setting-up-dash-service","title":"4.3 Setting up d.ASH Service","text":"<p>To set up the d.ASH service, you will need to configure the d.ASH service configuration file - <code>dash_service_config.json</code> - located in the folder <code>\\dash-sdk\\configs</code>. </p> <pre><code>dash-sdk/\n\u2514\u2500 configs/\n    \u2514\u2500 dash_service_config.json\n    \u2514\u2500 ...\n</code></pre> <p>First, run <code>runrest</code> to see available IP address for your rest server: <pre><code>runrest\n</code></pre> Pick the index of the IP address you like and append it to the <code>activeIPIdx</code> variable in <code>dash_service_config.json</code>: <pre><code>\"activeIPIdx\" : 1, # where '1' is the chosen IP address index\n</code></pre> Then, you will need to set your <code>preferredIP</code> address, that is, the IP address for the computer onboard your robot. This IP address will have precedence over <code>activeIPIdx</code>. Similarly, replace the default IP address with your preferred IP address in <code>dash_service_config.json</code>: <pre><code>\"preferredIP\" : \"10.8.0.5\", # where '10.8.0.5' is the preferred IP address\n</code></pre></p> <p>Ensure that the IP address of the onboard computer is within the same subnet by the remote client. Lastly, you will need to change the <code>&lt;PATH_OF_SDK&gt;</code> of <code>cmdPath</code> in <code>dash_service_config.json</code>:  <pre><code>\"cmdPath\" : \"&lt;PATH&gt;\"\n</code></pre></p> <p>To do this, use <code>pwd</code> to print your current working directory path and replace <code>&lt;PATH_OF_SDK&gt;</code> with the path printed. For example, if your current directory is <code>/home/dash_sdk/py_server</code>:</p> <pre><code>\"cmdPath\" : \"/home/dash_sdk\"\n</code></pre> <p>To test the d.ASH service, you'll need to run the d.ASH server by running the following command: </p> <pre><code>./robot_rest &lt;PATH_TO_SDK&gt;/configs/dash_service_config.json\n</code></pre> <p>Now that your d.ASH service is running, you can use our d.ASH Pilot app. To launch the  d.ASH Pilot app, simply search for it in your Windows search bar. Now, login to the system and connect to your robot to start controlling your robot. For more information on the d.ASH Pilot, refer to the d.ASH Pilot guide.</p>"},{"location":"setup/dash/#44-setting-up-dash-autonomy-engine","title":"4.4 Setting up d.ASH Autonomy Engine","text":"<p>To set up the d.ASH autonomy engine, you will need to configure the d.ASH autonomy configuration file - <code>auto_config.json</code> - located in the folder <code>/dash-sdk/configs/</code>.</p> <pre><code>dash-sdk/\n\u2514\u2500 configs/\n    \u2514\u2500 auto_config.json\n    \u2514\u2500 ...\n</code></pre> <p>Follow the variable definitions for <code>auto_config.json</code> to set up the file correctly for the d.ASH autonomy engine.</p> <p>Once <code>auto_config.json</code> has been set up, test the d.ASH autonomy engine by run the executable below to start autonomy driver. Note to replace <code>&lt;PATH_TO_SDK&gt;</code> with your current working directory containing the d.ASH SDK:</p> <pre><code>./dash_autonomy &lt;PATH_TO_SDK&gt;/config/auto_config.json\n</code></pre> <p>To find your current working directory, use <code>pwd</code>. For example, if your directory is <code>/home/dash-sdk</code>, you would run the following command to test d.ASH autonomy:</p> <pre><code>./dash_autonomy /home/dash-sdk/config/auto_config.json\n</code></pre> <p>You will need to run d.ASH service first before running the d.ASH server and the d.ASH autonomy engine.</p> <p>On a seperate terminal, start a simple <code>roslaunch</code> test by running the following prompt, replacing <code>&lt;PATH_TO_SDK&gt;</code> with your current working directory containing the d.ASH SDK:</p> <pre><code>cd \\launch\nroslaunch &lt;PATH_TO_SDK&gt;\\dash_sdk\\launch\\simple_joy.launch\n</code></pre> <p>Launch files have been prepared for setup - either with the Velodyne VLP-16 lidar sensor or the Ouster OS1-32 lidar sensor. These lauch files can be found in under the <code>\\dash-sdk\\launch</code> folder. You can also create your own sensor launch files for your tests.</p>"},{"location":"setup/desktop-dep/","title":"Installing Dependencies on the Desktop","text":"<p>While most of the d.ASH SDK build is hermetic, some system dependencies on the Desktop are required. This section of the d.ASH SDK documentation provides details for Intel RealSense SDK, Ubuntu, ROS Melodic, and FFmpeg installations.</p>"},{"location":"setup/desktop-dep/#11-ubuntu-installation","title":"1.1 Ubuntu Installation","text":"<p>Ubuntu is a complete Linux operating system, which will serve as the primary platform for ROS. Currently, the d.ASH SDK only supports Linux Ubuntu 18.04 LTS for development and simulation from your workstation. </p> <p>Ubuntu Installation via Bootable USB</p> <p>If you would like to install Ubuntu via a bootable USB, you can do so for both Windows and MacOS.</p> <p>Ubuntu Installation via Virtual Machine</p> <p>If you would like to install Ubuntu via a virtual machine, you can do so using VirtualBox to kickstart your installation process.</p> <p>Once Ubuntu is installed, check that your version of Ubuntu has the release code <code>18.04</code>.  Open the terminal and type the command: <pre><code>lsb_release -a\n</code></pre> This should print the following result: <pre><code>No LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 18.04.5 LTS\nRelease:        18.04\nCodename:       bionic\n</code></pre></p>"},{"location":"setup/desktop-dep/#12-ros-installation","title":"1.2 ROS Installation","text":"<p>ROS (Robot Operating System) is a open-source framework that helps researchers and developers build and reuse code between robotics applications. Currently, the d.ASH SDK only supports ROS Melodic for development and simulation from your workstation. </p> <p>Use Ubuntu to install ROS Melodic onto your computer system. Once ROS has been installed on your Linux system, check that your version of ROS is <code>melodic</code>.  Open the terminal and type the command:</p> <pre><code>rosversion -d\n</code></pre> <p>This should print <code>melodic</code>. Otherwise, ensure that you installed the correct version of ROS - ROS Melodic.</p>"},{"location":"setup/desktop-dep/#13-intel-realsense-sdk-installation","title":"1.3 Intel RealSense SDK Installation","text":"<p>Intel RealSense is an RGB camera with channels designed for depth perception capabilities. The RealSense SDK 2.0 provides installation packages for Intel X86 / AMD64-based Debian distributions in <code>dpkg</code> format for Ubuntu 16/18/20 LTS. You'll be able to configure custom settings for any Intel RealSense cameras attached to the system to stream images to remote clients. </p> <p>Use Ubuntu to install Intel RealSense SDK 2.0 onto your computer system.</p>"},{"location":"setup/desktop-dep/#14-ffmpeg-installation","title":"1.4 FFmpeg Installation","text":"<p>FFmpeg is an open-source software project consisting of libraries and programs that handle video, audio, and other multimedia files and streams.</p> <p>To install FFmpeg, run the following commands on your Ubuntu terminal: <pre><code>sudo add-apt-repository ppa:jonathonf/ffmpeg-4\nsudo apt-get install ffmpeg libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev libavutil-dev libpostproc-dev libswresample-dev libswscale-dev libgoogle-glog-dev\n</code></pre></p>"},{"location":"setup/desktop-dep/#15-python-requirements","title":"1.5 Python Requirements","text":"<p>The d.ASH SDK works with Python 3.7. To properly run the server, you will also need to install a python package installer, pip.</p>"},{"location":"setup/desktop-dep/#151-apt-get","title":"1.5.1 apt-get","text":"<p>Installed in Ubuntu and any Ubuntu-based Linux distribution, <code>apt-get</code> is tool for installing, upgrading, and cleaning packages. To set up the new environment, execute the following command on your Ubuntu terminal: <pre><code>sudo apt-get install -y python3.7-dev\n</code></pre></p>"},{"location":"setup/desktop-dep/#152-pip-installation","title":"1.5.2 Pip Installation","text":"<p>Pip is a package installer for Python. The d.ASH SDK and the third-party packages used by many of its programming examples use pip to install. To install pip, run the following command on your Ubuntu terminal:</p> <pre><code>sudo apt install python3.7 python3-pip python-pip\npython3.7 -m pip instal -- upgrade pip\n</code></pre>"},{"location":"setup/payload-reg/","title":"Payload Registration","text":"<p>Before running the d.ASH SDK, please make sure that all of your credentials have been set up correctly. This means using the right username and the right password. This section of the d.ASH SDK documentation provides details about setting up credentials for the d.ASH server, your robot, and d.ASH autonomy. Files in this section can be found in the folder <code>registration</code>:</p> <pre><code>dash-sdk/\n\u2514\u2500 registration\n    \u2514\u2500 set_spot_cred\n    \u2514\u2500 register_payload\n    \u2514\u2500 set_autonomy_cred\n</code></pre>"},{"location":"setup/payload-reg/#21-dash-server-credentials","title":"2.1 d.ASH Server Credentials","text":"<p>To set up the local credentials for the d.ASH server, you will need to run the file <code>set_spot_cred</code>. Run the following command replacing <code>&lt;USERNAME&gt;</code> with your chosen username and  <code>&lt;PASSWORD&gt;</code> with your chosen password.</p> <pre><code>./set_spot_cred -u &lt;USERNAME&gt; -p &lt;PASSWORD&gt;\n</code></pre> <p>For example, if your username is <code>user123</code> and your password is <code>pw123</code>, your command would look like this: <pre><code>./set_spot_cred -u user123 -p pw123\n</code></pre></p> <p>Username in Robot Configuration</p> <p>Please ensure that the username for the d.ASH server is the same as the one defined in the robot configuration file - <code>robot_config.json</code>. That is, you would replace <code>&lt;USERNAME&gt;</code> with your chosen username in <code>\"username\" : \"&lt;USERNAME&gt;\"</code>.</p>"},{"location":"setup/payload-reg/#22-robot-registration","title":"2.2 Robot Registration","text":"<p>To register the payload computer with d.ASH's backend system, you will need to run the file <code>register_payload</code>. However, you will first need to configure the <code>register_payload_config.json</code> found in the <code>\\dash-sdk\\configs</code> folder of the SDK. Set <code>&lt;ROBOT_NAME&gt;</code> to any name you like, and set <code>&lt;DC_USERNAME&gt;</code> to your dConstruct cloud admin username. </p> <p>For example, if your robot name is <code>robot1</code> and your cloud admin user name is <code>user123</code>, your <code>register_payload_config.json</code> would look like this:</p> <pre><code>{\n    RobotName: robot1,\n    RobotUserName: user123\n}\n</code></pre> <p>Now, run the following command to register your robot, replacing <code>&lt;PATH_TO_SDK&gt;</code> with your local path to the d.ASH SDK.</p> <pre><code>./register_payload -i &lt;PATH_TO_SDK&gt;/dash_sdk/configs/register_payload_config\n</code></pre>"},{"location":"setup/payload-reg/#23-dash-autonomy-credentials","title":"2.3 d.ASH Autonomy Credentials","text":"<p>To set up the local credentials for d.ASH autonomy, you will need to run the file  <code>set_autonomy_cred</code>. Run the following command replacing <code>&lt;USERNAME&gt;</code> with your cloud admin username. </p> <p><pre><code>cd ./set_auto_cred/build\n./set_autonomy_cred -u &lt;USERNAME&gt; \n</code></pre> For example, if your username is <code>user123</code>, your command would look like this: <pre><code>cd ./set_auto_cred/build\n./set_autonomy_cred -u user123\n</code></pre> You will then be prompted to enter a password, which will match your cloud admin password. Enter</p>"},{"location":"setup/vpn/","title":"Setting Up d.ASH VPN","text":"<p>When setting up VPN for d.ASH, two separate login credentials are required for two seperate VPN connections - one for the robot onboard computer and one for the remote client. This section of the d.ASH SDK documentation provides details about setting up the d.ASH VPN for both your robot and your remote client.</p>"},{"location":"setup/vpn/#31-setting-up-vpn-onboard-computer","title":"3.1 Setting Up VPN Onboard Computer","text":"<p>To start, you will need to install some packages to configure automatic VPN connection on Ubuntu 18.04 LTS by executing the following command:</p> <pre><code>sudo apt install network-manager-openvpn network-manager-openvpn-gnome openvpn openvpn-systemd-resolved -y\n</code></pre> <p>This will install an <code>openvpn</code> package, which creates a <code>/etc/openvpn/client/</code> directory into which you can place the OpenVPN client configuration file. You will need to configure the VPN configuration file - <code>client.ovpn</code> which can be found in your vpn folder <code>/dash_sdk/vpn</code>. </p> <p><pre><code>dash-sdk/\n\u2514\u2500 vpn/\n    \u2514\u2500 client.ovpn\n    \u2514\u2500 ca.crt\n    \u2514\u2500 &lt;USER&gt;.crt\n    \u2514\u2500 &lt;USER&gt;.key\n</code></pre> Note that <code>&lt;USER&gt;</code> in this instance is replaced by your dConstruct admin username. Now, you will need to copy <code>client.ovpn</code> and your user certifications - <code>ca.crt</code>, <code>&lt;USER&gt;.crt</code>, <code>&lt;USER&gt;.key</code> - into the new open vpn directory. In the <code>/dash_sdk</code> directory, execute the following commands:</p> <pre><code>python3.7 config_vpn.py\nsudo cp client.ovpn /etc/openvpn/client/client.conf \nsudo cp ca.crt &lt;USER&gt;.crt &lt;USER&gt;.key /etc/openvpn/client\n</code></pre> <p>For example, if your dConstruct admin username is <code>user123</code>, you would replacing <code>&lt;USER&gt;</code> with <code>user123</code>:</p> <pre><code>sudo cp client.ovpn /etc/openvpn/client/client.conf \nsudo cp ca.crt user123.crt user123.key /etc/openvpn/client\n</code></pre> <p>To check that your files have been copied and renamed correctly, <code>cd</code> into the <code>/etc/openvpn/client</code> directory and <code>ls</code> to see your list of files. You should have <code>client.conf</code> and your user certification files, namely <code>ca.crt &lt;USER&gt;.crt &lt;USER&gt;.key</code>:</p> <pre><code>etc/\n\u2514\u2500 openvpn/\n    \u2514\u2500 client/\n        \u2514\u2500 client.conf\n        \u2514\u2500 ca.crt\n        \u2514\u2500 &lt;USER&gt;.crt\n        \u2514\u2500 &lt;USER&gt;.key\n</code></pre> <p>Now, let's test that the VPN service was set up correctly by running the following command: <pre><code>sudo systemctl start openvpn-client@client.service\n</code></pre></p> <p>If there is no error print, proceed onto the next step. If you come across a failure, ensure that the path in <code>client.conf</code> matches the following format:</p> <pre><code>cat \\etc\\openvpn\\client\\ca.crt\ncert \\etc\\openvpn\\client\\&lt;USER&gt;.crt\nkey \\etc\\openvpn\\client\\&lt;USER&gt;.crt\n</code></pre> <p>Now, to check your VPN status, enter the following command:  <pre><code>sudo systemctl status openvpn-client@client.service\n</code></pre> If successful, you should be able to see the status <code>Initialization Sequence Completed</code>. Lastly, enable the VPN onboard your computer by executing the following command: </p> <pre><code>sudo systemctl enable openvpn-client@client.service\n</code></pre>"},{"location":"setup/vpn/#32-setting-up-vpn-remote-client","title":"3.2 Setting Up VPN Remote Client","text":"<p>Remember to use a separate login credential from the robot onboard computer credentials as at any point in time, there can only be one active user session.</p> <p>Firstly, download OpenVPN Connect. Once OpenVPN has been launched, click on the tab - 'Import from File' tab and drag-and-drop the <code>client.ovpn</code> file located in <code>\\dash-sdk\\vpn</code>. It is important to note that the <code>client.ovpn</code> file has to be in the same directory as there certification files, namely <code>ca.crt &lt;USER&gt;.crt &lt;USER&gt;.key</code>:</p> <pre><code>dash-sdk/\n\u2514\u2500 vpn/\n    \u2514\u2500 client.ovpn\n    \u2514\u2500 ca.crt\n    \u2514\u2500 &lt;USER&gt;.crt\n    \u2514\u2500 &lt;USER&gt;.key\n</code></pre>"}]}